Paper URL,Title,Author,Email,Confidence
https://arxiv.org/pdf/2302.00123.pdf,Design and Implementation of A Soccer Ball Detection System with Multiple Cameras,Lei Li,LI-LEI@USTC.EDU,95%
https://arxiv.org/pdf/2302.00123.pdf,Design and Implementation of A Soccer Ball Detection System with Multiple Cameras,Zhongfeng Kang,KANGZHF@GMAIL.COM,78%
https://arxiv.org/pdf/2302.00123.pdf,Design and Implementation of A Soccer Ball Detection System with Multiple Cameras,Wenhan Zhang,WENHANZHANG430@GMAIL.COM,95%
https://arxiv.org/pdf/2302.00123.pdf,Design and Implementation of A Soccer Ball Detection System with Multiple Cameras,Tianfang Zhang,,0%
https://arxiv.org/pdf/2302.00117.pdf,Real Estate Property Valuation using Self-Supervised Vision Transformers,Mahdieh Yazdani,,0%
https://arxiv.org/pdf/2302.00117.pdf,Real Estate Property Valuation using Self-Supervised Vision Transformers,Maziar Raissi,,0%
https://arxiv.org/pdf/2302.00070.pdf,Debiasing Vision-Language Models via Biased Prompts,Ching-yao Chuang,cychuang@mit.edu,82%
https://arxiv.org/pdf/2302.00070.pdf,Debiasing Vision-Language Models via Biased Prompts,Antonio Torralba,torralba@mit.edu,78%
https://arxiv.org/pdf/2302.00070.pdf,Debiasing Vision-Language Models via Biased Prompts,Yuanzhen Li,yzli@google.com,82%
https://arxiv.org/pdf/2302.00070.pdf,Debiasing Vision-Language Models via Biased Prompts,Varun Jampani,varunjampani@google.com,95%
https://arxiv.org/pdf/2302.00070.pdf,Debiasing Vision-Language Models via Biased Prompts,Stefanie Jegelka,,0%
https://arxiv.org/pdf/2302.00059.pdf,NASiam: Efficient Representation Learning using Neural Architecture Search for Siamese Networks,Hedi Tabia,hedi.tabia@univ-evry.fr,95%
https://arxiv.org/pdf/2302.00059.pdf,NASiam: Efficient Representation Learning using Neural Architecture Search for Siamese Networks,Hichem Arioui,hichem.arioui@univ-evry.fr,95%
https://arxiv.org/pdf/2302.00059.pdf,NASiam: Efficient Representation Learning using Neural Architecture Search for Siamese Networks,Alexandre Heuillet,alexandre.heuillet@univ-evry.fr,95%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Hongbin Zha,zha@cis.pku.edu.cn,78%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Hao Zhao,hao.zhao@intel.com,95%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Guyue Zhou,zhouguyue@air.tsinghua.edu.cn,95%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Pengfei Li,li-pf22@mails.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Yurong Chen,yurong.chen@intel.com,95%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Xiaoxue Chen,chenxx21@mails.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Huan-ang Gao,,0%
https://arxiv.org/pdf/2301.13865.pdf,From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds,Beiwen Tian,,0%
https://arxiv.org/pdf/2301.13862.pdf,Salient Conditional Diffusion for Defending Against Backdoor Attacks,N. Joseph Tatro,joseph.tatro@str.us,78%
https://arxiv.org/pdf/2301.13862.pdf,Salient Conditional Diffusion for Defending Against Backdoor Attacks,Brandon B. May,,0%
https://arxiv.org/pdf/2301.13862.pdf,Salient Conditional Diffusion for Defending Against Backdoor Attacks,Dylan Walker,,0%
https://arxiv.org/pdf/2301.13862.pdf,Salient Conditional Diffusion for Defending Against Backdoor Attacks,Piyush Kumar,,0%
https://arxiv.org/pdf/2301.13862.pdf,Salient Conditional Diffusion for Defending Against Backdoor Attacks,Nathan Shnidman,,0%
https://arxiv.org/pdf/2301.13823.pdf,Grounding Language Models to Images for Multimodal Inputs and Outputs,Jing Yu Koh,jingyuk@cs.cmu.edu,85%
https://arxiv.org/pdf/2301.13823.pdf,Grounding Language Models to Images for Multimodal Inputs and Outputs,Ruslan Salakhutdinov,,0%
https://arxiv.org/pdf/2301.13823.pdf,Grounding Language Models to Images for Multimodal Inputs and Outputs,Daniel Fried,,0%
https://arxiv.org/pdf/2301.13838.pdf,Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression,Martha Larson,m.larson@cs.ru.nl,82%
https://arxiv.org/pdf/2301.13838.pdf,Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression,Zhuoran Liu,z.liu@cs.ru.nl,82%
https://arxiv.org/pdf/2301.13838.pdf,Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression,Zhengyu Zhao,zhengyu.zhao@cispa.de,95%
https://arxiv.org/pdf/2301.13826.pdf,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,Yael Vinker,yael.vinker@mail.huji.ac.il,95%
https://arxiv.org/pdf/2301.13826.pdf,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,Hila Chefer,hilach70@gmail.com,85%
https://arxiv.org/pdf/2301.13826.pdf,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,Lior Wolf,liorwolf@gmail.com,95%
https://arxiv.org/pdf/2301.13826.pdf,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,Yuval Alaluf,yuvalalaluf@gmail.com,95%
https://arxiv.org/pdf/2301.13826.pdf,Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models,Daniel Cohen-or,,0%
https://arxiv.org/pdf/2301.13817.pdf,Patch Gradient Descent: Training Neural Networks on Very Large Images,Deepak K. Gupta,,0%
https://arxiv.org/pdf/2301.13817.pdf,Patch Gradient Descent: Training Neural Networks on Very Large Images,Gowreesh Mago,,0%
https://arxiv.org/pdf/2301.13817.pdf,Patch Gradient Descent: Training Neural Networks on Very Large Images,Arnav Chavan,,0%
https://arxiv.org/pdf/2301.13817.pdf,Patch Gradient Descent: Training Neural Networks on Very Large Images,Dilip K. Prasad,,0%
https://arxiv.org/pdf/2301.13809.pdf,A Prototype System for High Frame Rate Ultrasound Imaging based Prosthetic Arm Control,Mahesh Raveendranatha Panicker,mahesh@iitpkd.ac.in,85%
https://arxiv.org/pdf/2301.13809.pdf,A Prototype System for High Frame Rate Ultrasound Imaging based Prosthetic Arm Control,Ayush Singh,,0%
https://arxiv.org/pdf/2301.13809.pdf,A Prototype System for High Frame Rate Ultrasound Imaging based Prosthetic Arm Control,Pisharody Harikrishnan Gopalkrishnan,,0%
https://arxiv.org/pdf/2301.13803.pdf,Fairness-aware Vision Transformer via Debiased Self-Attention,Dongxiao Zhu,dzhu@wayne.edu,82%
https://arxiv.org/pdf/2301.13803.pdf,Fairness-aware Vision Transformer via Debiased Self-Attention,Chengyin Li,cyli@wayne.edu,82%
https://arxiv.org/pdf/2301.13803.pdf,Fairness-aware Vision Transformer via Debiased Self-Attention,Prashant Khanduri,khanduri.prashant@wayne.edu,95%
https://arxiv.org/pdf/2301.13803.pdf,Fairness-aware Vision Transformer via Debiased Self-Attention,Yao Qiang,yao@wayne.edu,85%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Daniel Capellán-martín,daniel.capellan@upm.es,85%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Elisa López-varela,mj.ledesma@upm.es,60%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Juan J. Gómez-valverde,,0%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Ramon Sanchez-jacob,,0%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,David Bermejo-peláez,,0%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Lara García-delgado,,0%
https://arxiv.org/pdf/2301.13786.pdf,Deep learning-based lung segmentation and automatic regional template in chest X-ray images for pediatric tuberculosis,Maria J. Ledesma-carbayo,,0%
https://arxiv.org/pdf/2301.13743.pdf,Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion,Zihao Wang,zihao.wang@ieee.org,95%
https://arxiv.org/pdf/2301.13743.pdf,Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion,Yingyu Yang,,0%
https://arxiv.org/pdf/2301.13743.pdf,Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion,Maxime Sermesant,,0%
https://arxiv.org/pdf/2301.13743.pdf,Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion,Hervé Delingette,,0%
https://arxiv.org/pdf/2301.13743.pdf,Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion,Ona Wu,,0%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Chun Yuan,yuanc@sz.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Dachuan Shi,,0%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Chaofan Tao,,0%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Ying Jin,,0%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Zhendong Yang,,0%
https://arxiv.org/pdf/2301.13741.pdf,UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers,Jiaqi Wang,,0%
https://arxiv.org/pdf/2301.13731.pdf,A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser,Samuel Hurault,,0%
https://arxiv.org/pdf/2301.13731.pdf,A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser,Antonin Chambolle,,0%
https://arxiv.org/pdf/2301.13731.pdf,A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser,Arthur Leclaire,,0%
https://arxiv.org/pdf/2301.13731.pdf,A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser,Nicolas Papadakis,,0%
https://arxiv.org/pdf/2301.13721.pdf,DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models,Tao Yang,wang-yuwang@mail.tsinghua.edu.cn,85%
https://arxiv.org/pdf/2301.13721.pdf,DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models,Nanning Zheng,nnzheng@mail.xjtu.edu.cn,82%
https://arxiv.org/pdf/2301.13721.pdf,DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models,Yuwang Wang,,0%
https://arxiv.org/pdf/2301.13721.pdf,DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models,Yan Lv,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Eva Schnider,eva.schnider@unibas.ch,95%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Julia Wolleb,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Antal Huck,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Mireille Toranelli,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Georg Rauter,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Magdalena Müller-gerbl,,0%
https://arxiv.org/pdf/2301.13674.pdf,Improved distinct bone segmentation in upper-body CT through multi-resolution networks,Philippe C. Cattin,,0%
https://arxiv.org/pdf/2301.13670.pdf,What Makes Good Examples for Visual In-Context Learning?,Ziwei Liu,ziwei.liu@ntu.edu.sg,95%
https://arxiv.org/pdf/2301.13670.pdf,What Makes Good Examples for Visual In-Context Learning?,Yuanhan Zhang,,0%
https://arxiv.org/pdf/2301.13670.pdf,What Makes Good Examples for Visual In-Context Learning?,Kaiyang Zhou,,0%
https://arxiv.org/pdf/2301.13659.pdf,Spyker: High-performance Library for Spiking Deep Neural Networks,Shahriar Rezghi Shirsavar,shahriar.rezghi@ut.ac.ir,85%
https://arxiv.org/pdf/2301.13659.pdf,Spyker: High-performance Library for Spiking Deep Neural Networks,Mohammad-reza A. Dehaqani,dehaqani@ut.ac.ir,78%
https://arxiv.org/pdf/2301.13656.pdf,A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds,Raphael Sulzer,raphaelsulzer@gmx.de,95%
https://arxiv.org/pdf/2301.13656.pdf,A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds,Renaud Marlet,,0%
https://arxiv.org/pdf/2301.13656.pdf,A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds,Bruno Vallet,,0%
https://arxiv.org/pdf/2301.13656.pdf,A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds,Loic Landrieu,,0%
https://arxiv.org/pdf/2301.13622.pdf,Learning Data Representations with Joint Diffusion Models,Kamil Deja,kamil.deja@pw.edu.pl,95%
https://arxiv.org/pdf/2301.13622.pdf,Learning Data Representations with Joint Diffusion Models,Tomasz Trzcinski,tomasz.trzcinski@pw.edu.pl,95%
https://arxiv.org/pdf/2301.13622.pdf,Learning Data Representations with Joint Diffusion Models,Jakub M. Tomczak,j.m.tomczak@tue.nl,82%
https://arxiv.org/pdf/2301.13592.pdf,Priors are Powerful: Improving a Transformer for Multi-camera 3D Detection with 2D Priors,Di Feng,fengdi1015@gmail.com,95%
https://arxiv.org/pdf/2301.13592.pdf,Priors are Powerful: Improving a Transformer for Multi-camera 3D Detection with 2D Priors,Francesco Ferroni,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Boris Mansencal,mediaeval.sport.task@diff.u-bordeaux.fr,70%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Pierre-etienne Martin,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Jordan Calandre,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Jenny Benois-pineau,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Renaud Péteri,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Laurent Mascarilla,,0%
https://arxiv.org/pdf/2301.13576.pdf,Sport Task: Fine Grained Action Detection and Classification of Table Tennis Strokes from Videos for MediaEval 2022,Julien Morlier,,0%
https://arxiv.org/pdf/2301.13569.pdf,NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning,Thomas Lukasiewicz,thomas.lukasiewicz@cs.ox.ac.uk,95%
https://arxiv.org/pdf/2301.13569.pdf,NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning,Xiaolin Hu,xlhu@tsinghua.edu.cn,82%
https://arxiv.org/pdf/2301.13569.pdf,NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning,Jianfeng Wang,jianfeng.wang@cs.ox.ac.uk,95%
https://arxiv.org/pdf/2302.00487.pdf,"A Comprehensive Survey of Continual Learning: Theory, Method and Application",Hang Su,suhangss@tsinghua.edu.cn,95%
https://arxiv.org/pdf/2302.00487.pdf,"A Comprehensive Survey of Continual Learning: Theory, Method and Application",Liyuan Wang,,0%
https://arxiv.org/pdf/2302.00487.pdf,"A Comprehensive Survey of Continual Learning: Theory, Method and Application",Xingxing Zhang,,0%
https://arxiv.org/pdf/2302.00487.pdf,"A Comprehensive Survey of Continual Learning: Theory, Method and Application",Jun Zhu,,0%
https://arxiv.org/pdf/2301.13558.pdf,Lidar Upsampling with Sliced Wasserstein Distance,Federico Tombar,tombari@in.tum.de,78%
https://arxiv.org/pdf/2301.13558.pdf,Lidar Upsampling with Sliced Wasserstein Distance,Artem Savkin,artem.savkin@tum.de,95%
https://arxiv.org/pdf/2301.13558.pdf,Lidar Upsampling with Sliced Wasserstein Distance,Yida Wang,,0%
https://arxiv.org/pdf/2301.13558.pdf,Lidar Upsampling with Sliced Wasserstein Distance,Sebastian Wirkert,,0%
https://arxiv.org/pdf/2301.13558.pdf,Lidar Upsampling with Sliced Wasserstein Distance,Nassir Navab,,0%
https://arxiv.org/pdf/2301.13554.pdf,NoiseTransfer: Image Noise Generation with Contrastive Embeddings,Seunghwan Lee,seunghwanlee@hanyang.ac.kr,95%
https://arxiv.org/pdf/2301.13554.pdf,NoiseTransfer: Image Noise Generation with Contrastive Embeddings,Tae Hyun Kim,taehyunkim@hanyang.ac.kr,95%
https://arxiv.org/pdf/2301.13549.pdf,Review of methods for automatic cerebral microbleeds detection,Michał Grochowski,michal.grochowski@pg.edu.pl,82%
https://arxiv.org/pdf/2301.13549.pdf,Review of methods for automatic cerebral microbleeds detection,Zuzanna Klawikowska,zuzanna.klawikowska@pg.edu.pl,95%
https://arxiv.org/pdf/2301.13549.pdf,Review of methods for automatic cerebral microbleeds detection,Maria Ferlin,maria.ferlin@pg.edu.pl,95%
https://arxiv.org/pdf/2301.13549.pdf,Review of methods for automatic cerebral microbleeds detection,Edyta Szurowska,eszurowska@gumed.edu.pl,82%
https://arxiv.org/pdf/2301.13549.pdf,Review of methods for automatic cerebral microbleeds detection,Małgorzata Grzywińska,,0%
https://arxiv.org/pdf/2301.13538.pdf,AMD: Adaptive Masked Distillation for Object Detection,Jun Li,lijuncst@njnu.edu.cn,95%
https://arxiv.org/pdf/2301.13538.pdf,AMD: Adaptive Masked Distillation for Object Detection,Guang Yang,,0%
https://arxiv.org/pdf/2301.13538.pdf,AMD: Adaptive Masked Distillation for Object Detection,Yin Tang,,0%
https://arxiv.org/pdf/2301.13538.pdf,AMD: Adaptive Masked Distillation for Object Detection,Jianhua Xu,,0%
https://arxiv.org/pdf/2301.13538.pdf,AMD: Adaptive Masked Distillation for Object Detection,Xili Wan,,0%
https://arxiv.org/pdf/2301.13530.pdf,Domain-Generalizable Multiple-Domain Clustering,Ofir Lindenbaum,ofirlin@gmail.com,85%
https://arxiv.org/pdf/2301.13530.pdf,Domain-Generalizable Multiple-Domain Clustering,Amit Rozner,,0%
https://arxiv.org/pdf/2301.13530.pdf,Domain-Generalizable Multiple-Domain Clustering,Barak Battash,,0%
https://arxiv.org/pdf/2301.13530.pdf,Domain-Generalizable Multiple-Domain Clustering,Lior Wolf,,0%
https://arxiv.org/pdf/2301.13514.pdf,Fourier Sensitivity and Regularization of Computer Vision Models,Chuan-sheng Foo,foo_chuan_sheng@i2r.a-star.edu.sg,95%
https://arxiv.org/pdf/2301.13514.pdf,Fourier Sensitivity and Regularization of Computer Vision Models,Kiran Krishnamachari,kirank@u.nus.edu,85%
https://arxiv.org/pdf/2301.13514.pdf,Fourier Sensitivity and Regularization of Computer Vision Models,See-kiong Ng,seekiong@nus.edu.sg,95%
https://arxiv.org/pdf/2301.13510.pdf,3D Former: Monocular Scene Reconstruction with 3D SDF Transformers,Siyu Zhu,siting.zsy@alibaba-inc.com,60%
https://arxiv.org/pdf/2301.13510.pdf,3D Former: Monocular Scene Reconstruction with 3D SDF Transformers,Weihao Yuan,,0%
https://arxiv.org/pdf/2301.13510.pdf,3D Former: Monocular Scene Reconstruction with 3D SDF Transformers,Xiaodong Gu,,0%
https://arxiv.org/pdf/2301.13510.pdf,3D Former: Monocular Scene Reconstruction with 3D SDF Transformers,Heng Li,,0%
https://arxiv.org/pdf/2301.13510.pdf,3D Former: Monocular Scene Reconstruction with 3D SDF Transformers,Zilong Dong,,0%
https://arxiv.org/pdf/2301.13504.pdf,Transfer Learning and Class Decomposition for Detecting the Cognitive Decline of Alzheimer Disease,Maha M. Alwuthaynani,maha.alwuthaynani@bristol.ac.uk,95%
https://arxiv.org/pdf/2301.13504.pdf,Transfer Learning and Class Decomposition for Detecting the Cognitive Decline of Alzheimer Disease,Zahraa S. Abdallah,zahraa.abdallah@bristol.ac.uk,95%
https://arxiv.org/pdf/2301.13504.pdf,Transfer Learning and Class Decomposition for Detecting the Cognitive Decline of Alzheimer Disease,Raul Santos-rodriguez,,0%
https://arxiv.org/pdf/2301.13487.pdf,Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,Zhiyuan Cheng,cheng443@purdue.edu,78%
https://arxiv.org/pdf/2301.13487.pdf,Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,Xiangyu Zhang,xyzhang@cs.purdue.edu,82%
https://arxiv.org/pdf/2301.13487.pdf,Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,Guanhong Tao,taog@purdue.edu,78%
https://arxiv.org/pdf/2301.13487.pdf,Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,Dongfang Liu,dongfang.liu@rit.edu,95%
https://arxiv.org/pdf/2301.13487.pdf,Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,James Liang,,0%
https://arxiv.org/pdf/2301.13473.pdf,CRC-RL: A Novel Visual Feature Representation Architecture for Unsupervised Reinforcement Learning,Swagat Kumar,kumars@edgehill.ac.uk,78%
https://arxiv.org/pdf/2301.13473.pdf,CRC-RL: A Novel Visual Feature Representation Architecture for Unsupervised Reinforcement Learning,Darshita Jain,,0%
https://arxiv.org/pdf/2301.13473.pdf,CRC-RL: A Novel Visual Feature Representation Architecture for Unsupervised Reinforcement Learning,Anima Majumder,,0%
https://arxiv.org/pdf/2301.13473.pdf,CRC-RL: A Novel Visual Feature Representation Architecture for Unsupervised Reinforcement Learning,Samrat Dutta,,0%
https://arxiv.org/pdf/2301.13459.pdf,Learning Generalized Hybrid Proximity Representation for Image Recognition,Anca Ralescu,ralescal@ucmail.uc.edu,65%
https://arxiv.org/pdf/2301.13459.pdf,Learning Generalized Hybrid Proximity Representation for Image Recognition,Zhiyuan Li,li3z3@mail.uc.edu,78%
https://arxiv.org/pdf/2303.08105.pdf,Image Guidance for Robot-Assisted Ankle Fracture Repair,Asef Islam,,0%
https://arxiv.org/pdf/2303.08105.pdf,Image Guidance for Robot-Assisted Ankle Fracture Repair,Anthony Wu,,0%
https://arxiv.org/pdf/2303.08105.pdf,Image Guidance for Robot-Assisted Ankle Fracture Repair,Jay Mandavilli,,0%
https://arxiv.org/pdf/2303.08105.pdf,Image Guidance for Robot-Assisted Ankle Fracture Repair,Wojtek Zbijewski,,0%
https://arxiv.org/pdf/2303.08105.pdf,Image Guidance for Robot-Assisted Ankle Fracture Repair,Jeff Siewerdsen,,0%
https://arxiv.org/pdf/2301.13445.pdf,A Survey of Explainable AI in Deep Visual Modeling: Methods and Metrics,Naveed Akhtar,naveed.akhtar@uwa.edu.au,95%
https://arxiv.org/pdf/2301.13444.pdf,Rethinking Soft Label in Label Distribution Learning Perspective,Min-kook Choi,mkchoi@hutom.io,82%
https://arxiv.org/pdf/2301.13444.pdf,Rethinking Soft Label in Label Distribution Learning Perspective,Seungbum Hong,,0%
https://arxiv.org/pdf/2301.13444.pdf,Rethinking Soft Label in Label Distribution Learning Perspective,Jihun Yoon,,0%
https://arxiv.org/pdf/2301.13444.pdf,Rethinking Soft Label in Label Distribution Learning Perspective,Bogyu Park,,0%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Jinzheng He,jinzhenghe@zju.edu.cn,95%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Zhenhui Ye,zhenhuiye@zju.edu.cn,95%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Jinglin Liu,jinglinliu@zju.edu.cn,95%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Ziyue Jiang,jiangziyue@zju.edu.cn,95%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Zhou Zhao,zhaozhou@zju.edu.cn,95%
https://arxiv.org/pdf/2301.13430.pdf,GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis,Yi Ren,ren.yi@bytedance.com,95%
https://arxiv.org/pdf/2301.13428.pdf,Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation,Yonggang Li,liyonggang@zjxu.edu.cn,95%
https://arxiv.org/pdf/2301.13428.pdf,Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation,Xiangbin Zhu,zhuxb@zjnu.cn,78%
https://arxiv.org/pdf/2301.13428.pdf,Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation,Yingjian Li,liyingjian@zjnu.edu.cn,95%
https://arxiv.org/pdf/2301.13428.pdf,Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation,Yuqi Chen,,0%
https://arxiv.org/pdf/2301.13428.pdf,Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation,Haojie Fang,,0%
https://arxiv.org/pdf/2301.13422.pdf,Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors,Jingtao Li,JingtaoLi@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13422.pdf,Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors,Hengwei Zhao,whu_zhaohw@whu.edu.cn,78%
https://arxiv.org/pdf/2301.13422.pdf,Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors,Yanfei Zhong,zhongyanfei@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13422.pdf,Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors,Xinyu Wang,wangxinyu@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13422.pdf,Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors,Shaoyu Wang,wangshaoyu@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Jiayi Yuan,jiayiyuan@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Jianjun Qian,csjqian@njust.edu.cn,78%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Jun Li,junli@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Xiang Li,xiang.li.implus@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Jian Yang,jiang.hao.bo@njust.edu.cn,85%
https://arxiv.org/pdf/2301.13419.pdf,Recurrent Structure Attention Guidance for Depth Super-Resolution,Haobo Jiang,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Chong Wang,chong.wang@adelaide.edu.au,95%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Yuanhong Chen,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Yuyuan Liu,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Michael Elliott,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Chun Fung Kwok,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Carlos Pena-solorzano,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Yu Tian,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Fengbei Liu,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Helen Frazer,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Davis J. Mccarthy,,0%
https://arxiv.org/pdf/2301.13418.pdf,BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations,Gustavo Carneiro,,0%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Jiayi Yuan,jiayiyuan@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Jianjun Qian,csjqian@njust.edu.cn,78%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Jun Li,junli@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Xiang Li,xiang.li.implus@njust.edu.cn,95%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Jian Yang,jiang.hao.bo@njust.edu.cn,85%
https://arxiv.org/pdf/2301.13416.pdf,Structure Flow-Guided Network for Real Depth Super-Resolution,Haobo Jiang,,0%
https://arxiv.org/pdf/2301.13411.pdf,Few-Shot Object Detection via Variational Feature Aggregation,Ke Yan,kerwinyan@tencent.com,95%
https://arxiv.org/pdf/2301.13411.pdf,Few-Shot Object Detection via Variational Feature Aggregation,Jiaming Han,hanjiaming@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13411.pdf,Few-Shot Object Detection via Variational Feature Aggregation,Yuqiang Ren,condiren@tencent.com,78%
https://arxiv.org/pdf/2301.13411.pdf,Few-Shot Object Detection via Variational Feature Aggregation,Gui-song Xia,guisong.xia@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13411.pdf,Few-Shot Object Detection via Variational Feature Aggregation,Jian Ding,jian.ding@whu.edu.cn,95%
https://arxiv.org/pdf/2301.13403.pdf,A Modular Multi-stage Lightweight Graph Transformer Network for Human Pose and Shape Estimation from 2D Human Pose,Mohsen Dorodchi,mdorodch@uncc.edu,90%
https://arxiv.org/pdf/2301.13403.pdf,A Modular Multi-stage Lightweight Graph Transformer Network for Human Pose and Shape Estimation from 2D Human Pose,Ayman Ali,,0%
https://arxiv.org/pdf/2301.13403.pdf,A Modular Multi-stage Lightweight Graph Transformer Network for Human Pose and Shape Estimation from 2D Human Pose,Ekkasit Pinyoanuntapong,,0%
https://arxiv.org/pdf/2301.13403.pdf,A Modular Multi-stage Lightweight Graph Transformer Network for Human Pose and Shape Estimation from 2D Human Pose,Pu Wang,,0%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Bingchuan Li,libingchuan@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Qian He,heqian@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Peng Zhang,zhangpeng.ucas@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Wei Liu,liuwei.jikun@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Tianxiang Ma,matianxiang.724@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Miao Hua,huamiao@bytedance.com,95%
https://arxiv.org/pdf/2301.13402.pdf,ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing,Zili Yi,yizili@bytedance.com,95%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Chung-i Huang,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Wei-yu Chen,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Wei Jan Ko,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Jih-sheng Chang,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Chen-kai Sun,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Hui Hung Yu,,0%
https://arxiv.org/pdf/2301.13385.pdf,Fisheye traffic data set of point center markers,Fang-pang Lin,,0%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Minwoo Lee,minwoo.lee@uncc.edu,95%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Zhi Sun,qzhisun@tsinghua.edu.cn,95%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Ekkasit Pinyoanuntapong,epinyoan@uncc.edu,90%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Chen Chen,chen.chen@crcv.ucf.edu,95%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Pu Wang,pwang13@uncc.edu,82%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Ayman Ali,aali26@uncc.edu,82%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Kalvik Jakkala,kjakkala@uncc.edu,82%
https://arxiv.org/pdf/2301.13384.pdf,GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition,Qucheng Peng,qucheng.peng@knights.ucf.edu,95%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Li Yi,jli3779@uwo.ca,85%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Boyu Wang,bwang@csd.uwo.ca,82%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Pengcheng Xu,pxu67@uwo.ca,82%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Ruizhi Pu,rpu2@uwo.ca,82%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,A. Ian Mcleod,aimcleod@uwo.ca,82%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Charles Ling,charles.ling@uwo.ca,95%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Gezheng Xu,gxu86@uwo.ca,82%
https://arxiv.org/pdf/2301.13381.pdf,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,Jiaqi Li,,0%
https://arxiv.org/pdf/2301.13376.pdf,Quantized Neural Networks for Low-Precision Accumulation with Guaranteed Overflow Avoidance,Ian Colbert,ian.colbert@amd.com,95%
https://arxiv.org/pdf/2301.13376.pdf,Quantized Neural Networks for Low-Precision Accumulation with Guaranteed Overflow Avoidance,Alessandro Pappalardo,,0%
https://arxiv.org/pdf/2301.13376.pdf,Quantized Neural Networks for Low-Precision Accumulation with Guaranteed Overflow Avoidance,Jakoba Petri-koenig,,0%
https://arxiv.org/pdf/2301.13371.pdf,Demystifying Disagreement-on-the-Line in High Dimensions,Hamed Hassani,hassani@seas.upenn.edu,82%
https://arxiv.org/pdf/2301.13371.pdf,Demystifying Disagreement-on-the-Line in High Dimensions,Xinmeng Huang,xinmengh@sas.upenn.edu,85%
https://arxiv.org/pdf/2301.13371.pdf,Demystifying Disagreement-on-the-Line in High Dimensions,Behrad Moniri,bemoniri@seas.upenn.edu,82%
https://arxiv.org/pdf/2301.13371.pdf,Demystifying Disagreement-on-the-Line in High Dimensions,Edgar Dobriban,dobriban@wharton.upenn.edu,78%
https://arxiv.org/pdf/2301.13371.pdf,Demystifying Disagreement-on-the-Line in High Dimensions,Donghwan Lee,,0%
https://arxiv.org/pdf/2301.13366.pdf,CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects,Murray Loew,loew@gwu.edu,78%
https://arxiv.org/pdf/2301.13366.pdf,CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects,Shuyue Guan,frankshuyueguan@gwu.edu,95%
https://arxiv.org/pdf/2301.13366.pdf,CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects,Ange Lou,ange.lou@vanderbilt.edu,95%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Yi Zhu,zhuyi36@huawei.com,95%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Jianzhuang Liu,liu.jianzhuang@huawei.com,95%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Pengzhen Ren,pzhren@foxmail.com,82%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Guangrun Wang,wanggrun@gmail.com,78%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Changlin Li,changlinli.ai@gmail.com,95%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Xiaodan Liang,xdliang328@gmail.com,82%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Xiaojun Chang,xiaojun.chang@uts.edu.au,95%
https://arxiv.org/pdf/2302.10307.pdf,ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency,Hang Xu,xu.hang@huawei.com,95%
https://arxiv.org/pdf/2301.13361.pdf,Iterative Loop Method Combining Active and Semi-Supervised Learning for Domain Adaptive Semantic Segmentation,Xue Yuan,xyuan@bjtu.edu.cn,82%
https://arxiv.org/pdf/2301.13361.pdf,Iterative Loop Method Combining Active and Semi-Supervised Learning for Domain Adaptive Semantic Segmentation,Licong Guan,,0%
https://arxiv.org/pdf/2301.13360.pdf,Skeleton-based Human Action Recognition via Convolutional Neural Networks (CNN),Mohsen Dorodchi,mdorodch@uncc.edu,90%
https://arxiv.org/pdf/2301.13360.pdf,Skeleton-based Human Action Recognition via Convolutional Neural Networks (CNN),Ayman Ali,,0%
https://arxiv.org/pdf/2301.13360.pdf,Skeleton-based Human Action Recognition via Convolutional Neural Networks (CNN),Ekkasit Pinyoanuntapong,,0%
https://arxiv.org/pdf/2301.13360.pdf,Skeleton-based Human Action Recognition via Convolutional Neural Networks (CNN),Pu Wang,,0%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Jinbao Wang,jasoncjwang@tencent.com,82%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Yaochu Jin,jinyaochu@westlake.edu.cn,95%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Jiaqi Liu,chaosliu@tencent.com,78%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Jiayi Lyu,lyujiayi21@mails.ucas.ac.cn,95%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Feng Zheng,f.zheng@ieee.org,82%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Guoyang Xie,guoyang.xie@ieee.org,95%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Yong Liu,,0%
https://arxiv.org/pdf/2301.13359.pdf,IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing,Chengjie Wang,,0%
https://arxiv.org/pdf/2301.13358.pdf,Hierarchical Disentangled Representation for Invertible Image Denoising and Beyond,Hu Chen,huchen@scu.edu.cn,95%
https://arxiv.org/pdf/2301.13358.pdf,Hierarchical Disentangled Representation for Invertible Image Denoising and Beyond,Yi Zhang,yzhang@scu.edu.cn,82%
https://arxiv.org/pdf/2301.13358.pdf,Hierarchical Disentangled Representation for Invertible Image Denoising and Beyond,Wenchao Du,wenchaodu.scu@gmail.com,95%
https://arxiv.org/pdf/2301.13358.pdf,Hierarchical Disentangled Representation for Invertible Image Denoising and Beyond,H. Yang,yanghongyu@scu.edu.cn,78%
https://arxiv.org/pdf/2301.13356.pdf,Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,Hugo Lemarchant,hugo@is.ids.osaka-u.ac.jp,85%
https://arxiv.org/pdf/2301.13356.pdf,Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,Yuta Nakashima,n-yuta@ids.osaka-u.ac.jp,85%
https://arxiv.org/pdf/2301.13356.pdf,Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,Hajime Nagahara,nagahara@ids.osaka-u.ac.jp,78%
https://arxiv.org/pdf/2301.13356.pdf,Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,Yiming Qian,yimingqian@ids.osaka-u.ac.jp,95%
https://arxiv.org/pdf/2301.13356.pdf,Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,Liangzi Li,li@ids.osaka-u.ac.jp,82%
https://arxiv.org/pdf/2301.13343.pdf,Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning,Jun Sakuma,jun@cs.tsukuba.ac.jp,85%
https://arxiv.org/pdf/2301.13343.pdf,Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning,Rei Sato,reisato@bbo.cs.tsukuba.ac.jp,95%
https://arxiv.org/pdf/2301.13343.pdf,Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning,Kazuto Fukuchi,fukuchi@cs.tsukuba.ac.jp,78%
https://arxiv.org/pdf/2301.13343.pdf,Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning,Youhei Akimoto,akimoto@cs.tsukuba.ac.jp,78%
https://arxiv.org/pdf/2301.13338.pdf,Continuous Spatiotemporal Transformers,David Van Dijk,david.vandijk@yale.edu,95%
https://arxiv.org/pdf/2301.13338.pdf,Continuous Spatiotemporal Transformers,Antonio H. De O. Fonseca,,0%
https://arxiv.org/pdf/2301.13338.pdf,Continuous Spatiotemporal Transformers,Emanuele Zappala,,0%
https://arxiv.org/pdf/2301.13338.pdf,Continuous Spatiotemporal Transformers,Josue Ortega Caro,,0%
https://arxiv.org/pdf/2301.13335.pdf,Multi-modal Large Language Model Enhanced Pseudo 3D Perception Framework for Visual Commonsense Reasoning,Jian Zhu,jianzhu@tongji.edu.cn,95%
https://arxiv.org/pdf/2301.13335.pdf,Multi-modal Large Language Model Enhanced Pseudo 3D Perception Framework for Visual Commonsense Reasoning,Miaojing Shi,mshi@tongji.edu.cn,82%
https://arxiv.org/pdf/2301.13335.pdf,Multi-modal Large Language Model Enhanced Pseudo 3D Perception Framework for Visual Commonsense Reasoning,Hanli Wang,hanliwang@tongji.edu.cn,95%
https://arxiv.org/pdf/2301.13330.pdf,"Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference",Deepika Bablani,deepika.bablani@ibm.com,95%
https://arxiv.org/pdf/2301.13330.pdf,"Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference",Jeffrey L. Mckinstry,,0%
https://arxiv.org/pdf/2301.13330.pdf,"Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference",Steven K. Esser,,0%
https://arxiv.org/pdf/2301.13330.pdf,"Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference",Rathinakumar Appuswamy,,0%
https://arxiv.org/pdf/2301.13330.pdf,"Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference",Dharmendra S. Modha,,0%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Klaus H. Maier-hein,klaus.maier-hein@dkfz-heidelberg.de,95%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Karol Gotkowski,karol.gotkowski@dkfz.de,95%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Shuvam Gupta,c.guimaraes-da-silva-tochtrop@hzdr.de,85%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Jose R. A. Godinho,j.godinho@hzdr.de,82%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Fabian Isensee,f.isensee@dkfz-heidelberg.de,82%
https://arxiv.org/pdf/2301.13319.pdf,ParticleSeg3D: A Scalable Out-of-the-Box Deep Learning Segmentation Solution for Individual Particle Characterization from Micro CT Images in Mineral Processing and Recycling,Camila G. S. Tochtrop,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Erik Wijmans,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Manolis Savva,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Irfan Essa,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Stefan Lee,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Ari S. Morcos,,0%
https://arxiv.org/pdf/2301.13261.pdf,Emergence of Maps in the Memories of Blind Navigation Agents,Dhruv Batra,,0%
https://arxiv.org/pdf/2301.13254.pdf,Deep Monocular Hazard Detection for Safe Small Body Landing,Travis Driver,,0%
https://arxiv.org/pdf/2301.13254.pdf,Deep Monocular Hazard Detection for Safe Small Body Landing,Kento Tomita,,0%
https://arxiv.org/pdf/2301.13254.pdf,Deep Monocular Hazard Detection for Safe Small Body Landing,Koki Ho,,0%
https://arxiv.org/pdf/2301.13254.pdf,Deep Monocular Hazard Detection for Safe Small Body Landing,Panagiotis Tsiotras,,0%
https://arxiv.org/pdf/2301.13244.pdf,Mono-STAR: Mono-camera Scene-level Tracking and Reconstruction,Haonan Chang,,0%
https://arxiv.org/pdf/2301.13244.pdf,Mono-STAR: Mono-camera Scene-level Tracking and Reconstruction,Dhruv Metha Ramesh,,0%
https://arxiv.org/pdf/2301.13244.pdf,Mono-STAR: Mono-camera Scene-level Tracking and Reconstruction,Shijie Geng,,0%
https://arxiv.org/pdf/2301.13244.pdf,Mono-STAR: Mono-camera Scene-level Tracking and Reconstruction,Yuqiu Gan,,0%
https://arxiv.org/pdf/2301.13244.pdf,Mono-STAR: Mono-camera Scene-level Tracking and Reconstruction,Abdeslam Boularias,,0%
https://arxiv.org/pdf/2301.13197.pdf,Unlocking Slot Attention by Changing Optimal Transport Costs,Yan Zhang,yan@cyan.zone,85%
https://arxiv.org/pdf/2301.13197.pdf,Unlocking Slot Attention by Changing Optimal Transport Costs,David W. Zhang,,0%
https://arxiv.org/pdf/2301.13197.pdf,Unlocking Slot Attention by Changing Optimal Transport Costs,Simon Lacoste-julien,,0%
https://arxiv.org/pdf/2301.13197.pdf,Unlocking Slot Attention by Changing Optimal Transport Costs,Gertjan J. Burghouts,,0%
https://arxiv.org/pdf/2301.13197.pdf,Unlocking Slot Attention by Changing Optimal Transport Costs,Cees G. M. Snoek,,0%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Fuzhao Xue,xuefuzhao24@gmail.com,95%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Mostafa Dehghani,dehghani@google.com,78%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Valerii Likhosherstov,,0%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Anurag Arnab,,0%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Neil Houlsby,,0%
https://arxiv.org/pdf/2301.13195.pdf,Adaptive Computation with Elastic Input Sequence,Yang You,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Yiran Zhong,zhongyiran@gmail.com,95%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Meng Wang,eric.mengwang@gmail.com,95%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Jinxing Zhou,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Xuyang Shen,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Jianyuan Wang,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Jiayi Zhang,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Weixuan Sun,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Jing Zhang,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Stan Birchfield,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Dan Guo,,0%
https://arxiv.org/pdf/2301.13190.pdf,Audio-Visual Segmentation with Semantics,Lingpeng Kong,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Nicholas Carlini,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Jamie Hayes,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Milad Nasr,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Matthew Jagielski,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Vikash Sehwag,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Florian Tramèr,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Borja Balle,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Daphne Ippolito,,0%
https://arxiv.org/pdf/2301.13188.pdf,Extracting Training Data from Diffusion Models,Eric Wallace,,0%
https://arxiv.org/pdf/2301.13186.pdf,Accurate Gaze Estimation using an Active-gaze Morphable Model,Hao Sun,,0%
https://arxiv.org/pdf/2301.13186.pdf,Accurate Gaze Estimation using an Active-gaze Morphable Model,Nick Pears,,0%
https://arxiv.org/pdf/2301.13173.pdf,Shape-aware Text-driven Layered Video Editing,Yao-chih Lee,,0%
https://arxiv.org/pdf/2301.13173.pdf,Shape-aware Text-driven Layered Video Editing,Ji-ze Genevieve Jang,,0%
https://arxiv.org/pdf/2301.13173.pdf,Shape-aware Text-driven Layered Video Editing,Yi-ting Chen,,0%
https://arxiv.org/pdf/2301.13173.pdf,Shape-aware Text-driven Layered Video Editing,Elizabeth Qiu,,0%
https://arxiv.org/pdf/2301.13173.pdf,Shape-aware Text-driven Layered Video Editing,Jia-bin Huang,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Xin Eric Wang,xwang366@ucsc.edu,82%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Kaiwen Zhou,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Kaizhi Zheng,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Connor Pryor,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Yilin Shen,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Hongxia Jin,,0%
https://arxiv.org/pdf/2301.13166.pdf,ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation,Lise Getoor,,0%
https://arxiv.org/pdf/2301.13156.pdf,SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,Li Zhang,lizhangfd@fudan.edu.cn,95%
https://arxiv.org/pdf/2301.13156.pdf,SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,Qiang Wan,,0%
https://arxiv.org/pdf/2301.13156.pdf,SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,Zilong Huang,,0%
https://arxiv.org/pdf/2301.13156.pdf,SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,Jiachen Lu,,0%
https://arxiv.org/pdf/2301.13156.pdf,SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,Gang Yu,,0%
https://arxiv.org/pdf/2301.13155.pdf,Advancing Radiograph Representation Learning with Masked Record Modeling,Hong-yu Zhou,whuzhouhongyu@gmail.com,95%
https://arxiv.org/pdf/2301.13155.pdf,Advancing Radiograph Representation Learning with Masked Record Modeling,Chenyu Lian,cylian@stu.xmu.edu.cn,82%
https://arxiv.org/pdf/2301.13155.pdf,Advancing Radiograph Representation Learning with Masked Record Modeling,Liansheng Wang,lswang@xmu.edu.cn,82%
https://arxiv.org/pdf/2301.13155.pdf,Advancing Radiograph Representation Learning with Masked Record Modeling,Yizhou Yu,yizhouy@acm.org,85%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Duaa Alsaeed,dalsaeed@ksu.edu.sa,82%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Remy Peyret,,0%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Fouad Khelifi,,0%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Nadia Al-ghreimil,,0%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Heyam Al-baity,,0%
https://arxiv.org/pdf/2301.13151.pdf,Convolutional Neural Network-Based Automatic Classification of Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System Development Study,Ahmed Bouridane,,0%
https://arxiv.org/pdf/2301.13141.pdf,Consistency Regularisation in Varying Contexts and Feature Perturbations for Semi-Supervised Semantic Segmentation of Histology Images,Talha Qaiser,talha.qaiser@warwick.ac.uk,95%
https://arxiv.org/pdf/2301.13141.pdf,Consistency Regularisation in Varying Contexts and Feature Perturbations for Semi-Supervised Semantic Segmentation of Histology Images,Shan E Ahmed Raza,shan.raza@warwick.ac.uk,95%
https://arxiv.org/pdf/2301.13141.pdf,Consistency Regularisation in Varying Contexts and Feature Perturbations for Semi-Supervised Semantic Segmentation of Histology Images,Raja Muhammad Saad Bashir,saad.bashir@warwick.ac.uk,78%
https://arxiv.org/pdf/2301.13141.pdf,Consistency Regularisation in Varying Contexts and Feature Perturbations for Semi-Supervised Semantic Segmentation of Histology Images,Nasir M. Rajpoot,n.m.rajpoot@warwick.ac.uk,82%
https://arxiv.org/pdf/2301.13128.pdf,Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology,Nicolas Nerrienet,nicolas.n@primaalab.com,85%
https://arxiv.org/pdf/2301.13128.pdf,Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology,Rémy Peyret,,0%
https://arxiv.org/pdf/2301.13128.pdf,Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology,Marie Sockeel,,0%
https://arxiv.org/pdf/2301.13128.pdf,Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology,Stéphane Sockeel,,0%
https://arxiv.org/pdf/2301.13104.pdf,Equivariant Differentially Private Deep Learning: Why DP-SGD Needs Sparser Models,Florian A. Hölzl,florian.hoelzl@tum.de,85%
https://arxiv.org/pdf/2301.13104.pdf,Equivariant Differentially Private Deep Learning: Why DP-SGD Needs Sparser Models,Georgios Kaissis,g.kaissis@tum.de,82%
https://arxiv.org/pdf/2301.13104.pdf,Equivariant Differentially Private Deep Learning: Why DP-SGD Needs Sparser Models,Daniel Rueckert,daniel.rueckert@tum.de,95%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Mengyun Qiao,m.qiao21@imperial.ac.uk,82%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Shuo Wang,,0%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Huaqi Qiu,,0%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Antonio De Marvao,,0%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Declan P. O'regan,,0%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Daniel Rueckert,,0%
https://arxiv.org/pdf/2301.13098.pdf,CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy,Wenjia Bai,,0%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Zhanhao Hu,huzhanha17@mails.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Xiaolin Hu,xlhu@mail.tsinghua.edu.cn,82%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Wei Zhang,zhang-w19@mails.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Xiao Li,lixiao20@mails.tsinghua.edu.cn,95%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Yining Liu,,0%
https://arxiv.org/pdf/2301.13096.pdf,Language-Driven Anchors for Zero-Shot Adversarial Robustness,Bo Zhang,,0%
https://arxiv.org/pdf/2301.13090.pdf,Action Capsules: Human Skeleton Action Recognition,Hamid D. Taghirad,taghirad@kntu.ac.ir,78%
https://arxiv.org/pdf/2301.13090.pdf,Action Capsules: Human Skeleton Action Recognition,Ali Farajzadeh Bavil,,0%
https://arxiv.org/pdf/2301.13090.pdf,Action Capsules: Human Skeleton Action Recognition,Hamed Damirchi,,0%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Yisheng Yuan,y.yuan@hw.ac.uk,82%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Zhang Luo,luozhang@seafogai.com,95%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Yang Xu,yang.xu@sdsu.edu,95%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Yue Wang,wang.yue.f07@kyoto-u.jp,95%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Wei Pang,w.pang@hw.ac.uk,82%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Zuhao Yang,,0%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Huajun Bai,,0%
https://arxiv.org/pdf/2301.13082.pdf,PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy,Yingfang Yuan,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Yinfei Yang,feiy@apple.com,90%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Bowen Zhang,zhang4@apple.com,78%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Chen Chen,chen999@apple.com,95%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Liangliang Cao,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Jiguang Shen,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Tom Gunter,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Albin Madappally Jose,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Alexander Toshev,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Jonathon Shlens,,0%
https://arxiv.org/pdf/2301.13081.pdf,STAIR: Learning Sparse Text and Image Representation in Grounded Tokens,Ruoming Pang,,0%
https://arxiv.org/pdf/2301.13018.pdf,DELTA: degradation-free fully test-time adaptation,Shu-tao Xia,xiast@sz.tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.13018.pdf,DELTA: degradation-free fully test-time adaptation,Chen Chen,chen1634chen@gmail.com,95%
https://arxiv.org/pdf/2301.13018.pdf,DELTA: degradation-free fully test-time adaptation,Bowen Zhao,,0%
https://arxiv.org/pdf/2301.12995.pdf,FedFA: Federated Feature Augmentation,Ender Konukoglu,kender@vision.ee.ethz.ch,85%
https://arxiv.org/pdf/2301.12995.pdf,FedFA: Federated Feature Augmentation,Tianfei Zhou,tiazhou@vision.ee.ethz.ch,82%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Florian Stimberg,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Ayan Chakrabarti,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Chun-ta Lu,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Hussein Hazimeh,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Otilia Stretcu,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Wei Qiao,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Yintao Liu,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Merve Kaya,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Cyrus Rashtchian,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Ariel Fuxman,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Mehmet Tek,,0%
https://arxiv.org/pdf/2301.12993.pdf,Benchmarking Robustness to Adversarial Image Obfuscations,Sven Gowal,,0%
https://arxiv.org/pdf/2301.12972.pdf,Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale Outdoor Scene,Sunghwan Yoo,,0%
https://arxiv.org/pdf/2301.12972.pdf,Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale Outdoor Scene,Yeongjeong Jeong,,0%
https://arxiv.org/pdf/2301.12972.pdf,Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale Outdoor Scene,Maryam Jameela,,0%
https://arxiv.org/pdf/2301.12972.pdf,Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale Outdoor Scene,Gunho Sohn,,0%
https://arxiv.org/pdf/2301.12959.pdf,GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis,Ming Tao,,0%
https://arxiv.org/pdf/2301.12959.pdf,GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis,Bing-kun Bao,,0%
https://arxiv.org/pdf/2301.12959.pdf,GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis,Hao Tang,,0%
https://arxiv.org/pdf/2301.12959.pdf,GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis,Changsheng Xu,,0%
https://arxiv.org/pdf/2301.13648.pdf,CSDN: Combing Shallow and Deep Networks for Accurate Real-time Segmentation of High-definition Intravascular Ultrasound Images,Feng Yang,yangf@smu.edu.cn,78%
https://arxiv.org/pdf/2301.13648.pdf,CSDN: Combing Shallow and Deep Networks for Accurate Real-time Segmentation of High-definition Intravascular Ultrasound Images,Shaofeng Yuan,shaofeng.yuan.smu@gmail.com,95%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Nikhil S. Narayan,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Shashanka B. R.,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Rohit Damodaran,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Chandrashekhar Jayaram,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,M. A. Kareem,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Mamta P.,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Saravanan K. R.,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Monu Krishnan,,0%
https://arxiv.org/pdf/2301.12943.pdf,Factors that affect Camera based Self-Monitoring of Vitals in the Wild,Raja Indana,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,Alexandros Kalimeris,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,Ioannis Psarros,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,Giorgos Giannopoulos,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,Manolis Terrovitis,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,George Papastefanatos,,0%
https://arxiv.org/pdf/2301.12939.pdf,Data-driven soiling detection in PV modules,Gregory Kotsis,,0%
https://arxiv.org/pdf/2301.12935.pdf,ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models,Shengming Li,,0%
https://arxiv.org/pdf/2301.12935.pdf,ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models,Luping Liu,,0%
https://arxiv.org/pdf/2301.12935.pdf,ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models,Runnan Li,,0%
https://arxiv.org/pdf/2301.12935.pdf,ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models,Xu Tan,,0%
https://arxiv.org/pdf/2301.12914.pdf,PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks,Alexandros Iosifidis,ai@ece.au.dk,90%
https://arxiv.org/pdf/2301.12914.pdf,PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks,Arian Bakhtiarnia,arianbakh@ece.au.dk,85%
https://arxiv.org/pdf/2301.12914.pdf,PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks,Qi Zhang,qz@ece.au.dk,90%
https://arxiv.org/pdf/2301.12900.pdf,DepGraph: Towards Any Structural Pruning,Xinyin Ma,maxinyin@u.nus.edu,95%
https://arxiv.org/pdf/2301.12900.pdf,DepGraph: Towards Any Structural Pruning,Xinchao Wang,xinchao@nus.edu.sg,85%
https://arxiv.org/pdf/2301.12900.pdf,DepGraph: Towards Any Structural Pruning,Gongfan Fang,gongfan@u.nus.edu,85%
https://arxiv.org/pdf/2301.12900.pdf,DepGraph: Towards Any Structural Pruning,Mingli Song,,0%
https://arxiv.org/pdf/2301.12900.pdf,DepGraph: Towards Any Structural Pruning,Michael Bi Mi,,0%
https://arxiv.org/pdf/2301.12891.pdf,Half of an image is enough for quality assessment,Junyong You,,0%
https://arxiv.org/pdf/2301.12891.pdf,Half of an image is enough for quality assessment,Yuan Lin,,0%
https://arxiv.org/pdf/2301.12891.pdf,Half of an image is enough for quality assessment,Jari Korhonen,,0%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Shiqi Wang,shiqwang@cityu.edu.hk,82%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Anderson Rocha,anderson.rocha@ic.unicamp.br,95%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Haoliang Li,haoliang.li@cityu.edu.hk,95%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Chenqi Kong,cqkong2-c@my.cityu.edu.hk,82%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Yibing Liu,lyibing112@gmail.com,85%
https://arxiv.org/pdf/2301.12831.pdf,M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,Kexin Zheng,kzhengaj@connect.ust.hk,82%
https://arxiv.org/pdf/2301.12827.pdf,YOLO-based Object Detection in Industry 4.0 Fischertechnik Model Environment,Marc Gebauer,gebaumar@b-tu.de,75%
https://arxiv.org/pdf/2301.12827.pdf,YOLO-based Object Detection in Industry 4.0 Fischertechnik Model Environment,Toni Schneidereit,schneton@b-tu.de,60%
https://arxiv.org/pdf/2301.12827.pdf,YOLO-based Object Detection in Industry 4.0 Fischertechnik Model Environment,Slavomira Schneidereit,,0%
https://arxiv.org/pdf/2301.12827.pdf,YOLO-based Object Detection in Industry 4.0 Fischertechnik Model Environment,Ashkan Mansouri Yarahmadi,,0%
https://arxiv.org/pdf/2301.12827.pdf,YOLO-based Object Detection in Industry 4.0 Fischertechnik Model Environment,Michael Breuß,,0%
https://arxiv.org/pdf/2301.12799.pdf,Eye Image-based Algorithms to Estimate Percentage Closure of Eye and Saccadic Ratio for Alertness Detection,Supratim Gupta,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Huazhu Fu,hzfu@ieee.org,82%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Yong Liu,liuyong@ihpc.a-star.edu.sg,95%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Meng Wang,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Kai Yu,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Chun-mei Feng,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Yiming Qian,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Ke Zou,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Lianyu Wang,,0%
https://arxiv.org/pdf/2301.12798.pdf,Reliable Federated Disentangling Network for Non-IID Domain Feature,Rick Siow Mong Goh,,0%
https://arxiv.org/pdf/2301.12796.pdf,Rendering the Directional TSDF for Tracking and Multi-Sensor Registration with Point-To-Plane Scale ICP,Malte Splietker,,0%
https://arxiv.org/pdf/2301.12796.pdf,Rendering the Directional TSDF for Tracking and Multi-Sensor Registration with Point-To-Plane Scale ICP,Sven Behnke,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Muhammad Al-barham,muhammadal-barham@ieee.org,95%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Adham Alsharkawi,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Musa Al-yaman,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Mohammad Al-fetyani,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Ashraf Elnagar,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Ahmad Abu Saaleek,,0%
https://arxiv.org/pdf/2301.11932.pdf,RGB Arabic Alphabets Sign Language Dataset,Mohammad Al-odat,,0%
https://arxiv.org/pdf/2301.12744.pdf,PointSmile: Point Self-supervised Learning via Curriculum Mutual Information,Songcan Chen,s.chen@nuaa.edu.cn,82%
https://arxiv.org/pdf/2301.12744.pdf,PointSmile: Point Self-supervised Learning via Curriculum Mutual Information,Mingqiang Wei,mingqiang.wei@gmail.com,95%
https://arxiv.org/pdf/2301.12744.pdf,PointSmile: Point Self-supervised Learning via Curriculum Mutual Information,Xin Li,,0%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Nan Li,chuanqil@sjtu.edu.cn,85%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Weijie Lv,lvweijie@nuaa.edu.cn,95%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Xuan Xia,,0%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Xing He,,0%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Chuanqi Liu,,0%
https://arxiv.org/pdf/2301.12739.pdf,FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation,Ning Ding,,0%
https://arxiv.org/pdf/2301.12698.pdf,Robust Meta Learning for Image based tasks,Penghao Jiang,,0%
https://arxiv.org/pdf/2301.12698.pdf,Robust Meta Learning for Image based tasks,Xin Ke,,0%
https://arxiv.org/pdf/2301.12698.pdf,Robust Meta Learning for Image based tasks,Zifeng Wang,,0%
https://arxiv.org/pdf/2301.12698.pdf,Robust Meta Learning for Image based tasks,Chunxi Li,,0%
https://arxiv.org/pdf/2301.12689.pdf,Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels,Younggun Cho,yg.cho@inha.ac.kr,82%
https://arxiv.org/pdf/2301.12689.pdf,Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels,Myung-hwan Jeon,myunghwan.jeon@snu.ac.kr,95%
https://arxiv.org/pdf/2301.12689.pdf,Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels,Dong-guw Lee,,0%
https://arxiv.org/pdf/2301.12689.pdf,Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels,Ayoung Kim,,0%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Linning Xu,linningxu@ie.cuhk.edu.hk,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Yuwei Guo,guoyuwei@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Libiao Jin,libiao@cuc.edu.cn,85%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Anyi Rao,anyirao@stanford.edu,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Bo Dai,daibo@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Lei Yang,yanglei@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Xuekun Jiang,jiangxuekun@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.12688.pdf,Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production,Dahua Lin,dhlin@ie.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Naoki Murata,naoki.murata@sony.com,95%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Koichi Saito,,0%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Chieh-hsin Lai,,0%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Yuhta Takida,,0%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Toshimitsu Uesaka,,0%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Yuki Mitsufuji,,0%
https://arxiv.org/pdf/2301.12686.pdf,GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration,Stefano Ermon,,0%
https://arxiv.org/pdf/2301.12682.pdf,Image Contrast Enhancement using Fuzzy Technique with Parameter Determination using Metaheuristics,M. Sohel Rahman,msrahman@cse.buet.ac.bd,82%
https://arxiv.org/pdf/2301.12682.pdf,Image Contrast Enhancement using Fuzzy Technique with Parameter Determination using Metaheuristics,Mohimenul Kabir,,0%
https://arxiv.org/pdf/2301.12682.pdf,Image Contrast Enhancement using Fuzzy Technique with Parameter Determination using Metaheuristics,Jaiaid Mobin,,0%
https://arxiv.org/pdf/2301.12682.pdf,Image Contrast Enhancement using Fuzzy Technique with Parameter Determination using Metaheuristics,Ahmad Hassanat,,0%
https://arxiv.org/pdf/2301.12667.pdf,NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification,Parth Padalkar,parth.padalkar@utdallas.edu,95%
https://arxiv.org/pdf/2301.12667.pdf,NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification,Huaduo Wang,,0%
https://arxiv.org/pdf/2301.12667.pdf,NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification,Gopal Gupta,,0%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Lijian Lin,ljlin@stu.xmu.edu.cn,82%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Jin Ma,majin01@mail.ustc.edu.cn,95%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Yizhen Chen,grayyzchen@tencent.com,78%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Zhongang Qi,zhongangqi@tencent.com,95%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Ying Shan,yingsshan@tencent.com,95%
https://arxiv.org/pdf/2301.12644.pdf,Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,Jie Wang,,0%
https://arxiv.org/pdf/2301.12643.pdf,Adversarial Style Augmentation for Domain Generalization,Yabin Zhang,csybzhang@comp.polyu.edu.hk,78%
https://arxiv.org/pdf/2301.12643.pdf,Adversarial Style Augmentation for Domain Generalization,Bin Deng,,0%
https://arxiv.org/pdf/2301.12643.pdf,Adversarial Style Augmentation for Domain Generalization,Ruihuang Li,,0%
https://arxiv.org/pdf/2301.12643.pdf,Adversarial Style Augmentation for Domain Generalization,Kui Jia,,0%
https://arxiv.org/pdf/2301.12643.pdf,Adversarial Style Augmentation for Domain Generalization,Lei Zhang,,0%
https://arxiv.org/pdf/2301.12637.pdf,Lateralized Learning for Multi-Class Visual Classification Tasks,Abubakar Siddique,,0%
https://arxiv.org/pdf/2301.12637.pdf,Lateralized Learning for Multi-Class Visual Classification Tasks,Will N. Browne,,0%
https://arxiv.org/pdf/2301.12637.pdf,Lateralized Learning for Multi-Class Visual Classification Tasks,Gina M. Grimshaw,,0%
https://arxiv.org/pdf/2301.12636.pdf,Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays,Curtis Langlotz,langlotz@stanford.edu,78%
https://arxiv.org/pdf/2301.12636.pdf,Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays,Akshay Chaudhari,akshaysc@stanford.edu,85%
https://arxiv.org/pdf/2301.12636.pdf,Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays,Rogier Van Der Sluijs,sluijs@stanford.edu,78%
https://arxiv.org/pdf/2301.12636.pdf,Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays,Daniel Rubin,dlrubin@stanford.edu,82%
https://arxiv.org/pdf/2301.12636.pdf,Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays,Nandita Bhaskhar,,0%
https://arxiv.org/pdf/2301.12614.pdf,RREx-BoT: Remote Referring Expressions with a Bag of Tricks,Gunnar A. Sigurdsson,,0%
https://arxiv.org/pdf/2301.12614.pdf,RREx-BoT: Remote Referring Expressions with a Bag of Tricks,Jesse Thomason,,0%
https://arxiv.org/pdf/2301.12614.pdf,RREx-BoT: Remote Referring Expressions with a Bag of Tricks,Gaurav S. Sukhatme,,0%
https://arxiv.org/pdf/2301.12614.pdf,RREx-BoT: Remote Referring Expressions with a Bag of Tricks,Robinson Piramuthu,,0%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Bingbing Ni,nibingbing@sjtu.edu.cn,95%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Xiaoyang Huang,huangxiaoyang@sjtu.edu.cn,95%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Yanjun Wang,,0%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Yang Liu,,0%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Wenjun Zhang,,0%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Jinxian Liu,,0%
https://arxiv.org/pdf/2301.12613.pdf,AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio,Teng Li,,0%
https://arxiv.org/pdf/2301.12597.pdf,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models,Junnan Li,,0%
https://arxiv.org/pdf/2301.12597.pdf,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models,Dongxu Li,,0%
https://arxiv.org/pdf/2301.12597.pdf,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models,Silvio Savarese,,0%
https://arxiv.org/pdf/2301.12597.pdf,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models,Steven Hoi,,0%
https://arxiv.org/pdf/2301.12592.pdf,Ensemble Learning for Fusion of Multiview Vision with Occlusion and Missing Information: Framework and Evaluations with Real-World Data and Applications in Driver Hand Activity Recognition,Ross Greer,regreer@ucsd.edu,82%
https://arxiv.org/pdf/2301.12592.pdf,Ensemble Learning for Fusion of Multiview Vision with Occlusion and Missing Information: Framework and Evaluations with Real-World Data and Applications in Driver Hand Activity Recognition,Mohan Trivedi,,0%
https://arxiv.org/pdf/2301.12589.pdf,Confidence-Aware Calibration and Scoring Functions for Curriculum Learning,Shuang Ao,,0%
https://arxiv.org/pdf/2301.12589.pdf,Confidence-Aware Calibration and Scoring Functions for Curriculum Learning,Stefan Rueger,,0%
https://arxiv.org/pdf/2301.12589.pdf,Confidence-Aware Calibration and Scoring Functions for Curriculum Learning,Advaith Siddharthan,,0%
https://arxiv.org/pdf/2301.12588.pdf,Development of Machine learning algorithms to identify the Cobb angle in adolescents with idiopathic scoliosis based on lumbosacral joint efforts during gait (Case study),Bahare Samadi,,0%
https://arxiv.org/pdf/2301.12588.pdf,Development of Machine learning algorithms to identify the Cobb angle in adolescents with idiopathic scoliosis based on lumbosacral joint efforts during gait (Case study),Maxime Raison,,0%
https://arxiv.org/pdf/2301.12588.pdf,Development of Machine learning algorithms to identify the Cobb angle in adolescents with idiopathic scoliosis based on lumbosacral joint efforts during gait (Case study),Philippe Mahaudens,,0%
https://arxiv.org/pdf/2301.12588.pdf,Development of Machine learning algorithms to identify the Cobb angle in adolescents with idiopathic scoliosis based on lumbosacral joint efforts during gait (Case study),Christine Detrembleur,,0%
https://arxiv.org/pdf/2301.12588.pdf,Development of Machine learning algorithms to identify the Cobb angle in adolescents with idiopathic scoliosis based on lumbosacral joint efforts during gait (Case study),Sofiane Achiche,,0%
https://arxiv.org/pdf/2301.12554.pdf,Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,Yatong Bai,yatong_bai@berkeley.edu,95%
https://arxiv.org/pdf/2301.12554.pdf,Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,Somayeh Sojoudi,sojoudi@berkeley.edu,82%
https://arxiv.org/pdf/2301.12554.pdf,Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,Aerin Kim,aerinykim@gmail.com,95%
https://arxiv.org/pdf/2301.12554.pdf,Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,Brendon G. Anderson,bganderson@berkeley.edu,82%
https://arxiv.org/pdf/2301.12549.pdf,Unlocking Deterministic Robustness Certification on ImageNet,Matt Fredrikson,mfredrik@cs.cmu.edu,90%
https://arxiv.org/pdf/2301.12549.pdf,Unlocking Deterministic Robustness Certification on ImageNet,Klas Leino,kleino@cs.cmu.edu,82%
https://arxiv.org/pdf/2301.12549.pdf,Unlocking Deterministic Robustness Certification on ImageNet,Zifan Wang,zifan@safe.ai,85%
https://arxiv.org/pdf/2301.12549.pdf,Unlocking Deterministic Robustness Certification on ImageNet,Kai Hu,kaihu@andrew.cmu.edu,95%
https://arxiv.org/pdf/2301.12549.pdf,Unlocking Deterministic Robustness Certification on ImageNet,Andy Zou,andyzou@cmu.edu,95%
https://arxiv.org/pdf/2301.12541.pdf,Supervised and Contrastive Self-Supervised In-Domain Representation Learning for Dense Prediction Problems in Remote Sensing,Ali Ghanbarzade,,0%
https://arxiv.org/pdf/2301.12541.pdf,Supervised and Contrastive Self-Supervised In-Domain Representation Learning for Dense Prediction Problems in Remote Sensing,Hossein Soleimani,,0%
https://arxiv.org/pdf/2301.12531.pdf,PhyCV: The First Physics-inspired Computer Vision Library,Yiming Zhou,,0%
https://arxiv.org/pdf/2301.12531.pdf,PhyCV: The First Physics-inspired Computer Vision Library,Callen Macphee,,0%
https://arxiv.org/pdf/2301.12531.pdf,PhyCV: The First Physics-inspired Computer Vision Library,Madhuri Suthar,,0%
https://arxiv.org/pdf/2301.12531.pdf,PhyCV: The First Physics-inspired Computer Vision Library,Bahram Jalali,,0%
https://arxiv.org/pdf/2301.12527.pdf,"Diverse, Difficult, and Odd Instances (D2O): A New Test Set for Object Classification",Ali Borji,aliborji@gmail.com,95%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Jin Fang,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Dingfu Zhou,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Jingjing Zhao,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Chenming Wu,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Chulin Tang,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Cheng-zhong Xu,,0%
https://arxiv.org/pdf/2301.12515.pdf,LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection,Liangjun Zhang,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Yangguang Li,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Bin Huang,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Zeren Chen,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Yufeng Cui,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Feng Liang,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Mingzhu Shen,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Fenggang Liu,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Enze Xie,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Lu Sheng,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Wanli Ouyang,,0%
https://arxiv.org/pdf/2301.12511.pdf,Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline,Jing Shao,,0%
https://arxiv.org/pdf/2301.13606.pdf,Multi-video Moment Ranking with Multimodal Clue,Danyang Hou,,0%
https://arxiv.org/pdf/2301.13606.pdf,Multi-video Moment Ranking with Multimodal Clue,Liang Pang,,0%
https://arxiv.org/pdf/2301.13606.pdf,Multi-video Moment Ranking with Multimodal Clue,Yanyan Lan,,0%
https://arxiv.org/pdf/2301.13606.pdf,Multi-video Moment Ranking with Multimodal Clue,Huawei Shen,,0%
https://arxiv.org/pdf/2301.13606.pdf,Multi-video Moment Ranking with Multimodal Clue,Xueqi Cheng,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Isaac Osei Agyemang,ioagyemang@std.uestc.edu.cn,82%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Isaac Adjei Mensah,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Sophyani Banaamwini Yussif,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Fiasam Linda Delali,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Bernard Cobinnah Mawuli,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Bless Lord Y. Agbley,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Collins Sey,,0%
https://arxiv.org/pdf/2301.12470.pdf,Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators,Joshua Berkohd,,0%
https://arxiv.org/pdf/2301.12459.pdf,The Influences of Color and Shape Features in Visual Contrastive Learning,Xiaoqi Zhuang,xiaoqizhuang@outlook.com,95%
https://arxiv.org/pdf/2301.12456.pdf,Towards Verifying the Geometric Robustness of Large-scale Neural Networks,Wenjie Ruan,w.ruan@exeter.ac.uk,82%
https://arxiv.org/pdf/2301.12456.pdf,Towards Verifying the Geometric Robustness of Large-scale Neural Networks,Peipei Xu,peipei.xu@liverpool.ac.uk,95%
https://arxiv.org/pdf/2301.12456.pdf,Towards Verifying the Geometric Robustness of Large-scale Neural Networks,Xiaowei Huang,xiaowei.huang@liverpool.ac.uk,95%
https://arxiv.org/pdf/2301.12456.pdf,Towards Verifying the Geometric Robustness of Large-scale Neural Networks,Fu Wang,,0%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Qixiang Ye,qxye@ucas.ac.cn,82%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Jiahan Li,han.li@cumt.edu.cn,78%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Qiong Wu,qiong@stu.xmu.edu.cn,85%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Pingyang Dai,pydai@xmu.edu.cn,82%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Liujuan Cao,caoliujuan@xmu.edu.cn,95%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Rongrong Ji,rrji@xmu.edu.cn,82%
https://arxiv.org/pdf/2301.12439.pdf,Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning,Yongjian Wu,,0%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Yi Cheng,cheng yi@i2r.a-star.edu.sg,95%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Ying Sun,suny@i2r.a-star.edu.sg,78%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Qianli Xu,qxu@i2r.a-star.edu.sg,82%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Hao Xuan Woon,haoxuan.woon@u.nus.edu,95%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Dongyun Lin,lin dongyun@i2r.a-star.edu.sg,95%
https://arxiv.org/pdf/2301.12436.pdf,Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022,Fen Fang,fang fen@i2r.a-star.edu.sg,95%
https://arxiv.org/pdf/2301.12429.pdf,Debiased Fine-Tuning for Vision-language Models by Prompt Regularization,Beier Zhu,beier002@e.ntu.edu.sg,85%
https://arxiv.org/pdf/2301.12429.pdf,Debiased Fine-Tuning for Vision-language Models by Prompt Regularization,Hanwang Zhang,hanwangzhang@ntu.edu.sg,95%
https://arxiv.org/pdf/2301.12429.pdf,Debiased Fine-Tuning for Vision-language Models by Prompt Regularization,Saeil Lee,saeil.lee@hmgics.com,95%
https://arxiv.org/pdf/2301.12429.pdf,Debiased Fine-Tuning for Vision-language Models by Prompt Regularization,Yulei Niu,yn.yuleiniu@gmail.com,95%
https://arxiv.org/pdf/2301.12429.pdf,Debiased Fine-Tuning for Vision-language Models by Prompt Regularization,Minhoe Hur,minhoe.hur@hyundai.com,95%
https://arxiv.org/pdf/2301.12416.pdf,Deep Learning for Human Parsing: A Survey,Ming Tang,tangm@nlpr.ia.ac.cn,78%
https://arxiv.org/pdf/2301.12416.pdf,Deep Learning for Human Parsing: A Survey,Xiaomei Zhang,xiaomei.zhang@nlpr.ia.ac.cn,95%
https://arxiv.org/pdf/2301.12416.pdf,Deep Learning for Human Parsing: A Survey,Xiangyu Zhu,xiangyu.zhu.chen@nlpr.ia.ac.cn,95%
https://arxiv.org/pdf/2301.12416.pdf,Deep Learning for Human Parsing: A Survey,Zhen Lei,zlei@nlpr.ia.ac.cn,82%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Kan Ren,kan.ren@microsoft.com,95%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Ziyue Li,litzy0619owned@gmail.com,78%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Yifan Yang,,0%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Xinyang Jiang,,0%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Yuqing Yang,,0%
https://arxiv.org/pdf/2301.12378.pdf,Towards Inference Efficient Deep Ensemble Learning,Dongsheng Li,,0%
https://arxiv.org/pdf/2301.12356.pdf,Exploiting High Performance Spiking Neural Networks with Efficient Spiking Patterns,Yi Zeng,yi.zeng@ia.ac.cn,95%
https://arxiv.org/pdf/2301.12356.pdf,Exploiting High Performance Spiking Neural Networks with Efficient Spiking Patterns,Guobin Shen,shenguobin2021@ia.ac.cn,95%
https://arxiv.org/pdf/2301.12356.pdf,Exploiting High Performance Spiking Neural Networks with Efficient Spiking Patterns,Dongcheng Zhao,zhaodongcheng2016@ia.ac.cn,95%
https://arxiv.org/pdf/2301.12352.pdf,Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video Object Segmentation,Jialin Yuan,yuanjial@oregonstate.edu,78%
https://arxiv.org/pdf/2301.12352.pdf,Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video Object Segmentation,Hung Nguyen,nguyehu5@oregonstate.edu,85%
https://arxiv.org/pdf/2301.12352.pdf,Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video Object Segmentation,Jay Patravali,patravaj@oregonstate.edu,65%
https://arxiv.org/pdf/2301.12352.pdf,Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video Object Segmentation,Li Fuxin,lif@oregonstate.edu,85%
https://arxiv.org/pdf/2301.12352.pdf,Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video Object Segmentation,Chanho Kim,kimchanh@oregonstate.edu,78%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Weihua Zhou,whzhou@mtu.edu,82%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Ni Yao,niceday1987@hotmail.com,85%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Yanhui Tian,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Daniel Gama Das Neves,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Chen Zhao,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Claudio Tinoco Mesquita,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Wolney De Andrade Martins,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Alair Augusto Sarmet Moreira Damas Dos Santos,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Yanting Li,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Chuang Han,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Fubao Zhu,,0%
https://arxiv.org/pdf/2301.12340.pdf,Incremental Value and Interpretability of Radiomics Features of Both Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19 Infection,Neng Dai,,0%
https://arxiv.org/pdf/2301.12334.pdf,Don't Play Favorites: Minority Guidance for Diffusion Models,Suhyeon Lee,suhyeon.lee@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.12334.pdf,Don't Play Favorites: Minority Guidance for Diffusion Models,Soobin Um,sum@kaist.ac.kr,82%
https://arxiv.org/pdf/2301.12334.pdf,Don't Play Favorites: Minority Guidance for Diffusion Models,Jong Chul Ye,jong.ye@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.12332.pdf,Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration,Peng Qiao,pengqiao@nudt.edu.cn,95%
https://arxiv.org/pdf/2301.12332.pdf,Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration,Sidun Liu,,0%
https://arxiv.org/pdf/2301.12332.pdf,Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration,Tao Sun,,0%
https://arxiv.org/pdf/2301.12332.pdf,Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration,Ke Yang,,0%
https://arxiv.org/pdf/2301.12332.pdf,Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration,Yong Dou,,0%
https://arxiv.org/pdf/2301.12293.pdf,ACL-Fig: A Dataset for Scientific Figure Classification,Zeba Karishma,zebakarishma@gmail.com,95%
https://arxiv.org/pdf/2301.12293.pdf,ACL-Fig: A Dataset for Scientific Figure Classification,Jian Wu,jwu@cs.odu.edu,82%
https://arxiv.org/pdf/2301.12293.pdf,ACL-Fig: A Dataset for Scientific Figure Classification,Shaurya Rohatgi,,0%
https://arxiv.org/pdf/2301.12293.pdf,ACL-Fig: A Dataset for Scientific Figure Classification,Kavya Shrinivas Puranik,,0%
https://arxiv.org/pdf/2301.12293.pdf,ACL-Fig: A Dataset for Scientific Figure Classification,C. Lee Giles,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Jieneng Chen,jienengchen01@gmail.com,95%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Zaiyi Liu,zyliu@163.com,82%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Yingda Xia,yingda.xia@alibaba-inc.com,95%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Jiawen Yao,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Ke Yan,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Jianpeng Zhang,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Le Lu,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Fakai Wang,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Bo Zhou,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Mingyan Qiu,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Qihang Yu,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Mingze Yuan,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Wei Fang,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Yuxing Tang,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Minfeng Xu,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Jian Zhou,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Yuqian Zhao,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Qifeng Wang,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Xianghua Ye,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Xiaoli Yin,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Yu Shi,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Xin Chen,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Jingren Zhou,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Alan Yuille,,0%
https://arxiv.org/pdf/2301.12291.pdf,"CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",Ling Zhang,,0%
https://arxiv.org/pdf/2301.12276.pdf,ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts,Bartosz Zieliński,bartosz.zielinski@uj.edu.pl,95%
https://arxiv.org/pdf/2301.12276.pdf,ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts,Jacek Tabor,lukasz.struski;jacek.tabor;bartosz.zielinski@uj.edu.pl,95%
https://arxiv.org/pdf/2301.12276.pdf,ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts,Dawid Rymarczyk,dawid.rymarczyk@doctoral.uj.edu.pl,95%
https://arxiv.org/pdf/2301.12276.pdf,ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts,Mikołaj Sacha,,0%
https://arxiv.org/pdf/2301.12276.pdf,ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts,Łukasz Struski,,0%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Sonia Moshfeghi,smoshfeghi@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Jiannan Zhai,jzhai@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,David Newman,dnewma@fau.edu,90%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Kwangsoo Yang,yangk@fau.edu,78%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Monica Rosselli,mrossell@fau.edu,90%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Borko Furht,bfurht@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Jinwoo Jang,jangj@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Ruth Tappen,rtappen@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Muhammad Tanveer Jan,mjan2021@fau.edu,82%
https://arxiv.org/pdf/2301.12269.pdf,Methods and Tools for Monitoring Driver's Behavior,Joshua William Conniff,fau.jconniff@health.fau.edu,78%
https://arxiv.org/pdf/2301.12257.pdf,Few-shot Face Image Translation via GAN Prior Distillation,Xiaoyu Wang,fanghuaxue@gmail.com,65%
https://arxiv.org/pdf/2301.12257.pdf,Few-shot Face Image Translation via GAN Prior Distillation,Nannan Wang,nnwang@xidian.edu.cn,82%
https://arxiv.org/pdf/2301.12257.pdf,Few-shot Face Image Translation via GAN Prior Distillation,Ruoyu Zhao,royzhao@stu.xidian.edu.cn,82%
https://arxiv.org/pdf/2301.12257.pdf,Few-shot Face Image Translation via GAN Prior Distillation,Mingrui Zhu,mrzhu@xidian.edu.cn,82%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Manuel Brack,brack@cs.tu-darmstadt.de,78%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Felix Friedrich,,0%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Dominik Hintersdorf,,0%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Lukas Struppek,,0%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Patrick Schramowski,,0%
https://arxiv.org/pdf/2301.12247.pdf,SEGA: Instructing Text-to-Image Models using Semantic Guidance,Kristian Kersting,,0%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Jingkuan Song,jingkuan.song@gmail.com,95%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Xu Luo,,0%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Hao Wu,,0%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Ji Zhang,,0%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Lianli Gao,,0%
https://arxiv.org/pdf/2301.12246.pdf,A Closer Look at Few-shot Classification Again,Jing Xu,,0%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Junyou Wang,wangjunyou@stu.scu.edu.cn,95%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Jianwei Zhang,zhangjianwei@stu.scu.edu.cn,95%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Lei Zhang,leizhang@scu.edu.cn,95%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Xin Wei,weixin@stu.scu.edu.cn,95%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Jiaqi Li,lijiaqicd@gmail.com,95%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Wenjie Liu,liuwj@stu.scu.edu.cn,78%
https://arxiv.org/pdf/2301.12219.pdf,Towards Accurate Acne Detection via Decoupled Sequential Detection Head,Xian Jiang,,0%
https://arxiv.org/pdf/2301.12176.pdf,Neural Gas Network Image Features and Segmentation for Brain Tumor Detection Using Magnetic Resonance Imaging Data,S. Muhammad Hossein Mousavi,mosavi.a.i.buali@gmail.com,85%
https://arxiv.org/pdf/2301.12171.pdf,ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts,Jong Chul Ye,jong.ye@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.12171.pdf,ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts,Yujin Oh,yujin.oh@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.12171.pdf,ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts,Kwanyoung Kim,,0%
https://arxiv.org/pdf/2301.12168.pdf,"Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks via Aggregated Early Exits",Matteo Matteucci,matteo.matteucci@polimi.it,95%
https://arxiv.org/pdf/2301.12168.pdf,"Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks via Aggregated Early Exits",Simone Sarti,simone.sarti@mail.polimi.it,95%
https://arxiv.org/pdf/2301.12168.pdf,"Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks via Aggregated Early Exits",Eugenio Lomurno,eugenio.lomurno@polimi.it,95%
https://arxiv.org/pdf/2301.12165.pdf,Dynamic Point Cloud Geometry Compression Using Multiscale Inter Conditional Coding,Jianqiang Wang,,0%
https://arxiv.org/pdf/2301.12165.pdf,Dynamic Point Cloud Geometry Compression Using Multiscale Inter Conditional Coding,Dandan Ding,,0%
https://arxiv.org/pdf/2301.12165.pdf,Dynamic Point Cloud Geometry Compression Using Multiscale Inter Conditional Coding,Hao Chen,,0%
https://arxiv.org/pdf/2301.12165.pdf,Dynamic Point Cloud Geometry Compression Using Multiscale Inter Conditional Coding,Zhan Ma,,0%
https://arxiv.org/pdf/2301.12159.pdf,ClusterFuG: Clustering Fully connected Graphs by Multicut,Ahmed Abbas,ahmed.abbas@mpi-inf.mpg.de,95%
https://arxiv.org/pdf/2301.12159.pdf,ClusterFuG: Clustering Fully connected Graphs by Multicut,Paul Swoboda,,0%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Aibin Huang,huangaibin@hdu.edu.cn,95%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Yuanqi Chang,yuanqichang@hdu.edu.cn,95%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Jiawei Mao,jiaweima0@hdu.edu.cn,85%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Binling Nie,binlingnie@hdu.edu.cn,95%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Xuesong Yin,yinxs@hdu.edu.cn,78%
https://arxiv.org/pdf/2301.12149.pdf,POSTER++: A simpler and stronger facial expression recognition network,Rui Xu,,0%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Xiaoya Yang,yangxiaoya@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Dongxv Liu,liudongxv@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Pu Cao,caopu@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Tianrui Huang,huangtianrui@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Lu Yang,,0%
https://arxiv.org/pdf/2301.12141.pdf,What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion,Qing Song,,0%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Gim Hee Lee,gimhee.lee@comp.nus.edu.sg,95%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Jianming Li,jianming.li@ninebot.com,95%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Shu Song,songshu0905@gmail.com,95%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Yu Chen,chenyu@comp.nus.edu.sg,95%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Tianning Yu,tianning.yu@rlm.segway.com,95%
https://arxiv.org/pdf/2301.12135.pdf,AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,Zihao Yu,yuzihao@buaa.edu.cn,95%
https://arxiv.org/pdf/2301.12093.pdf,Local Contrast and Global Contextual Information Make Infrared Small Object Salient Again,Chenyi Wang,Nanjing@qq.com,55%
https://arxiv.org/pdf/2301.12093.pdf,Local Contrast and Global Contextual Information Make Infrared Small Object Salient Again,Huan Wang,,0%
https://arxiv.org/pdf/2301.12093.pdf,Local Contrast and Global Contextual Information Make Infrared Small Object Salient Again,Peiwen Pan,,0%
https://arxiv.org/pdf/2301.12082.pdf,Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore,Feng Zheng,zhengf@sustech.edu.cn,78%
https://arxiv.org/pdf/2301.12082.pdf,Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore,Guoyang Xie,guoyang.xie@surrey.ac.uk,95%
https://arxiv.org/pdf/2301.12082.pdf,Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore,Yaochu Jin,yaochu.jin@uni-bielefeld.de,95%
https://arxiv.org/pdf/2301.12082.pdf,Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore,Jiaqi Liu,liujq32021@mail.sustech.edu.cn,78%
https://arxiv.org/pdf/2301.12082.pdf,Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore,Jinbao Wang,,0%
https://arxiv.org/pdf/2301.12077.pdf,ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning,Mingyu Xu,xumingyu2021@ia.ac.cn,95%
https://arxiv.org/pdf/2301.12077.pdf,ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning,Zheng Lian,lianzheng2016@ia.ac.cn,95%
https://arxiv.org/pdf/2301.12077.pdf,ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning,Lei Feng,,0%
https://arxiv.org/pdf/2301.12077.pdf,ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning,Bin Liu,,0%
https://arxiv.org/pdf/2301.12077.pdf,ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label Learning,Jianhua Tao,,0%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Lia Coleman,liac@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Peter Schaldenbrand,pschalde@andrew.cmu.edu,90%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Youeun Shin,youeuns@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Jihie Kim,jihie.kim@dgu.edu,95%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Jean Oh,jeanoh@cmu.edu,95%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Zhixuan Liu,zhixuan2@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Youngsik Yun,youngsiy@andrew.cmu.edu,75%
https://arxiv.org/pdf/2301.12073.pdf,Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset,Beverley-claire Okogwu,bokogwu@andrew.cmu.edu,82%
https://arxiv.org/pdf/2301.12067.pdf,Learning Optimal Features via Partial Invariance,Lav R. Varshney,varshney@illinois.edu,78%
https://arxiv.org/pdf/2301.12067.pdf,Learning Optimal Features via Partial Invariance,Moulik Choraria,moulikc2@illinois.edu,85%
https://arxiv.org/pdf/2301.12067.pdf,Learning Optimal Features via Partial Invariance,Ibtihal Ferwana,iferwna2@illinois.edu,65%
https://arxiv.org/pdf/2301.12067.pdf,Learning Optimal Features via Partial Invariance,Ankur Mani,amani@umn.edu,82%
https://arxiv.org/pdf/2301.12058.pdf,Aerial Image Object Detection With Vision Transformer Detector (ViTDet),Liya Wang,,0%
https://arxiv.org/pdf/2301.12058.pdf,Aerial Image Object Detection With Vision Transformer Detector (ViTDet),Alex Tien,,0%
https://arxiv.org/pdf/2301.12057.pdf,Object Preserving Siamese Network for Single Object Tracking on Point Clouds,Kaijie Zhao,,0%
https://arxiv.org/pdf/2301.12057.pdf,Object Preserving Siamese Network for Single Object Tracking on Point Clouds,Haitao Zhao,,0%
https://arxiv.org/pdf/2301.12057.pdf,Object Preserving Siamese Network for Single Object Tracking on Point Clouds,Zhongze Wang,,0%
https://arxiv.org/pdf/2301.12057.pdf,Object Preserving Siamese Network for Single Object Tracking on Point Clouds,Jingchao Peng,,0%
https://arxiv.org/pdf/2301.12057.pdf,Object Preserving Siamese Network for Single Object Tracking on Point Clouds,Zhengwei Hu,,0%
https://arxiv.org/pdf/2301.12053.pdf,Weakly Supervised Image Segmentation Beyond Tight Bounding Box Annotations,Bin Xia,b.xia@sibionics.com,82%
https://arxiv.org/pdf/2301.12053.pdf,Weakly Supervised Image Segmentation Beyond Tight Bounding Box Annotations,Juan Wang,wangjuan313@gmail.com,95%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Yue Bai,bai.yue@northeastern.edu,95%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Yun Fu,yunfu@ece.neu.edu,95%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Yi Xu,xu.yi@northeastern.edu,95%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Xu Ma,ma.xu1@northeastern.edu,95%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Can Qin,qin.ca@northeastern.edu,78%
https://arxiv.org/pdf/2301.12048.pdf,Making Reconstruction-based Method Great Again for Video Anomaly Detection,Yizhou Wang,,0%
https://arxiv.org/pdf/2301.12046.pdf,Semantic Adversarial Attacks on Face Recognition through Significant Attributes,Yasmeen M. Khedr,yasmeenkhedr@hust.edu.cn,95%
https://arxiv.org/pdf/2301.12046.pdf,Semantic Adversarial Attacks on Face Recognition through Significant Attributes,Yifeng Xiong,xiongyf@hust.edu.cn,78%
https://arxiv.org/pdf/2301.12046.pdf,Semantic Adversarial Attacks on Face Recognition through Significant Attributes,Kun He,,0%
https://arxiv.org/pdf/2301.12032.pdf,BinaryVQA: A Versatile Test Set to Evaluate the Out-of-Distribution Generalization of VQA Models,Ali Borji,aliborji@gmail.com,95%
https://arxiv.org/pdf/2301.12025.pdf,Cross-Architectural Positive Pairs improve the effectiveness of Self-Supervised Learning,Pranav Singh,,0%
https://arxiv.org/pdf/2301.12025.pdf,Cross-Architectural Positive Pairs improve the effectiveness of Self-Supervised Learning,Jacopo Cirrone,,0%
https://arxiv.org/pdf/2301.12006.pdf,Improved knowledge distillation by utilizing backward pass knowledge in neural networks,Aref Jafari,aref.jafari@uwaterloo.ca,95%
https://arxiv.org/pdf/2301.12006.pdf,Improved knowledge distillation by utilizing backward pass knowledge in neural networks,Mehdi Rezagholizadeh,mehdi.rezagholizadeh@huawei.com,95%
https://arxiv.org/pdf/2301.12006.pdf,Improved knowledge distillation by utilizing backward pass knowledge in neural networks,Ali Ghodsi,ali.ghodsi@uwaterloo.ca,95%
https://arxiv.org/pdf/2301.12003.pdf,Minimizing Trajectory Curvature of ODE-based Generative Models,Jong Chul Ye,jong.ye@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.12003.pdf,Minimizing Trajectory Curvature of ODE-based Generative Models,Sangyun Lee,,0%
https://arxiv.org/pdf/2301.12003.pdf,Minimizing Trajectory Curvature of ODE-based Generative Models,Beomsu Kim,,0%
https://arxiv.org/pdf/2301.11990.pdf,Alignment with human representations supports robust few-shot learning,Ilia Sucholutsky,,0%
https://arxiv.org/pdf/2301.11990.pdf,Alignment with human representations supports robust few-shot learning,Thomas L. Griffiths,,0%
https://arxiv.org/pdf/2301.11986.pdf,Enhancing Face Recognition with Latent Space Data Augmentation and Facial Posture Reconstruction,Hamid Hassanpour,h.hassanpour@shahroodut.ac.ir,82%
https://arxiv.org/pdf/2301.11986.pdf,Enhancing Face Recognition with Latent Space Data Augmentation and Facial Posture Reconstruction,Soroush Hashemifar,hashemifar_soroush@cmps2.iust.ac.ir,95%
https://arxiv.org/pdf/2301.11986.pdf,Enhancing Face Recognition with Latent Space Data Augmentation and Facial Posture Reconstruction,Javad Hassannataj Joloudari,javad.hassannataj@birjand.ac.ir,85%
https://arxiv.org/pdf/2301.11986.pdf,Enhancing Face Recognition with Latent Space Data Augmentation and Facial Posture Reconstruction,Abdolreza Marefat,rzamarefat@gmail.com,78%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Xinggang Wang,xgwang@hust.edu.cn,82%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Jie Zhu,zhujie@stu.pku.edu.cn,95%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Jiyang Qi,jiyangqi@hust.edu.cn,95%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Mingyu Ding,myding@berkeley.edu,82%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Ping Luo,pluo@cs.hku.hk,82%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Jingdong Wang,wangjingdong@outlook.com,95%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Leye Wang,leyewang@pku.edu.cn,95%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Wenyu Liu,liuwy@hust.edu.cn,78%
https://arxiv.org/pdf/2301.11915.pdf,Understanding Self-Supervised Pretraining with Part-Aware Representation Learning,Xiaokang Chen,,0%
https://arxiv.org/pdf/2301.11752.pdf,Inter-View Depth Consistency Testing in Depth Difference Subspace,Markus Flierl,markus.ﬂierl@kth.se,95%
https://arxiv.org/pdf/2301.11752.pdf,Inter-View Depth Consistency Testing in Depth Difference Subspace,Pravin Kumar Rana,pravin.rana@tobii.com,95%
https://arxiv.org/pdf/2301.11892.pdf,Streaming LifeLong Learning With Any-Time Inference,Vinay Kumar Verma,vinaykumar.verma@duke.edu,95%
https://arxiv.org/pdf/2301.11892.pdf,Streaming LifeLong Learning With Any-Time Inference,Soumya Banerjee,soumyab@cse.iitk.ac.in,85%
https://arxiv.org/pdf/2301.11892.pdf,Streaming LifeLong Learning With Any-Time Inference,Vinay P. Namboodiri,,0%
https://arxiv.org/pdf/2301.11880.pdf,"Optical Flow Estimation in 360$^\circ$ Videos: Dataset, Model and Application",Yan Yan,yyan34@iit.edu,95%
https://arxiv.org/pdf/2301.11880.pdf,"Optical Flow Estimation in 360$^\circ$ Videos: Dataset, Model and Application",Bin Duan,bduan2@hawk.iit.edu,82%
https://arxiv.org/pdf/2301.11880.pdf,"Optical Flow Estimation in 360$^\circ$ Videos: Dataset, Model and Application",Keshav Bhandari,,0%
https://arxiv.org/pdf/2301.11880.pdf,"Optical Flow Estimation in 360$^\circ$ Videos: Dataset, Model and Application",Gaowen Liu,,0%
https://arxiv.org/pdf/2301.11843.pdf,Reading and Reasoning over Chart Images for Evidence-based Automated Fact-Checking,Oana Cocarascu,oana.cocarascu@kcl.ac.uk,95%
https://arxiv.org/pdf/2301.11843.pdf,Reading and Reasoning over Chart Images for Evidence-based Automated Fact-Checking,Elena Simperl,elena.simperl@kcl.ac.uk,95%
https://arxiv.org/pdf/2301.11843.pdf,Reading and Reasoning over Chart Images for Evidence-based Automated Fact-Checking,Mubashara Akhtar,mubashara.akhtar@kcl.ac.uk,95%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Erdi Kara,erdikara@spelman.edu,95%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,George Zhang,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Joseph J. Williams,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Gonzalo Ferrandez-quinto,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Leviticus J. Rhoden,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Maximilian Kim,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,J. Nathan Kutz,,0%
https://arxiv.org/pdf/2302.05425.pdf,Deep Learning Based Object Tracking in Walking Droplet and Granular Intruder Experiments,Aminur Rahman,,0%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Zahra Arjmandi,zahraarj@yorku.com,85%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Yujia Zhang,zhang89@yorku.ca,78%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Mostafa Ahmadi,ahmadism@yorku.ca,78%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Amin Alizadeh Naeini,naeini@yorku.ca,78%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Gunho Sohn,gsohn@yorku.ca,82%
https://arxiv.org/pdf/2301.11823.pdf,HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera,Mohammad Moein Sheikholeslami,,0%
https://arxiv.org/pdf/2301.11810.pdf,BOMP-NAS: Bayesian Optimization Mixed Precision NAS,Floran De Putter,f.a.m.d.putter@tue.nl,82%
https://arxiv.org/pdf/2301.11810.pdf,BOMP-NAS: Bayesian Optimization Mixed Precision NAS,David Van Son,d.v.son@tue.nl,82%
https://arxiv.org/pdf/2301.11810.pdf,BOMP-NAS: Bayesian Optimization Mixed Precision NAS,Sebastian Vogel,sebastian.vogel@nxp.com,95%
https://arxiv.org/pdf/2301.11810.pdf,BOMP-NAS: Bayesian Optimization Mixed Precision NAS,Henk Corporaal,h.corporaal@tue.nl,82%
https://arxiv.org/pdf/2301.11806.pdf,PCV: A Point Cloud-Based Network Verifier,Matthew B. Dwyer,matthewbdwyer@virginia.edu,95%
https://arxiv.org/pdf/2301.11806.pdf,PCV: A Point Cloud-Based Network Verifier,Arup Kumar Sarker,,0%
https://arxiv.org/pdf/2301.11806.pdf,PCV: A Point Cloud-Based Network Verifier,Farzana Yasmin Ahmad,,0%
https://arxiv.org/pdf/2301.11790.pdf,Leveraging the Third Dimension in Contrastive Learning,Sumukh Aithal,,0%
https://arxiv.org/pdf/2301.11790.pdf,Leveraging the Third Dimension in Contrastive Learning,Anirudh Goyal,,0%
https://arxiv.org/pdf/2301.11790.pdf,Leveraging the Third Dimension in Contrastive Learning,Alex Lamb,,0%
https://arxiv.org/pdf/2301.11790.pdf,Leveraging the Third Dimension in Contrastive Learning,Yoshua Bengio,,0%
https://arxiv.org/pdf/2301.11790.pdf,Leveraging the Third Dimension in Contrastive Learning,Michael Mozer,,0%
https://arxiv.org/pdf/2302.10309.pdf,Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI,Jiajing Zhang,zhangjj83@mail2.sysu.edu.cn,78%
https://arxiv.org/pdf/2302.10309.pdf,Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI,Yifeng Guo,guoyf25@mail2.sysu.edu.cn,78%
https://arxiv.org/pdf/2302.10309.pdf,Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI,Zhifan Gao,gaozhifan@mail.sysu.edu.cn,95%
https://arxiv.org/pdf/2302.10309.pdf,Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI,Tieyong Zeng,zeng@math.cuhk.edu.hk,78%
https://arxiv.org/pdf/2302.10309.pdf,Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI,Guang Yang,g.yang@imperial.ac.uk,82%
https://arxiv.org/pdf/2301.11753.pdf,Détection d'Objets dans les documents numérisés par réseaux de neurones profonds,Mélodie Boillet,,0%
https://arxiv.org/pdf/2301.11745.pdf,Side Auth: Synthesizing Virtual Sensors for Authentication,Kevin Fu,k.fu@northeastern.edu,82%
https://arxiv.org/pdf/2301.11745.pdf,Side Auth: Synthesizing Virtual Sensors for Authentication,Yan Long,yanlong@umich.edu,95%
https://arxiv.org/pdf/2301.11706.pdf,Input Perturbation Reduces Exposure Bias in Diffusion Models,Mang Ning,m.ning@uu.nl,82%
https://arxiv.org/pdf/2301.11706.pdf,Input Perturbation Reduces Exposure Bias in Diffusion Models,Enver Sangineto,,0%
https://arxiv.org/pdf/2301.11706.pdf,Input Perturbation Reduces Exposure Bias in Diffusion Models,Angelo Porrello,,0%
https://arxiv.org/pdf/2301.11706.pdf,Input Perturbation Reduces Exposure Bias in Diffusion Models,Simone Calderara,,0%
https://arxiv.org/pdf/2301.11706.pdf,Input Perturbation Reduces Exposure Bias in Diffusion Models,Rita Cucchiara,,0%
https://arxiv.org/pdf/2301.11699.pdf,Image Restoration with Mean-Reverting Stochastic Differential Equations,Ziwei Luo,ziwei.luo@it.uu.se,95%
https://arxiv.org/pdf/2301.11699.pdf,Image Restoration with Mean-Reverting Stochastic Differential Equations,Fredrik K. Gustafsson,,0%
https://arxiv.org/pdf/2301.11699.pdf,Image Restoration with Mean-Reverting Stochastic Differential Equations,Zheng Zhao,,0%
https://arxiv.org/pdf/2301.11699.pdf,Image Restoration with Mean-Reverting Stochastic Differential Equations,Jens Sjölund,,0%
https://arxiv.org/pdf/2301.11699.pdf,Image Restoration with Mean-Reverting Stochastic Differential Equations,Thomas B. Schön,,0%
https://arxiv.org/pdf/2301.11663.pdf,Deep Residual Compensation Convolutional Network without Backpropagation,Richard Wilson,richard.wilson@york.ac.uk,95%
https://arxiv.org/pdf/2301.11663.pdf,Deep Residual Compensation Convolutional Network without Backpropagation,Mubarakah Alotaibi,,0%
https://arxiv.org/pdf/2301.11650.pdf,Fast Region of Interest Proposals on Maritime UAVs,Andreas Zell,prename.surname@uni-tuebingen.de,60%
https://arxiv.org/pdf/2301.11650.pdf,Fast Region of Interest Proposals on Maritime UAVs,Benjamin Kiefer,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Przemysław Spurek,myslaw.spurek@uj.edu.pl,78%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Adam Kania,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Artur Kasymov,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Jakub Kościukiewicz,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Artur Górak,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Marcin Mazur,,0%
https://arxiv.org/pdf/2301.11631.pdf,HyperNeRFGAN: Hypernetwork approach to 3D NeRF GAN,Maciej Zięba,,0%
https://arxiv.org/pdf/2301.11630.pdf,Joint Geometry and Attribute Upsampling of Point Clouds Using Frequency-Selective Models with Overlapped Support,Viktoria Heimann,viktoria.heimann@fau.de,95%
https://arxiv.org/pdf/2301.11630.pdf,Joint Geometry and Attribute Upsampling of Point Clouds Using Frequency-Selective Models with Overlapped Support,André Kaup,andre.kaup@fau.de,95%
https://arxiv.org/pdf/2301.11630.pdf,Joint Geometry and Attribute Upsampling of Point Clouds Using Frequency-Selective Models with Overlapped Support,Andreas Spruck,,0%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Jason Gu,jason.gu@dal.ca,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Tiefeng Li,litiefeng@zju.edu.cn,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Yi Ren,even.renyi@huawei.com,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Xiaowen Chu,xwchu@hkust-gz.edu.cn,82%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Piaopiao Jin,piaopiaojin@zju.edu.cn,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Penglei Sun,psun012@connect.hkust-gz.edu.cn,82%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Yaoxian Song,songyaoxian@zju.edu.cn,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Yue Zhang,zhangyue@westlake.edu.cn,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Zhixu Li,zhixuli@ruc.edu.cn,95%
https://arxiv.org/pdf/2301.11564.pdf,Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding,Yu Zheng,yu.zheng3@ubtrobot.com,95%
https://arxiv.org/pdf/2301.11558.pdf,Accelerating Guided Diffusion Sampling with Splitting Numerical Methods,Suttisak Wizadwongsa,suttisak.w s19@vistec.ac.th,85%
https://arxiv.org/pdf/2301.11558.pdf,Accelerating Guided Diffusion Sampling with Splitting Numerical Methods,Supasorn Suwajanakorn,supasorn.s@vistec.ac.th,85%
https://arxiv.org/pdf/2301.11553.pdf,Robust Transformer with Locality Inductive Bias and Feature Normalization,Hossein Kashiani,h_asgariandehkordi@elec.iust.ac.ir,85%
https://arxiv.org/pdf/2301.11553.pdf,Robust Transformer with Locality Inductive Bias and Feature Normalization,Shahriar Baradaran Shokouhi,bshokouhi@iust.ac.ir,78%
https://arxiv.org/pdf/2301.11553.pdf,Robust Transformer with Locality Inductive Bias and Feature Normalization,Omid Nejati Manzari,omid_nejaty@alumni.iust.ac.ir,85%
https://arxiv.org/pdf/2301.11553.pdf,Robust Transformer with Locality Inductive Bias and Feature Normalization,Hojat Asgarian Dehkordi,,0%
https://arxiv.org/pdf/2301.11551.pdf,Harmonizing Flows: Unsupervised MR harmonization based on normalizing flows,Farzad Beizaee,farzad.beizaee.1@ens.etsmtl.ca,95%
https://arxiv.org/pdf/2301.11551.pdf,Harmonizing Flows: Unsupervised MR harmonization based on normalizing flows,Christian Desrosiers,,0%
https://arxiv.org/pdf/2301.11551.pdf,Harmonizing Flows: Unsupervised MR harmonization based on normalizing flows,Gregory A. Lodygensky,,0%
https://arxiv.org/pdf/2301.11551.pdf,Harmonizing Flows: Unsupervised MR harmonization based on normalizing flows,Jose Dolz,,0%
https://arxiv.org/pdf/2301.11525.pdf,Mixed Attention Network for Hyperspectral Image Denoising,Ying Fu,fuying@bit.edu.cn,95%
https://arxiv.org/pdf/2301.11525.pdf,Mixed Attention Network for Hyperspectral Image Denoising,Zeqiang Lai,laizeqiang@bit.edu.cn,95%
https://arxiv.org/pdf/2301.11522.pdf,A Comparison of Tiny-nerf versus Spatial Representations for 3d Reconstruction,Saulo Abraham Gante,sganted1500@ipn.mx,82%
https://arxiv.org/pdf/2301.11522.pdf,A Comparison of Tiny-nerf versus Spatial Representations for 3d Reconstruction,Juan Irving Vasquez,,0%
https://arxiv.org/pdf/2301.11522.pdf,A Comparison of Tiny-nerf versus Spatial Representations for 3d Reconstruction,Marco Antonio Valencia,,0%
https://arxiv.org/pdf/2301.11522.pdf,A Comparison of Tiny-nerf versus Spatial Representations for 3d Reconstruction,Mauricio Olguín Carbajal,,0%
https://arxiv.org/pdf/2301.11520.pdf,SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning,H. Jin Kim,hjinkim@snu.ac.kr,82%
https://arxiv.org/pdf/2301.11520.pdf,SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning,Dongseok Shim,,0%
https://arxiv.org/pdf/2301.11520.pdf,SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning,Seungjae Lee,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Jiaqi Liu,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Guoyang Xie,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Jinbao Wang,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Shangnian Li,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Chengjie Wang,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Feng Zheng,,0%
https://arxiv.org/pdf/2301.11514.pdf,Deep Industrial Image Anomaly Detection: A Survey,Yaochu Jin,,0%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Chunhui Li,lich@smail.nju.edu.cn,78%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Zhiling Yan,zhilingyan724@outlook.com,95%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Guanglei Zhang,guangleizhang@buaa.edu.cn,95%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Yunlu Feng,yunluf@icloud.com,85%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Nan Ying,rain986532@126.com,60%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Tianyi Zhang,,0%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Yanli Lei,,0%
https://arxiv.org/pdf/2301.11513.pdf,CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification,Yu Zhao,,0%
https://arxiv.org/pdf/2301.11507.pdf,Semi-Parametric Video-Grounded Text Generation,Minjoon Seo,minjoon@kaist.ac.kr,85%
https://arxiv.org/pdf/2301.11507.pdf,Semi-Parametric Video-Grounded Text Generation,Sungdong Kim,,0%
https://arxiv.org/pdf/2301.11507.pdf,Semi-Parametric Video-Grounded Text Generation,Jin-hwa Kim,,0%
https://arxiv.org/pdf/2301.11507.pdf,Semi-Parametric Video-Grounded Text Generation,Jiyoung Lee,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Dong Sun,medsun@cityu.edu.hk,78%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Fei Pan,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Yutong Wu,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Kangning Cui,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Shuxun Chen,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Yanfang Li,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Yaofang Liu,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Adnan Shakoor,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Han Zhao,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Beijia Lu,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Shaohua Zhi,,0%
https://arxiv.org/pdf/2301.11499.pdf,Dual-View Selective Instance Segmentation Network for Unstained Live Adherent Cells in Differential Interference Contrast Images,Raymond Chan,,0%
https://arxiv.org/pdf/2301.11497.pdf,D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts,Fenggen Yu,,0%
https://arxiv.org/pdf/2301.11497.pdf,D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts,Qimin Chen,,0%
https://arxiv.org/pdf/2301.11497.pdf,D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts,Maham Tanveer,,0%
https://arxiv.org/pdf/2301.11497.pdf,D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts,Ali Mahdavi Amiri,,0%
https://arxiv.org/pdf/2301.11497.pdf,D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts,Hao Zhang,,0%
https://arxiv.org/pdf/2301.11495.pdf,Skeleton-based Action Recognition through Contrasting Two-Stream Spatial-Temporal Networks,Lei Lyu,lvlei@sdnu.edu.cn,85%
https://arxiv.org/pdf/2301.11495.pdf,Skeleton-based Action Recognition through Contrasting Two-Stream Spatial-Temporal Networks,Chen Pang,,0%
https://arxiv.org/pdf/2301.11495.pdf,Skeleton-based Action Recognition through Contrasting Two-Stream Spatial-Temporal Networks,Xuequan Lu,,0%
https://arxiv.org/pdf/2301.11494.pdf,Learning Vortex Dynamics for Fluid Inference and Prediction,Yitong Deng,,0%
https://arxiv.org/pdf/2301.11494.pdf,Learning Vortex Dynamics for Fluid Inference and Prediction,Hong-xing Yu,,0%
https://arxiv.org/pdf/2301.11494.pdf,Learning Vortex Dynamics for Fluid Inference and Prediction,Jiajun Wu,,0%
https://arxiv.org/pdf/2301.11494.pdf,Learning Vortex Dynamics for Fluid Inference and Prediction,Bo Zhu,,0%
https://arxiv.org/pdf/2302.08901.pdf,Exploring External Knowledge for Accurate modeling of Visual and Language Problems,Xuewen Yang,,0%
https://arxiv.org/pdf/2302.10280.pdf,Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM,Jacob Mallet,,0%
https://arxiv.org/pdf/2302.10280.pdf,Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM,Laura Pryor,,0%
https://arxiv.org/pdf/2302.10280.pdf,Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM,Rushit Dave,,0%
https://arxiv.org/pdf/2302.10280.pdf,Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM,Mounika Vanamala,,0%
https://arxiv.org/pdf/2301.11468.pdf,Multi-limb Split Learning for Tumor Classification on Vertically Distributed Data,Mayar M. Alfares,mayar.mohamed@guc.edu.eg,85%
https://arxiv.org/pdf/2301.11468.pdf,Multi-limb Split Learning for Tumor Classification on Vertically Distributed Data,Mohammed A. -m. Salem,mohammed.salem@guc.edu.eg,95%
https://arxiv.org/pdf/2301.11468.pdf,Multi-limb Split Learning for Tumor Classification on Vertically Distributed Data,Omar S. Ads,omar.ads@student.guc.edu.eg,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Shu Hu,shuhu@cmu.edu,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Xi Wu,xi.wu@imde.ac.cn,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Siwei Lyu,siweilyu@buffalo.edu,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Yunxu Xie,xieyunxu@imde.ac.cn,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Xin Wang,xwang264@buffalo.edu,82%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Bin Zhu,binzhu@microsoft.com,95%
https://arxiv.org/pdf/2301.11457.pdf,Attacking Important Pixels for Anchor-free Detectors,Quanyu Liao,,0%
https://arxiv.org/pdf/2301.11454.pdf,Boundary Aware U-Net for Glacier Segmentation,Bibek Aryal,baryal@miners.utep.edu,82%
https://arxiv.org/pdf/2301.11454.pdf,Boundary Aware U-Net for Glacier Segmentation,Katie E. Miles,,0%
https://arxiv.org/pdf/2301.11454.pdf,Boundary Aware U-Net for Glacier Segmentation,Sergio A. Vargas Zesati,,0%
https://arxiv.org/pdf/2301.11454.pdf,Boundary Aware U-Net for Glacier Segmentation,Olac Fuentes,,0%
https://arxiv.org/pdf/2301.11445.pdf,3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models,Matthias Niessner,niessner@tum.de,78%
https://arxiv.org/pdf/2301.11445.pdf,3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models,Jiapeng Tang,jiapeng.tang@tum.de,95%
https://arxiv.org/pdf/2301.11445.pdf,3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models,Biao Zhang,biao.zhang@kaust.edu.sa,95%
https://arxiv.org/pdf/2301.11445.pdf,3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models,Peter Wonka,,0%
https://arxiv.org/pdf/2301.11431.pdf,Semidefinite Relaxations for Robust Multiview Triangulation,Daniel Cremers,cremers@tum.de,78%
https://arxiv.org/pdf/2301.11431.pdf,Semidefinite Relaxations for Robust Multiview Triangulation,Linus Härenstam-nielsen,linus.nielsen@tum.de,85%
https://arxiv.org/pdf/2301.11431.pdf,Semidefinite Relaxations for Robust Multiview Triangulation,Niclas Zeller,niclas.zeller@h-ka.de,95%
https://arxiv.org/pdf/2301.11422.pdf,RMSim: Controlled Respiratory Motion Simulation on Static Patient Scans,Masoud Zarepisheh,zarepism@mskcc.org,65%
https://arxiv.org/pdf/2301.11422.pdf,RMSim: Controlled Respiratory Motion Simulation on Static Patient Scans,Donghoon Lee,leed10@mskcc.org,78%
https://arxiv.org/pdf/2301.11422.pdf,RMSim: Controlled Respiratory Motion Simulation on Static Patient Scans,Yu-chi Hu,huj@mskcc.org,78%
https://arxiv.org/pdf/2301.11422.pdf,RMSim: Controlled Respiratory Motion Simulation on Static Patient Scans,Saad Nadeem,nadeems@mskcc.org,78%
https://arxiv.org/pdf/2301.11422.pdf,RMSim: Controlled Respiratory Motion Simulation on Static Patient Scans,Ellen Yorke,yorkee@mskcc.org,78%
https://arxiv.org/pdf/2301.11418.pdf,Parkinson gait modelling from an anomaly deep representation,Edgar Rangel,edgar.rangel@correo.uis.edu.co,95%
https://arxiv.org/pdf/2301.11418.pdf,Parkinson gait modelling from an anomaly deep representation,Fabio Martinez,,0%
https://arxiv.org/pdf/2301.11417.pdf,Are Labels Needed for Incremental Instance Learning?,Joaquin Vanschoren,j.vanschoren@tue.nl,82%
https://arxiv.org/pdf/2301.11417.pdf,Are Labels Needed for Incremental Instance Learning?,Mert Kilickaya,kilickayamert@gmail.com,95%
https://arxiv.org/pdf/2301.11405.pdf,Discriminative Entropy Clustering and its Relation to K-means and SVM,Zhongwen Zhang,z889zhan@uwaterloo.ca,65%
https://arxiv.org/pdf/2301.11405.pdf,Discriminative Entropy Clustering and its Relation to K-means and SVM,Yuri Boykov,yboykov@uwaterloo.ca,82%
https://arxiv.org/pdf/2301.11387.pdf,Universal Domain Adaptation for Remote Sensing Image Scene Classification,Qingsong Xu,qingsong.xu@tum.de,95%
https://arxiv.org/pdf/2301.11387.pdf,Universal Domain Adaptation for Remote Sensing Image Scene Classification,Xin Yuan,xyuan@westlake.edu.cn,82%
https://arxiv.org/pdf/2301.11387.pdf,Universal Domain Adaptation for Remote Sensing Image Scene Classification,Xiao Xiang Zhu,xiaoxiang.zhu@tum.de,95%
https://arxiv.org/pdf/2301.11387.pdf,Universal Domain Adaptation for Remote Sensing Image Scene Classification,Yilei Shi,yilei.shi@tum.de,95%
https://arxiv.org/pdf/2301.11367.pdf,Style-Aware Contrastive Learning for Multi-Style Image Captioning,Guodong Long,guodong.long@uts.edu.au,95%
https://arxiv.org/pdf/2301.11367.pdf,Style-Aware Contrastive Learning for Multi-Style Image Captioning,Yucheng Zhou,yucheng.zhou-1@student.uts.edu.au,95%
https://arxiv.org/pdf/2301.11362.pdf,Improving Cross-modal Alignment for Text-Guided Image Inpainting,Guodong Long,guodong.long@uts.edu.au,95%
https://arxiv.org/pdf/2301.11362.pdf,Improving Cross-modal Alignment for Text-Guided Image Inpainting,Yucheng Zhou,yucheng.zhou-1@student.uts.edu.au,95%
https://arxiv.org/pdf/2301.11360.pdf,The Power of Linear Combinations: Learning with Random Convolutions,Paul Gavrikov,paul.gavrikov@hs-offenburg.de,95%
https://arxiv.org/pdf/2301.11360.pdf,The Power of Linear Combinations: Learning with Random Convolutions,Janis Keuper,janis.keuper@hs-offenburg.de,95%
https://arxiv.org/pdf/2301.11357.pdf,Multimodal Event Transformer for Image-guided Story Ending Generation,Guodong Long,guodong.long@uts.edu.au,95%
https://arxiv.org/pdf/2301.11357.pdf,Multimodal Event Transformer for Image-guided Story Ending Generation,Yucheng Zhou,yucheng.zhou-1@student.uts.edu.au,95%
https://arxiv.org/pdf/2301.11329.pdf,Anatomy-aware and acquisition-agnostic joint registration with SynthMorph,Malte Hoffmann,mhoffmann@mgh.harvard.edu,82%
https://arxiv.org/pdf/2301.11329.pdf,Anatomy-aware and acquisition-agnostic joint registration with SynthMorph,Andrew Hoopes,,0%
https://arxiv.org/pdf/2301.11329.pdf,Anatomy-aware and acquisition-agnostic joint registration with SynthMorph,Douglas N. Greve,,0%
https://arxiv.org/pdf/2301.11329.pdf,Anatomy-aware and acquisition-agnostic joint registration with SynthMorph,Bruce Fischl,,0%
https://arxiv.org/pdf/2301.11329.pdf,Anatomy-aware and acquisition-agnostic joint registration with SynthMorph,Adrian V. Dalca,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Aliaksandr Siarohin,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Willi Menapace,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Ivan Skorokhodov,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Kyle Olszewski,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Jian Ren,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Hsin-ying Lee,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Menglei Chai,,0%
https://arxiv.org/pdf/2301.11326.pdf,Unsupervised Volumetric Animation,Sergey Tulyakov,,0%
https://arxiv.org/pdf/2301.11320.pdf,Cut and Learn for Unsupervised Object Detection and Instance Segmentation,Xudong Wang,,0%
https://arxiv.org/pdf/2301.11320.pdf,Cut and Learn for Unsupervised Object Detection and Instance Segmentation,Rohit Girdhar,,0%
https://arxiv.org/pdf/2301.11320.pdf,Cut and Learn for Unsupervised Object Detection and Instance Segmentation,Stella X. Yu,,0%
https://arxiv.org/pdf/2301.11320.pdf,Cut and Learn for Unsupervised Object Detection and Instance Segmentation,Ishan Misra,,0%
https://arxiv.org/pdf/2301.11316.pdf,Open Problems in Applied Deep Learning,Maziar Raissi,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Mingquan Lin,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Yuyun Xiao,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Bojian Hou,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Tingyi Wanyan,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Mohit Manoj Sharma,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Zhangyang Wang,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Fei Wang,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Sarah Van Tassel,,0%
https://arxiv.org/pdf/2301.11315.pdf,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served patient populations,Yifan Peng,,0%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Luca De Luigi,luca.deluigi4@unibo.it,95%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Pierluigi Zama Ramirez,pierluigi.zama@unibo.it,85%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Samuele Salti,samuele.salti@unibo.it,95%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Alessio Tonioni,alessiot@google.com,85%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Luigi Di Stefano,luigi.distefano@unibo.it,95%
https://arxiv.org/pdf/2301.11310.pdf,Learning Good Features to Transfer Across Tasks and Domains,Adriano Cardace,adriano.cardace2@unibo.it,95%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Uriel Singer,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Shelly Sheynin,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Adam Polyak,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Oron Ashual,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Iurii Makarov,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Filippos Kokkinos,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Naman Goyal,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Andrea Vedaldi,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Devi Parikh,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Justin Johnson,,0%
https://arxiv.org/pdf/2301.11280.pdf,Text-To-4D Dynamic Scene Generation,Yaniv Taigman,,0%
https://arxiv.org/pdf/2301.11274.pdf,Self-Supervised RGB-T Tracking with Cross-Input Consistency,Xingchen Zhang,xingchen.zhang@imperial.ac.uk,95%
https://arxiv.org/pdf/2301.11274.pdf,Self-Supervised RGB-T Tracking with Cross-Input Consistency,Yiannis Demiris,y.demiris@imperial.ac.uk,82%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Xianglong Liu,xlliu@buaa.edu.cn,82%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Haotong Qin,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Mingyuan Zhang,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Yifu Ding,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Aoyu Li,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Zhongang Cai,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Ziwei Liu,,0%
https://arxiv.org/pdf/2301.11233.pdf,BiBench: Benchmarking and Analyzing Network Binarization,Fisher Yu,,0%
https://arxiv.org/pdf/2301.11201.pdf,Relative-Interior Solution for the (Incomplete) Linear Assignment Problem with Applications to the Quadratic Assignment Problem,Bogdan Savchynskyy,bogdan.savchynskyy@iwr.uni-heidelberg.de,95%
https://arxiv.org/pdf/2301.11201.pdf,Relative-Interior Solution for the (Incomplete) Linear Assignment Problem with Applications to the Quadratic Assignment Problem,Tomáš Dlask,dlaskto2@fel.cvut.cz,78%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Derek Gloudemans,derek.gloudemans@vanderbilt.edu,95%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Yanbing Wang,,0%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Junyi Ji,,0%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Gergely Zachar,,0%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Will Barbour,,0%
https://arxiv.org/pdf/2301.11198.pdf,I-24 MOTION: An instrument for freeway traffic science,Daniel B. Work,,0%
https://arxiv.org/pdf/2301.11189.pdf,Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models,Matthew J. Muckley,mmuckley@meta.com,82%
https://arxiv.org/pdf/2301.11189.pdf,Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models,Alaaeldin El-nouby,,0%
https://arxiv.org/pdf/2301.11189.pdf,Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models,Karen Ullrich,,0%
https://arxiv.org/pdf/2301.11189.pdf,Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models,Hervé Jégou,,0%
https://arxiv.org/pdf/2301.11189.pdf,Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models,Jakob Verbeek,,0%
https://arxiv.org/pdf/2301.11180.pdf,Low-Rank Winograd Transformation for 3D Convolutional Neural Networks,Mingbao Lin,linmb001@outlook.com,78%
https://arxiv.org/pdf/2301.11180.pdf,Low-Rank Winograd Transformation for 3D Convolutional Neural Networks,Ziran Qin,qinziran@sjtu.edu.cn,95%
https://arxiv.org/pdf/2301.11180.pdf,Low-Rank Winograd Transformation for 3D Convolutional Neural Networks,Weiyao Lin,wylin@sjtu.edu.cn,82%
https://arxiv.org/pdf/2301.11174.pdf,Semi-Supervised Image Captioning by Adversarially Propagating Labeled Data,Tae-hyun Oh,taehyun@postech.ac.kr,85%
https://arxiv.org/pdf/2301.11174.pdf,Semi-Supervised Image Captioning by Adversarially Propagating Labeled Data,Dong-jin Kim,jinsc37@kaist.ac.kr,85%
https://arxiv.org/pdf/2301.11174.pdf,Semi-Supervised Image Captioning by Adversarially Propagating Labeled Data,In So Kweon,iskweon77@kaist.ac.kr,82%
https://arxiv.org/pdf/2301.11174.pdf,Semi-Supervised Image Captioning by Adversarially Propagating Labeled Data,Jinsoo Choi,,0%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Michal Kawulok,michal.kawulok@polsl.pl,95%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Jakub Nalepa,jakub.nalepa@polsl.pl,95%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Tomasz Tarasiewicz,tomasz.tarasiewicz@polsl.pl,95%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Reuben A. Farrugia,,0%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Gianluca Valentino,,0%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Mang Chen,,0%
https://arxiv.org/pdf/2301.11154.pdf,Multitemporal and multispectral data fusion for super-resolution of Sentinel-2 images,Johann A. Briffa,,0%
https://arxiv.org/pdf/2301.11145.pdf,Learning from Mistakes: Self-Regularizing Hierarchical Representations in Point Cloud Semantic Segmentation,Umberto Michieli,umberto.michieli@dei.unipd.it,95%
https://arxiv.org/pdf/2301.11145.pdf,Learning from Mistakes: Self-Regularizing Hierarchical Representations in Point Cloud Semantic Segmentation,Elena Camuffo,elena.camuffo@dei.unipd.it,95%
https://arxiv.org/pdf/2301.11145.pdf,Learning from Mistakes: Self-Regularizing Hierarchical Representations in Point Cloud Semantic Segmentation,Simone Milani,simone.milani@dei.unipd.it,95%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Jingjia Huang,huangjingjia@bytedance.com,95%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Jiashi Feng,jshfeng@bytedance.com,82%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Xinglong Wu,wuxinglong@bytedance.com,95%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Thomas H. Li,thomas@.pku.edu.cn,85%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Ruyang Liu,,0%
https://arxiv.org/pdf/2301.11116.pdf,Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring,Ge Li,,0%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Sangwoo Mo,swmo@umich.edu,82%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Younghyun Kim,younghyun.kim@kaist.ac.kr,95%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Minkyu Kim,,0%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Kyungmin Lee,,0%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Jaeho Lee,,0%
https://arxiv.org/pdf/2301.11104.pdf,Discovering and Mitigating Visual Biases through Keyword Explanation,Jinwoo Shin,,0%
https://arxiv.org/pdf/2301.11100.pdf,Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities,Melissa Hall,melissahall@meta.com,95%
https://arxiv.org/pdf/2301.11100.pdf,Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities,Candace Ross,ccross@meta.com,82%
https://arxiv.org/pdf/2301.11100.pdf,Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities,Laura Gustafson,,0%
https://arxiv.org/pdf/2301.11100.pdf,Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities,Aaron Adcock,,0%
https://arxiv.org/pdf/2301.11100.pdf,Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities,Ishan Misra,,0%
https://arxiv.org/pdf/2301.11093.pdf,Simple diffusion: End-to-end diffusion for high resolution images,Emiel Hoogeboom,emielh@google.com,85%
https://arxiv.org/pdf/2301.11093.pdf,Simple diffusion: End-to-end diffusion for high resolution images,Jonathan Heek,,0%
https://arxiv.org/pdf/2301.11093.pdf,Simple diffusion: End-to-end diffusion for high resolution images,Tim Salimans,,0%
https://arxiv.org/pdf/2301.11779.pdf,Invariant Meta Learning for Out-of-Distribution Generalization,Penghao Jiang,,0%
https://arxiv.org/pdf/2301.11779.pdf,Invariant Meta Learning for Out-of-Distribution Generalization,Ke Xin,,0%
https://arxiv.org/pdf/2301.11779.pdf,Invariant Meta Learning for Out-of-Distribution Generalization,Zifeng Wang,,0%
https://arxiv.org/pdf/2301.11779.pdf,Invariant Meta Learning for Out-of-Distribution Generalization,Chunxi Li,,0%
https://arxiv.org/pdf/2301.11065.pdf,Inspecting class hierarchies in classification-based metric learning models,Hyeongji Kim,,0%
https://arxiv.org/pdf/2301.11065.pdf,Inspecting class hierarchies in classification-based metric learning models,Pekka Parviainen,,0%
https://arxiv.org/pdf/2301.11065.pdf,Inspecting class hierarchies in classification-based metric learning models,Terje Berge,,0%
https://arxiv.org/pdf/2301.11065.pdf,Inspecting class hierarchies in classification-based metric learning models,Ketil Malde,,0%
https://arxiv.org/pdf/2301.11063.pdf,Rewarded meta-pruning: Meta Learning with Rewards for Channel Pruning,Abhishek Kumar,abhishek.ai@knu.ac.kr,85%
https://arxiv.org/pdf/2301.11063.pdf,Rewarded meta-pruning: Meta Learning with Rewards for Channel Pruning,Athul Shibu,athulshibu@knu.ac.kr,95%
https://arxiv.org/pdf/2301.11063.pdf,Rewarded meta-pruning: Meta Learning with Rewards for Channel Pruning,Dong-gyu Lee,dglee@knu.ac.kr,82%
https://arxiv.org/pdf/2301.11063.pdf,Rewarded meta-pruning: Meta Learning with Rewards for Channel Pruning,Heechul Jung,heechul@knu.ac.kr,85%
https://arxiv.org/pdf/2302.01394.pdf,Understanding and contextualising diffusion models,Stefano Scotta,,0%
https://arxiv.org/pdf/2302.01394.pdf,Understanding and contextualising diffusion models,Alberto Messina,,0%
https://arxiv.org/pdf/2301.11022.pdf,Semantic Segmentation Enhanced Transformer Model for Human Attention Prediction,Shuo Zhang,,0%
https://arxiv.org/pdf/2301.11015.pdf,Explore the Power of Dropout on Few-shot Learning,Shaobo Lin,,0%
https://arxiv.org/pdf/2301.11015.pdf,Explore the Power of Dropout on Few-shot Learning,Xingyu Zeng,,0%
https://arxiv.org/pdf/2301.11015.pdf,Explore the Power of Dropout on Few-shot Learning,Rui Zhao,,0%
https://arxiv.org/pdf/2301.11785.pdf,Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization,Yao Zhao,yzhao@bjtu.edu.cn,82%
https://arxiv.org/pdf/2301.11785.pdf,Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization,Shangrong Yang,sr yang@bjtu.edu.cn,82%
https://arxiv.org/pdf/2301.11785.pdf,Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization,Kang Liao,kang liao@bjtu.edu.cn,95%
https://arxiv.org/pdf/2301.11785.pdf,Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization,Chunyu Lin,cylin@bjtu.edu.cn,82%
https://arxiv.org/pdf/2301.10972.pdf,On the Importance of Noise Scheduling for Diffusion Models,Ting Chen,iamtingchen@google.com,95%
https://arxiv.org/pdf/2301.10958.pdf,Learning Large Scale Sparse Models,Atul Dhingra,atul.dhingra@rutgers.edu,95%
https://arxiv.org/pdf/2301.10958.pdf,Learning Large Scale Sparse Models,Jie Shen,,0%
https://arxiv.org/pdf/2301.10958.pdf,Learning Large Scale Sparse Models,Nicholas Kleene,,0%
https://arxiv.org/pdf/2301.10957.pdf,Neurorehab: An Interface for Rehabilitation,Atul Dhingra,,0%
https://arxiv.org/pdf/2301.10957.pdf,Neurorehab: An Interface for Rehabilitation,Adeboye A. Adejare,,0%
https://arxiv.org/pdf/2301.10957.pdf,Neurorehab: An Interface for Rehabilitation,Adam Fendler,,0%
https://arxiv.org/pdf/2301.10957.pdf,Neurorehab: An Interface for Rehabilitation,Roopeswar Kommalapati,,0%
https://arxiv.org/pdf/2301.10951.pdf,Cross Modal Global Local Representation Learning from Radiology Reports and X-Ray Chest Images,Ali Vosoughi,mvosough@ece.rochester.edu,55%
https://arxiv.org/pdf/2301.10951.pdf,Cross Modal Global Local Representation Learning from Radiology Reports and X-Ray Chest Images,Nathan Hadjiyski,,0%
https://arxiv.org/pdf/2301.10951.pdf,Cross Modal Global Local Representation Learning from Radiology Reports and X-Ray Chest Images,Axel Wismueller,,0%
https://arxiv.org/pdf/2301.10941.pdf,GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency,Jiuhn Song,song@korea.ac.kr,78%
https://arxiv.org/pdf/2301.10941.pdf,GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency,Seungryong Kim,kim@korea.ac.kr,78%
https://arxiv.org/pdf/2301.10941.pdf,GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency,Min-seop Kwak,mskwak01@korea.ac.kr,82%
https://arxiv.org/pdf/2301.10939.pdf,Affective Faces for Goal-Driven Dyadic Communication,Sachit Menon,sachit.menon@columbia.edu,95%
https://arxiv.org/pdf/2301.10939.pdf,Affective Faces for Goal-Driven Dyadic Communication,Scott Geng,scott.geng@columbia.edu,95%
https://arxiv.org/pdf/2301.10939.pdf,Affective Faces for Goal-Driven Dyadic Communication,Revant Teotia,,0%
https://arxiv.org/pdf/2301.10939.pdf,Affective Faces for Goal-Driven Dyadic Communication,Purva Tendulkar,,0%
https://arxiv.org/pdf/2301.10939.pdf,Affective Faces for Goal-Driven Dyadic Communication,Carl Vondrick,,0%
https://arxiv.org/pdf/2301.10938.pdf,Compact Transformer Tracker with Correlative Masked Modeling,Junqing Yu,yjqing@hust.edu.cn,75%
https://arxiv.org/pdf/2301.10938.pdf,Compact Transformer Tracker with Correlative Masked Modeling,Zikai Song,skyesong@hust.edu.cn,78%
https://arxiv.org/pdf/2301.10938.pdf,Compact Transformer Tracker with Correlative Masked Modeling,Yi-ping Phoebe Chen,phoebe.chen@latrobe.edu.au,78%
https://arxiv.org/pdf/2301.10938.pdf,Compact Transformer Tracker with Correlative Masked Modeling,Wei Yang,weiyangcs@hust.edu.cn,95%
https://arxiv.org/pdf/2301.10938.pdf,Compact Transformer Tracker with Correlative Masked Modeling,Run Luo,,0%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Fanman Meng,fmmeng@uestc.edu.cn,82%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Qingbo Wu,qbwu@uestc.edu.cn,82%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Linfeng Xu,lfxu@uestc.edu.cn,82%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Hongliang Li,hlli@uestc.edu.cn,82%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Lili Pan,lilipan@uestc.edu.cn,95%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Chiyuan He,,0%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Hanxin Wang,,0%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Shaoxu Cheng,,0%
https://arxiv.org/pdf/2301.10931.pdf,Towards Continual Egocentric Activity Recognition: A Multi-modal Egocentric Activity Dataset for Continual Learning,Yu Dai,,0%
https://arxiv.org/pdf/2301.10922.pdf,Detecting Building Changes with Off-Nadir Aerial Images,Gui-song Xia,guisong.xia@whu.edu.cn,95%
https://arxiv.org/pdf/2301.10922.pdf,Detecting Building Changes with Off-Nadir Aerial Images,Chao Pang,,0%
https://arxiv.org/pdf/2301.10922.pdf,Detecting Building Changes with Off-Nadir Aerial Images,Jiang Wu,,0%
https://arxiv.org/pdf/2301.10922.pdf,Detecting Building Changes with Off-Nadir Aerial Images,Jian Ding,,0%
https://arxiv.org/pdf/2301.10922.pdf,Detecting Building Changes with Off-Nadir Aerial Images,Can Song,,0%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Ran Tao,taoran1@cmu.edu,95%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Marios Savvides,marioss@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Hao Chen,haoc3@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Jindong Wang,jindong.wang@microsoft.com,95%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Yue Fan,,0%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Yidong Wang,,0%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Bernt Schiele,,0%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Xing Xie,,0%
https://arxiv.org/pdf/2301.10921.pdf,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,Bhiksha Raj,,0%
https://arxiv.org/pdf/2301.10916.pdf,ITstyler: Image-optimized Text-based Style Transfer,Yunpeng Bai,,0%
https://arxiv.org/pdf/2301.10916.pdf,ITstyler: Image-optimized Text-based Style Transfer,Jiayue Liu,,0%
https://arxiv.org/pdf/2301.10916.pdf,ITstyler: Image-optimized Text-based Style Transfer,Chao Dong,,0%
https://arxiv.org/pdf/2301.10916.pdf,ITstyler: Image-optimized Text-based Style Transfer,Chun Yuan,,0%
https://arxiv.org/pdf/2301.10908.pdf,Distilling Cognitive Backdoor Patterns within an Image,James Bailey,baileyj@unimelb.edu.au,78%
https://arxiv.org/pdf/2301.10908.pdf,Distilling Cognitive Backdoor Patterns within an Image,Xingjun Ma,xingjunma@fudan.edu.cn,95%
https://arxiv.org/pdf/2301.10908.pdf,Distilling Cognitive Backdoor Patterns within an Image,Sarah Erfani,sarah.erfani@unimelb.edu.au,95%
https://arxiv.org/pdf/2301.10908.pdf,Distilling Cognitive Backdoor Patterns within an Image,Hanxun Huang,hanxunh@student.unimelb.edu.au,85%
https://arxiv.org/pdf/2301.10906.pdf,Facial Expression Recognition using Squeeze and Excitation-powered Swin Transformers,Arpita Vats,avats@scu.edu,82%
https://arxiv.org/pdf/2301.10906.pdf,Facial Expression Recognition using Squeeze and Excitation-powered Swin Transformers,Aman Chadha,,0%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Errui Ding,dingerrui@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Jian Wang,wangjian33@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Xinggang Wang,xgwang@hust.edu.cn,82%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Jingdong Wang,wangjingdong@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Haocheng Feng,fenghaocheng@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Xiaohu Huang,huangxiaohu@hust.edu.cn,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Junyu Han,hanjunyu@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Hao Zhou,zhouhao14@baidu.com,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Bin Feng,fengbin@hust.edu.cn,95%
https://arxiv.org/pdf/2301.10900.pdf,Graph Contrastive Learning for Skeleton-based Action Recognition,Wenyu Liu,liuwy@hust.edu.cn,78%
https://arxiv.org/pdf/2301.10877.pdf,The Projection-Enhancement Network (PEN),Bo Sun,sunb@onid.orst.edu,78%
https://arxiv.org/pdf/2301.10877.pdf,The Projection-Enhancement Network (PEN),Christopher Z. Eddy,,0%
https://arxiv.org/pdf/2301.10877.pdf,The Projection-Enhancement Network (PEN),Austin Naylor,,0%
https://arxiv.org/pdf/2301.10876.pdf,Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing,Rohitash Chandra,rohitash.chandra@unsw.edu.au,95%
https://arxiv.org/pdf/2301.10876.pdf,Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing,Saharsh Barve,saharshbarve3@gmail.com,95%
https://arxiv.org/pdf/2301.10876.pdf,Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing,Jody M. Webster,jody.webster@sydney.edu.au,95%
https://arxiv.org/pdf/2301.10863.pdf,Shape Reconstruction from Thoracoscopic Images using Self-supervised Virtual Learning,Tomoki Oya,t-oya@sys.i.kyoto-u.ac.jp,82%
https://arxiv.org/pdf/2301.10863.pdf,Shape Reconstruction from Thoracoscopic Images using Self-supervised Virtual Learning,Megumi Nakao,,0%
https://arxiv.org/pdf/2301.10863.pdf,Shape Reconstruction from Thoracoscopic Images using Self-supervised Virtual Learning,Tetsuya Matsuda,,0%
https://arxiv.org/pdf/2301.10847.pdf,Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach,Yiwei Jia,yiwei.jia@lfb.rwth-aachen.de,95%
https://arxiv.org/pdf/2301.10847.pdf,Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach,Reza Azad,reza.azad; yiwei.jia@lfb.rwth-aachen.de,95%
https://arxiv.org/pdf/2301.10847.pdf,Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach,Julien Cohen-adad,jcohen@polymtl.ca,90%
https://arxiv.org/pdf/2301.10847.pdf,Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach,Dorit Merhof,dorit.merhof@ur.de,95%
https://arxiv.org/pdf/2301.10847.pdf,Enhancing Medical Image Segmentation with TransCeption: A Multi-Scale Feature Fusion Approach,Ehsan Khodapanah Aghdam,ehsan.khpaghdam@gmail.com,95%
https://arxiv.org/pdf/2301.10829.pdf,TranSOP: Transformer-based Multimodal Classification for Stroke Treatment Outcome Prediction,Zeynel A. Samak,,0%
https://arxiv.org/pdf/2301.10829.pdf,TranSOP: Transformer-based Multimodal Classification for Stroke Treatment Outcome Prediction,Philip Clatworthy,,0%
https://arxiv.org/pdf/2301.10829.pdf,TranSOP: Transformer-based Multimodal Classification for Stroke Treatment Outcome Prediction,Majid Mirmehdi,,0%
https://arxiv.org/pdf/2301.10766.pdf,On the Adversarial Robustness of Camera-based 3D Object Detection,Zichao Li,zli489@ucsc.edu,82%
https://arxiv.org/pdf/2301.10766.pdf,On the Adversarial Robustness of Camera-based 3D Object Detection,Shaoyuan Xie,shaoyux@uci.edu,84%
https://arxiv.org/pdf/2301.10766.pdf,On the Adversarial Robustness of Camera-based 3D Object Detection,Cihang Xie,cixie@ucsc.edu,82%
https://arxiv.org/pdf/2301.10766.pdf,On the Adversarial Robustness of Camera-based 3D Object Detection,Zeyu Wang,zwang615@ucsc.edu,82%
https://arxiv.org/pdf/2301.10759.pdf,Efficient Flow-Guided Multi-frame De-fencing,Stavros Tsogkas,stavros.t@samsung.com,85%
https://arxiv.org/pdf/2301.10759.pdf,Efficient Flow-Guided Multi-frame De-fencing,Alex Levinshtein,alex.lev@samsung.com,85%
https://arxiv.org/pdf/2301.10759.pdf,Efficient Flow-Guided Multi-frame De-fencing,Fengjia Zhang,f.zhang2@samsung.com,82%
https://arxiv.org/pdf/2301.10759.pdf,Efficient Flow-Guided Multi-frame De-fencing,Allan Jepson,allan.jepson@samsung.com,95%
https://arxiv.org/pdf/2301.10750.pdf,Out of Distribution Performance of State of Art Vision Model,Salman Rahman,salman@nyu.edu,85%
https://arxiv.org/pdf/2301.10750.pdf,Out of Distribution Performance of State of Art Vision Model,Wonkwon Lee,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Aotian Wu,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Pan He,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Xiao Li,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Ke Chen,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Sanjay Ranka,,0%
https://arxiv.org/pdf/2301.10732.pdf,An Efficient Semi-Automated Scheme for Infrastructure LiDAR Annotation,Anand Rangarajan,,0%
https://arxiv.org/pdf/2301.10687.pdf,Self-Supervised Curricular Deep Learning for Chest X-Ray Image Classification,Iván De Andrés Tamé,ivan.andrest@estudiante.uam.es,85%
https://arxiv.org/pdf/2301.10687.pdf,Self-Supervised Curricular Deep Learning for Chest X-Ray Image Classification,Marcos Escudero-viñolo,marcos.escudero@uam.es,85%
https://arxiv.org/pdf/2301.10687.pdf,Self-Supervised Curricular Deep Learning for Chest X-Ray Image Classification,Pablo Carballeira,pablo.carballeira@uam.es,95%
https://arxiv.org/pdf/2301.10687.pdf,Self-Supervised Curricular Deep Learning for Chest X-Ray Image Classification,Kirill Sirotkin,kirill.sirotkin@uam.es,95%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Yunpeng Bai,,0%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Zihan Zhong,,0%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Chao Dong,,0%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Weichen Zhang,,0%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Guowei Xu,,0%
https://arxiv.org/pdf/2301.10670.pdf,Towards Arbitrary Text-driven Image Manipulation via Space Alignment,Chun Yuan,,0%
https://arxiv.org/pdf/2301.10625.pdf,Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment,Carsten T. Lüth,carsten.lueth@dkfz-heidelberg.de,85%
https://arxiv.org/pdf/2301.10625.pdf,Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment,Till J. Bungert,,0%
https://arxiv.org/pdf/2301.10625.pdf,Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment,Lukas Klein,,0%
https://arxiv.org/pdf/2301.10625.pdf,Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment,Paul F. Jaeger,,0%
https://arxiv.org/pdf/2301.10611.pdf,Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification,Enjie Ghorbel,enjie.ghorbel@uni.lu,95%
https://arxiv.org/pdf/2301.10611.pdf,Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification,Djamila Aouada,djamila.aouada@uni.lu,95%
https://arxiv.org/pdf/2301.10611.pdf,Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification,Arunkumar Rathinam,arunkumar.rathinam@uni.lu,95%
https://arxiv.org/pdf/2301.10611.pdf,Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification,Anis Kacem,anis.kacem@uni.lu,95%
https://arxiv.org/pdf/2301.10611.pdf,Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification,Indel Pal Singh,inder.singh@uni.lu,82%
https://arxiv.org/pdf/2301.10608.pdf,Connecting metrics for shape-texture knowledge in computer vision,Tiago Oliveira,,0%
https://arxiv.org/pdf/2301.10608.pdf,Connecting metrics for shape-texture knowledge in computer vision,Tiago Marques,,0%
https://arxiv.org/pdf/2301.10608.pdf,Connecting metrics for shape-texture knowledge in computer vision,Arlindo L. Oliveira,,0%
https://arxiv.org/pdf/2302.10801.pdf,Deep Generative Neural Embeddings for High Dimensional Data Visualization,Gerardo Hermosillo Valadez,gerardo.hermosillovaladez@siemens-healthineers.com,95%
https://arxiv.org/pdf/2302.10801.pdf,Deep Generative Neural Embeddings for High Dimensional Data Visualization,Halid Ziya Yerebakan,halid.yerebakan@siemens-healthineers.com,95%
https://arxiv.org/pdf/2301.10593.pdf,Faster DAN: Multi-target Queries with Document Positional Encoding for End-to-end Handwritten Document Recognition,Denis Coquenet,denis.coquenet@lecnam.net,95%
https://arxiv.org/pdf/2301.10593.pdf,Faster DAN: Multi-target Queries with Document Positional Encoding for End-to-end Handwritten Document Recognition,Thierry Paquet,thierry.paquet@litislab.eu,95%
https://arxiv.org/pdf/2301.10593.pdf,Faster DAN: Multi-target Queries with Document Positional Encoding for End-to-end Handwritten Document Recognition,Clément Chatelain,clement.chatelain@litislab.eu,95%
https://arxiv.org/pdf/2301.10584.pdf,A Method For Eliminating Contour Errors In Self-Encoder Reconstructed Images,Hao Zhang,haozhang@stu.sicnu.edu.cn,95%
https://arxiv.org/pdf/2301.10584.pdf,A Method For Eliminating Contour Errors In Self-Encoder Reconstructed Images,Yonggang Li,,0%
https://arxiv.org/pdf/2301.10583.pdf,An Efficient Approximate Method for Online Convolutional Dictionary Learning,Farshad G. Veshki,,0%
https://arxiv.org/pdf/2301.10583.pdf,An Efficient Approximate Method for Online Convolutional Dictionary Learning,Sergiy A. Vorobyov,,0%
https://arxiv.org/pdf/2301.10575.pdf,Trainable Loss Weights in Super-Resolution,Arash Chaichi Mellatshahi,,0%
https://arxiv.org/pdf/2301.10575.pdf,Trainable Loss Weights in Super-Resolution,Shohreh Kasaei,,0%
https://arxiv.org/pdf/2301.10559.pdf,Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking,Chamath Abeysinghe,chamath.abeysinghe@monash.edu,95%
https://arxiv.org/pdf/2301.10559.pdf,Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking,Bernd Meyer,bernd.meyer@monash.edu,95%
https://arxiv.org/pdf/2301.10559.pdf,Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking,Chris Reid,chris.reid@mq.edu.au,95%
https://arxiv.org/pdf/2301.10559.pdf,Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking,Hamid Rezatofighi,hamid.rezatoﬁghi@monash.edu,95%
https://arxiv.org/pdf/2301.10551.pdf,Variation-Aware Semantic Image Synthesis,Mingle Xu,,0%
https://arxiv.org/pdf/2301.10551.pdf,Variation-Aware Semantic Image Synthesis,Jaehwan Lee,,0%
https://arxiv.org/pdf/2301.10551.pdf,Variation-Aware Semantic Image Synthesis,Sook Yoon,,0%
https://arxiv.org/pdf/2301.10551.pdf,Variation-Aware Semantic Image Synthesis,Hyongsuk Kim,,0%
https://arxiv.org/pdf/2301.10551.pdf,Variation-Aware Semantic Image Synthesis,Dong Sun Park,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,David W. Romero,d.w.romeroguzman@vu.nl,82%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,David M. Knigge,d.m.knigge@uva.nl,82%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Albert Gu,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Efstratios Gavves,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Erik J. Bekkers,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Jakub M. Tomczak,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Mark Hoogendoorn,,0%
https://arxiv.org/pdf/2301.10540.pdf,Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN,Jan-jakob Sonke,,0%
https://arxiv.org/pdf/2301.10531.pdf,3D Tooth Mesh Segmentation with Simplified Mesh Cell Representation,Ananya Jana,,0%
https://arxiv.org/pdf/2301.10531.pdf,3D Tooth Mesh Segmentation with Simplified Mesh Cell Representation,Hrebesh Molly Subhash,,0%
https://arxiv.org/pdf/2301.10531.pdf,3D Tooth Mesh Segmentation with Simplified Mesh Cell Representation,Dimitris N. Metaxas,,0%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Nassir Navab,nassir.navab@tum.de,95%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Mehrdad Salehi,mehrdad.salehi@tum.de,95%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Benjamin Busam,b.busam@tum.de,82%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Christine Eilers,christine.eilers@tum.de,95%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Mohammad Farid Azampour,mf.azampour@tum.de,82%
https://arxiv.org/pdf/2301.10520.pdf,Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging,Magdalena Wysocki,magdalena.wysocki@tum.de,95%
https://arxiv.org/pdf/2302.10306.pdf,Deep Convolutional Framelet Denoising for Panoramic by Mixed Wavelet Integration,Masoud Shahraki Mohammadi,mahdavi@mshdiau.ac.ir,65%
https://arxiv.org/pdf/2302.10306.pdf,Deep Convolutional Framelet Denoising for Panoramic by Mixed Wavelet Integration,Seyed Javad Seyed Mahdavi Chabok,,0%
https://arxiv.org/pdf/2301.10492.pdf,Flow-guided Semi-supervised Video Object Segmentation,Yushan Zhang,,0%
https://arxiv.org/pdf/2301.10492.pdf,Flow-guided Semi-supervised Video Object Segmentation,Andreas Robinson,,0%
https://arxiv.org/pdf/2301.10492.pdf,Flow-guided Semi-supervised Video Object Segmentation,Maria Magnusson,,0%
https://arxiv.org/pdf/2301.10492.pdf,Flow-guided Semi-supervised Video Object Segmentation,Michael Felsberg,,0%
https://arxiv.org/pdf/2301.10473.pdf,Aircraft Skin Inspections: Towards a New Model for Dent Evaluation,Pasquale Lafiosca,pasquale.lafiosca@cranfield.ac.uk,95%
https://arxiv.org/pdf/2301.10473.pdf,Aircraft Skin Inspections: Towards a New Model for Dent Evaluation,Ip-shing Fan,,0%
https://arxiv.org/pdf/2301.10473.pdf,Aircraft Skin Inspections: Towards a New Model for Dent Evaluation,Nicolas P. Avdelidis,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Fenggen Yu,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Yiming Qian,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Francisca Gil-ureta,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Brian Jackson,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Eric Bennett,,0%
https://arxiv.org/pdf/2301.10460.pdf,HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling,Hao Zhang,,0%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Pengwei Zhang,zhangpengwei@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Chengqian Ma,machengqian01@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Long Zheng,zhenglong@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Chunlei Cai,caichunlei@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Yi Wang,wangyi@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Chao Chen,chenchao02@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Zhiqiang Wu,wuzhiqiang01@bilibili.com,95%
https://arxiv.org/pdf/2301.10455.pdf,Rate-Perception Optimized Preprocessing for Video Coding,Quan Zhou,zhouquan@bilibili.com,95%
https://arxiv.org/pdf/2301.10454.pdf,A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,Arman Zarei,arman.zarei@sharif.edu,95%
https://arxiv.org/pdf/2301.10454.pdf,A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,Mohammad Azizmalayeri,m.azizmalayeri@sharif.edu,82%
https://arxiv.org/pdf/2301.10454.pdf,A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,Mohammad Hossein Rohban,rohban@sharif.edu,78%
https://arxiv.org/pdf/2301.10454.pdf,A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,Alireza Isavand,alireza.isavand@sharif.edu,95%
https://arxiv.org/pdf/2301.10454.pdf,A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,Mohammad Taghi Manzuri,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Tongzhi Niu,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Bin Li,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Kai Li,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Yufeng Lin,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Yuwei Li,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Weifeng Li,,0%
https://arxiv.org/pdf/2301.10441.pdf,Learning Trustworthy Model from Noisy Labels based on Rough Set for Surface Defect Detection,Zhenrong Wang,,0%
https://arxiv.org/pdf/2301.10431.pdf,Bias-Compensated Integral Regression for Human Pose Estimation,Angela Yao,ayao@comp.nus.edu.sg,82%
https://arxiv.org/pdf/2301.10431.pdf,Bias-Compensated Integral Regression for Human Pose Estimation,Kerui Gu,keruigu@comp.nus.edu.sg,95%
https://arxiv.org/pdf/2301.10431.pdf,Bias-Compensated Integral Regression for Human Pose Estimation,Linlin Yang,yangll@comp.nus.edu.sg,78%
https://arxiv.org/pdf/2301.10431.pdf,Bias-Compensated Integral Regression for Human Pose Estimation,Michael Bi Mi,,0%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Chen Sun,chen.sun@sony.com,95%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Lixu Wang,lixuwang2025@u.northwestern.edu,95%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Lingjuan Lyu,Lingjuan.Lv@sony.com,85%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Xiao Wang,wangxiao@northwestern.edu,95%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Chenxi Liu,chenxiliu2020@u.northwestern.edu,95%
https://arxiv.org/pdf/2301.10418.pdf,DEJA VU: Continual Model Generalization For Unseen Domains,Qi Zhu,qzhu@northwestern.edu,82%
https://arxiv.org/pdf/2301.10413.pdf,Local Feature Extraction from Salient Regions by Feature Map Transformation,Nur Suriza Syazwany Binti Ahmad Nizam,surizasyazwany@inha.edu,90%
https://arxiv.org/pdf/2301.10413.pdf,Local Feature Extraction from Salient Regions by Feature Map Transformation,Sang-chul Lee,sclee@inha.ac.kr,82%
https://arxiv.org/pdf/2301.10413.pdf,Local Feature Extraction from Salient Regions by Feature Map Transformation,Yerim Jung,,0%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Neel Dey,dey@mit.edu,78%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Nalini M. Singh,nmsingh@mit.edu,82%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Bruce Fischl,bfischl@mgh.harvard.edu,82%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Adrian V. Dalca,adalca@mit.edu,82%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Polina Golland,polina@csail.mit.edu,85%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Elfar Adalsteinsson,elfar@mit.edu,85%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Robert Frost,srfrost@mgh.harvard.edu,78%
https://arxiv.org/pdf/2301.10365.pdf,Data Consistent Deep Rigid MRI Motion Correction,Malte Hoffmann,mhoffmann@mgh.harvard.edu,82%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,John Lagergren,lagergrenjh@ornl.gov,78%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Hari B. Chhetri,streichjc@ornl.gov,75%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Daniel Jacobson,jacobsonda@ornl.gov,78%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Mirko Pavicic,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Larry M. York,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,P. Doug Hyatt,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,David Kainer,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Erica M. Rutter,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Kevin Flores,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Jack Bailey-bale,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Marie Klein,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Gail Taylor,,0%
https://arxiv.org/pdf/2301.10351.pdf,Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in Populus trichocarpa,Jared Streich,,0%
https://arxiv.org/pdf/2301.10327.pdf,Generating Multidimensional Clusters With Support Lines,Nuno Fachada,nuno.fachada@ulusofona.pt,95%
https://arxiv.org/pdf/2301.10327.pdf,Generating Multidimensional Clusters With Support Lines,Diogo De Andrade,diogo.andrade@ulusofona.pt,95%
https://arxiv.org/pdf/2301.10241.pdf,"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance",Benjamin Recht,brecht@berkeley.edu,82%
https://arxiv.org/pdf/2301.10241.pdf,"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance",Angjoo Kanazawa,kanazawa@berkeley.edu,78%
https://arxiv.org/pdf/2301.10241.pdf,"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance",Giacomo Meanti,giacomo.meanti@iit.it,95%
https://arxiv.org/pdf/2301.10241.pdf,"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance",Sara Fridovich-keil,sfk@berkeley.edu,98%
https://arxiv.org/pdf/2301.10241.pdf,"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance",Frederik Warburg,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Angelika Ando,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Spyros Gidaris,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Andrei Bursuc,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Gilles Puy,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Alexandre Boulch,,0%
https://arxiv.org/pdf/2301.10222.pdf,RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving,Renaud Marlet,,0%
https://arxiv.org/pdf/2301.10218.pdf,Detecting and measuring human gastric peristalsis using magnetically controlled capsule endoscope,Xueshen Li,,0%
https://arxiv.org/pdf/2301.10218.pdf,Detecting and measuring human gastric peristalsis using magnetically controlled capsule endoscope,Yu Gan,,0%
https://arxiv.org/pdf/2301.10218.pdf,Detecting and measuring human gastric peristalsis using magnetically controlled capsule endoscope,David Duan,,0%
https://arxiv.org/pdf/2301.10218.pdf,Detecting and measuring human gastric peristalsis using magnetically controlled capsule endoscope,Xiao Yang,,0%
https://arxiv.org/pdf/2301.10208.pdf,A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction,Xinggang Wang,xgwang@hust.edu.cn,82%
https://arxiv.org/pdf/2301.10208.pdf,A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction,Junyu Wang,,0%
https://arxiv.org/pdf/2301.10208.pdf,A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction,Shijie Wang,,0%
https://arxiv.org/pdf/2301.10208.pdf,A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction,Wenyu Liu,,0%
https://arxiv.org/pdf/2301.10208.pdf,A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction,Zengqiang Zheng,,0%
https://arxiv.org/pdf/2301.10187.pdf,Enhanced Sharp-GAN For Histopathology Image Synthesis,Min Xian,mxian@uidaho.edu,82%
https://arxiv.org/pdf/2301.10187.pdf,Enhanced Sharp-GAN For Histopathology Image Synthesis,Sujata Butte,,0%
https://arxiv.org/pdf/2301.10187.pdf,Enhanced Sharp-GAN For Histopathology Image Synthesis,Haotian Wang,,0%
https://arxiv.org/pdf/2301.10187.pdf,Enhanced Sharp-GAN For Histopathology Image Synthesis,Aleksandar Vakanski,,0%
https://arxiv.org/pdf/2301.10134.pdf,Bipartite Graph Diffusion Model for Human Interaction Generation,Baptiste Chopin,,0%
https://arxiv.org/pdf/2301.10134.pdf,Bipartite Graph Diffusion Model for Human Interaction Generation,Hao Tang,,0%
https://arxiv.org/pdf/2301.10134.pdf,Bipartite Graph Diffusion Model for Human Interaction Generation,Mohamed Daoudi,,0%
https://arxiv.org/pdf/2301.10127.pdf,Improving Open-Set Semi-Supervised Learning with Self-Supervision,Lennart Svensson,lennart.svensson@chalmers.se,95%
https://arxiv.org/pdf/2301.10127.pdf,Improving Open-Set Semi-Supervised Learning with Self-Supervision,Lars Hammarstrand,lars.hammarstrand@chalmers.se,95%
https://arxiv.org/pdf/2301.10127.pdf,Improving Open-Set Semi-Supervised Learning with Self-Supervision,Erik Wallin,walline@chalmers.se,78%
https://arxiv.org/pdf/2301.10127.pdf,Improving Open-Set Semi-Supervised Learning with Self-Supervision,Fredrik Kahl,fredrik.kahl@chalmers.se,95%
https://arxiv.org/pdf/2301.10100.pdf,Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation,Gilles Puy,,0%
https://arxiv.org/pdf/2301.10100.pdf,Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation,Alexandre Boulch,,0%
https://arxiv.org/pdf/2301.10100.pdf,Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation,Renaud Marlet,,0%
https://arxiv.org/pdf/2301.10092.pdf,Model soups to increase inference without increasing compute time,Charles Dansereau,charles.dansereau@polymtl.ca,95%
https://arxiv.org/pdf/2301.10092.pdf,Model soups to increase inference without increasing compute time,Mehdi Zalai,mehdi.zalai@polymtl.ca,95%
https://arxiv.org/pdf/2301.10092.pdf,Model soups to increase inference without increasing compute time,Milo Sobral,milo.sobral@polymtl.ca,95%
https://arxiv.org/pdf/2301.10092.pdf,Model soups to increase inference without increasing compute time,Maninder Bhogal,maninder.bhogal@polymtl.ca,95%
https://arxiv.org/pdf/2302.10303.pdf,Interpretable Out-Of-Distribution Detection Using Pattern Identification,Romain Xu-darme,romain.xu-darme@cea.fr,95%
https://arxiv.org/pdf/2302.10303.pdf,Interpretable Out-Of-Distribution Detection Using Pattern Identification,Zakaria Chihani,zakaria.chihani@cea.fr,95%
https://arxiv.org/pdf/2302.10303.pdf,Interpretable Out-Of-Distribution Detection Using Pattern Identification,Julien Girard-satabin,julien.girard2@cea.fr,85%
https://arxiv.org/pdf/2302.10303.pdf,Interpretable Out-Of-Distribution Detection Using Pattern Identification,Darryl Hond,,0%
https://arxiv.org/pdf/2302.10303.pdf,Interpretable Out-Of-Distribution Detection Using Pattern Identification,Gabriele Incorvaia,,0%
https://arxiv.org/pdf/2301.10057.pdf,Planar Object Tracking via Weighted Optical Flow,Jiri Matas,matas@fel.cvut.cz,78%
https://arxiv.org/pdf/2301.10057.pdf,Planar Object Tracking via Weighted Optical Flow,Jonas Serych,serycjon@fel.cvut.cz,75%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Blas Kojusner,bkojusner@ufl.edu,82%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Pirouz Naghavi,pnaghavi@ufl.edu,82%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Kevin Butler,butler@ufl.edu,78%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Sara Rampazzi,srampazzi@ufl.edu,82%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Kevin Fu,k.fu@northeastern.edu,82%
https://arxiv.org/pdf/2301.10056.pdf,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses,Yan Long,yanlong@umich.edu,95%
https://arxiv.org/pdf/2301.10052.pdf,Event Detection in Football using Graph Convolutional Networks,Aditya Sangram Singh Rana,adityasangramsingh.rana@e-campus.uab.cat,95%
https://arxiv.org/pdf/2301.10051.pdf,Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism,Zanjia Tong,,0%
https://arxiv.org/pdf/2301.10051.pdf,Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism,Yuhang Chen,,0%
https://arxiv.org/pdf/2301.10051.pdf,Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism,Zewei Xu,,0%
https://arxiv.org/pdf/2301.10051.pdf,Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism,Rong Yu,,0%
https://arxiv.org/pdf/2301.10048.pdf,Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting,Jingjing Fu,jifu@microsoft.com,82%
https://arxiv.org/pdf/2301.10048.pdf,Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting,Dong Liu,dongeliu@ustc.edu.cn,95%
https://arxiv.org/pdf/2301.10048.pdf,Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting,Kaidong Zhang,,0%
https://arxiv.org/pdf/2301.10048.pdf,Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting,Jialun Peng,,0%
https://arxiv.org/pdf/2301.10047.pdf,DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model,Naye Ji,jinaye@cuz.edu.cn,95%
https://arxiv.org/pdf/2301.10047.pdf,DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model,Fan Zhang,fanzhang@cuz.edu.cn,95%
https://arxiv.org/pdf/2301.10047.pdf,DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model,Yongping Li,liyongping@nbufe.edu.cn,95%
https://arxiv.org/pdf/2301.10047.pdf,DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model,Fuxing Gao,fuxing@cuz.edu.cn,85%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Peijie Dong,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Xin Niu,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Zhiliang Tian,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Lujun Li,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Xiaodong Wang,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Zimian Wei,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Hengyue Pan,,0%
https://arxiv.org/pdf/2301.10038.pdf,Progressive Meta-Pooling Learning for Lightweight Image Classification Model,Dongsheng Li,,0%
https://arxiv.org/pdf/2301.10008.pdf,Few-shot Font Generation by Learning Style Difference and Similarity,Xiao He,,0%
https://arxiv.org/pdf/2301.10008.pdf,Few-shot Font Generation by Learning Style Difference and Similarity,Mingrui Zhu,,0%
https://arxiv.org/pdf/2301.10008.pdf,Few-shot Font Generation by Learning Style Difference and Similarity,Nannan Wang,,0%
https://arxiv.org/pdf/2301.10008.pdf,Few-shot Font Generation by Learning Style Difference and Similarity,Xinbo Gao,,0%
https://arxiv.org/pdf/2301.10008.pdf,Few-shot Font Generation by Learning Style Difference and Similarity,Heng Yang,,0%
https://arxiv.org/pdf/2301.09964.pdf,Uncertainty-Aware Distillation for Semi-Supervised Few-Shot Class-Incremental Learning,Li Liu,dreamliu2010@gmail.com,95%
https://arxiv.org/pdf/2301.09964.pdf,Uncertainty-Aware Distillation for Semi-Supervised Few-Shot Class-Incremental Learning,Wanxia Deng,dengwanxia14@nudt.edu.cn,95%
https://arxiv.org/pdf/2301.09964.pdf,Uncertainty-Aware Distillation for Semi-Supervised Few-Shot Class-Incremental Learning,Yawen Cui,,0%
https://arxiv.org/pdf/2301.09964.pdf,Uncertainty-Aware Distillation for Semi-Supervised Few-Shot Class-Incremental Learning,Haoyu Chen,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Verena Jasmin Hallitschke,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Tobias Schlumberger,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Philipp Kataliakos,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Zdravko Marinov,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Moon Kim,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Lars Heiliger,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Constantin Seibold,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Jens Kleesiek,,0%
https://arxiv.org/pdf/2301.09914.pdf,Multimodal Interactive Lung Lesion Segmentation: A Framework for Annotating PET/CT Images based on Physiological and Anatomical Cues,Rainer Stiefelhagen,,0%
https://arxiv.org/pdf/2301.09906.pdf,Transfer Learning for Olfactory Object Detection,Mathias Zinnen,,0%
https://arxiv.org/pdf/2301.09906.pdf,Transfer Learning for Olfactory Object Detection,Prathmesh Madhu,,0%
https://arxiv.org/pdf/2301.09906.pdf,Transfer Learning for Olfactory Object Detection,Peter Bell,,0%
https://arxiv.org/pdf/2301.09906.pdf,Transfer Learning for Olfactory Object Detection,Andreas Maier,,0%
https://arxiv.org/pdf/2301.09906.pdf,Transfer Learning for Olfactory Object Detection,Vincent Christlein,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Azadeh Fakhrzadeh,fakhrzadeh@irandoc.ac.ir,78%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Pouya Karimian,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Mahsa Meyari,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Cris L. Luengo Hendriks,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Lena Holm,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Christian Sonne,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Rune Dietz,,0%
https://arxiv.org/pdf/2301.09887.pdf,Deep learning-based method for segmenting epithelial layer of tubules in histopathological images of testicular tissue,Ellinor Spörndly-nees,,0%
https://arxiv.org/pdf/2301.09879.pdf,Data Augmentation Alone Can Improve Adversarial Training,Lin Li,michael.spratling@kcl.ac.uk,95%
https://arxiv.org/pdf/2301.09879.pdf,Data Augmentation Alone Can Improve Adversarial Training,Michael Spratling,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Mathias Zinnen,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Prathmesh Madhu,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Ronak Kosti,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Peter Bell,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Andreas Maier,,0%
https://arxiv.org/pdf/2301.09878.pdf,ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition,Vincent Christlein,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Jinpeng Shi,jinpeeeng.s@gmail.com,75%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Hui Li,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Tianle Liu,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Yulong Liu,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Mingjian Zhang,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Jinchen Zhu,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Ling Zheng,,0%
https://arxiv.org/pdf/2301.09869.pdf,Image Super-Resolution using Efficient Striped Window Transformer,Shizhuang Weng,,0%
https://arxiv.org/pdf/2301.09858.pdf,PowerQuant: Automorphism Search for Non-Uniform Quantization,Edouard Yvinec,ey@datakalab.com,90%
https://arxiv.org/pdf/2301.09858.pdf,PowerQuant: Automorphism Search for Non-Uniform Quantization,Arnaud Dapogny,,0%
https://arxiv.org/pdf/2301.09858.pdf,PowerQuant: Automorphism Search for Non-Uniform Quantization,Matthieu Cord,,0%
https://arxiv.org/pdf/2301.09858.pdf,PowerQuant: Automorphism Search for Non-Uniform Quantization,Kevin Bailly,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Peijie Dong,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Xin Niu,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Lujun Li,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Zhiliang Tian,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Xiaodong Wang,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Zimian Wei,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Hengyue Pan,,0%
https://arxiv.org/pdf/2301.09850.pdf,RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking Distillation from Zero-cost Proxies,Dongsheng Li,,0%
https://arxiv.org/pdf/2301.09799.pdf,LDMIC: Learning-based Distributed Multi-view Image Coding,Xinjie Zhang,xinjie.zhang@connect.ust.hk,95%
https://arxiv.org/pdf/2301.09799.pdf,LDMIC: Learning-based Distributed Multi-view Image Coding,Jiawei Shao,jiawei.shao@connect.ust.hk,95%
https://arxiv.org/pdf/2301.09799.pdf,LDMIC: Learning-based Distributed Multi-view Image Coding,Jun Zhang,,0%
https://arxiv.org/pdf/2301.11726.pdf,GAN-Based Object Removal in High-Resolution Satellite Images,Hadi Mansourifar,,0%
https://arxiv.org/pdf/2301.11726.pdf,GAN-Based Object Removal in High-Resolution Satellite Images,Steven J. Simske,,0%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Joseph Bentsman,jbentsma@illinois.edu,90%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Martin Ostoja-starzewski,martinos@illinois.edu,85%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Leonardo P. Chamorro,lpchamo@illinois.edu,65%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Richard Berlin,pubs-permissions@ieee.org,65%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Junren Ran,jran2@illinois.edu,82%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Hamza El-kebir,,0%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Yongseok Lee,,0%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Gabriela M. Aguiluz Cornejo,,0%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Enrico Benedetti,,0%
https://arxiv.org/pdf/2301.09733.pdf,Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling using Real-time Thermography,Pier C. Giulianotti,,0%
https://arxiv.org/pdf/2301.09724.pdf,Long-tail Detection with Effective Class-Margins,Jang Hyun Cho,janghyuncho7@utexas.edu,95%
https://arxiv.org/pdf/2301.09724.pdf,Long-tail Detection with Effective Class-Margins,Philipp Krähenbühl,philkr@cs.utexas.edu,60%
https://arxiv.org/pdf/2301.09702.pdf,Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification,Jiaqi Guo,guo498@purdue.edu,78%
https://arxiv.org/pdf/2301.09702.pdf,Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification,Amy R. Reibman,reibman@purdue.edu,78%
https://arxiv.org/pdf/2301.09702.pdf,Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification,Edward J. Delp,,0%
https://arxiv.org/pdf/2301.09667.pdf,Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans,Amir Ghasemi,,0%
https://arxiv.org/pdf/2301.09667.pdf,Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans,Nasrin Bayat,,0%
https://arxiv.org/pdf/2301.09667.pdf,Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans,Fatemeh Mottaghian,,0%
https://arxiv.org/pdf/2301.09667.pdf,Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans,Akram Bayat,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Chieh Hubert Lin,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Hsin-ying Lee,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Willi Menapace,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Menglei Chai,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Aliaksandr Siarohin,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Ming-hsuan Yang,,0%
https://arxiv.org/pdf/2301.09637.pdf,InfiniCity: Infinite-Scale City Synthesis,Sergey Tulyakov,,0%
https://arxiv.org/pdf/2301.09632.pdf,HexPlane: A Fast Representation for Dynamic Scenes,Ang Cao,ancao@umich.edu,82%
https://arxiv.org/pdf/2301.09632.pdf,HexPlane: A Fast Representation for Dynamic Scenes,Justin Johnson,justincj@umich.edu,85%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Qiuhong Anna Wei,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Sijie Ding,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Jeong Joon Park,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Rahul Sajnani,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Adrien Poulenard,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Srinath Sridhar,,0%
https://arxiv.org/pdf/2301.09629.pdf,LEGO-Net: Learning Regular Rearrangements of Objects in Rooms,Leonidas Guibas,,0%
https://arxiv.org/pdf/2301.09624.pdf,Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling of Whole Slide Images,Piotr Keller,,0%
https://arxiv.org/pdf/2301.09624.pdf,Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling of Whole Slide Images,Muhammad Dawood,,0%
https://arxiv.org/pdf/2301.09624.pdf,Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling of Whole Slide Images,Fayyaz Ul Amir Afsar Minhas,,0%
https://arxiv.org/pdf/2301.09620.pdf,Tracking the industrial growth of modern China with high-resolution panchromatic imagery: A sequential convolutional approach,Ethan Brewer,ethan.brewer@nyu.edu,95%
https://arxiv.org/pdf/2301.09620.pdf,Tracking the industrial growth of modern China with high-resolution panchromatic imagery: A sequential convolutional approach,Dan Runfola,danr@wm.edu,85%
https://arxiv.org/pdf/2301.09620.pdf,Tracking the industrial growth of modern China with high-resolution panchromatic imagery: A sequential convolutional approach,Zhonghui Lv,zlv@wm.edu,82%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Sophia J. Wagner,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Daniel Reisenbüchler,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Nicholas P. West,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Jan Moritz Niehues,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Gregory Patrick Veldhuizen,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Philip Quirke,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Heike I. Grabsch,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Piet A. Van Den Brandt,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Gordon G. A. Hutchins,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Susan D. Richman,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Tanwei Yuan,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Rupert Langer,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Josien Christina Anna Jenniskens,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Kelly Offermans,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Wolfram Mueller,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Richard Gray,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Stephen B. Gruber,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Joel K. Greenson,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Gad Rennert,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Joseph D. Bonner,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Daniel Schmolze,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Jacqueline A. James,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Maurice B. Loughrey,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Manuel Salto-tellez,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Hermann Brenner,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Michael Hoffmeister,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Daniel Truhn,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Julia A. Schnabel,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Melanie Boxberg,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Tingying Peng,,0%
https://arxiv.org/pdf/2301.09617.pdf,Fully transformer-based biomarker prediction from colorectal cancer histology: a large-scale multicentric study,Jakob Nikolas Kather,,0%
https://arxiv.org/pdf/2301.09602.pdf,Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly Segmentation,Jesus Angulo,jesus.angulo@minesparis.psl.eu,95%
https://arxiv.org/pdf/2301.09602.pdf,Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly Segmentation,Etienne Decencière,etienne.decenciere@minesparis.psl.eu,95%
https://arxiv.org/pdf/2301.09602.pdf,Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly Segmentation,Santiago Velasco-forero,santiago.velasco@minesparis.psl.eu,85%
https://arxiv.org/pdf/2301.09602.pdf,Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly Segmentation,Joao P. C. Bertoldo,jpcbertoldo@minesparis.psl.eu,82%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Adrià Recasens,arecasens@google.com,82%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Jason Lin,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Joāo Carreira,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Drew Jaegle,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Luyu Wang,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Jean-baptiste Alayrac,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Pauline Luc,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Antoine Miech,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Lucas Smaira,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Ross Hemsley,,0%
https://arxiv.org/pdf/2301.09595.pdf,Zorro: the masked multimodal transformer,Andrew Zisserman,,0%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Nathalie Majcherczyk,majcherc@amazon.com,90%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Xuewei Qi,qixuewei@amazon.com,95%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Rajasimman Madhivanan,rajasimm@amazon.com,90%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Wenhao Ding,wenhaod@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Arnie Sen,senarnie@amazon.com,95%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Ding Zhao,dingzhao@andrew.cmu.edu,95%
https://arxiv.org/pdf/2301.09544.pdf,Learning to View: Decision Transformers for Active Object Detection,Mohit Deshpande,deshmohi@amazon.com,60%
https://arxiv.org/pdf/2301.09542.pdf,Improving Presentation Attack Detection for ID Cards on Remote Verification Systems,Sebastian Gonzalez,sebastian.gonzalez@tocbiometrics.com,95%
https://arxiv.org/pdf/2301.09542.pdf,Improving Presentation Attack Detection for ID Cards on Remote Verification Systems,Juan Tapia,juan.tapia-farias@h-da.de,95%
https://arxiv.org/pdf/2301.09525.pdf,DeepFEL: Deep Fastfood Ensemble Learning for Histopathology Image Analysis,Nima Hatami,hatami@creatis.insa-lyon.fr,78%
https://arxiv.org/pdf/2301.09522.pdf,Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,Dengyu Wu,dengyu.wu@liverpool.ac.uk,95%
https://arxiv.org/pdf/2301.09522.pdf,Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,Xiaowei Huang,xiaowei.huang@liverpool.ac.uk,95%
https://arxiv.org/pdf/2301.09522.pdf,Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,Gaojie Jin,,0%
https://arxiv.org/pdf/2301.09522.pdf,Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,Han Yu,,0%
https://arxiv.org/pdf/2301.09522.pdf,Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,Xinping Yi,,0%
https://arxiv.org/pdf/2301.09515.pdf,StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,Axel Sauer,a.sauer@uni-tuebingen.de,82%
https://arxiv.org/pdf/2301.09515.pdf,StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,Tero Karras,,0%
https://arxiv.org/pdf/2301.09515.pdf,StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,Samuli Laine,,0%
https://arxiv.org/pdf/2301.09515.pdf,StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,Andreas Geiger,,0%
https://arxiv.org/pdf/2301.09515.pdf,StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,Timo Aila,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Keyan Chen,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Xiaolong Jiang,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Yao Hu,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Xu Tang,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Yan Gao,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Jianqi Chen,,0%
https://arxiv.org/pdf/2301.09506.pdf,OvarNet: Towards Open-vocabulary Object Attribute Recognition,Weidi Xie,,0%
https://arxiv.org/pdf/2301.09498.pdf,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,Liyan Zhang,zhangliyan@nuaa.edu.cn,95%
https://arxiv.org/pdf/2301.09498.pdf,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,Xiangbo Shu,shuxb@njust.edu.cn,78%
https://arxiv.org/pdf/2301.09498.pdf,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,Fei Shen,feishen@njust.edu.cn,95%
https://arxiv.org/pdf/2301.09498.pdf,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,Xiaoyu Du,duxy@njust.edu.cn,78%
https://arxiv.org/pdf/2301.09498.pdf,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,Jinhui Tang,jinhuitang@njust.edu.cn,95%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Alessandro Flaborea,flaborea@di.uniroma1.it,78%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Guido D'amely,,0%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Stefano D'arrigo,,0%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Marco Aurelio Sterpa,,0%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Alessio Sampieri,,0%
https://arxiv.org/pdf/2301.09489.pdf,Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,Fabio Galasso,,0%
https://arxiv.org/pdf/2301.09461.pdf,Study on the identification limits of craniofacial superimposition,Óscar Ibáñez,oscar.ibanez@udc.es,95%
https://arxiv.org/pdf/2301.09461.pdf,Study on the identification limits of craniofacial superimposition,Enrique Bermejo,,0%
https://arxiv.org/pdf/2301.09461.pdf,Study on the identification limits of craniofacial superimposition,Andrea Valsecchi,,0%
https://arxiv.org/pdf/2301.09460.pdf,HRVQA: A Visual Question Answering Benchmark for High-Resolution Aerial Images,Kun Li,,0%
https://arxiv.org/pdf/2301.09460.pdf,HRVQA: A Visual Question Answering Benchmark for High-Resolution Aerial Images,George Vosselman,,0%
https://arxiv.org/pdf/2301.09460.pdf,HRVQA: A Visual Question Answering Benchmark for High-Resolution Aerial Images,Michael Ying Yang,,0%
https://arxiv.org/pdf/2301.09451.pdf,A Simple Recipe for Competitive Low-compute Self supervised Vision Models,Ishan Misra,imisra@meta.com,82%
https://arxiv.org/pdf/2301.09451.pdf,A Simple Recipe for Competitive Low-compute Self supervised Vision Models,Nicolas Ballas,ballasn@meta.com,78%
https://arxiv.org/pdf/2301.09451.pdf,A Simple Recipe for Competitive Low-compute Self supervised Vision Models,Quentin Duval,qduval@meta.com,82%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Thibaut Eloy,,0%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Etienne Baudrier,,0%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Marine Laporte,,0%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Virginie Hamel,,0%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Paul Guichard,,0%
https://arxiv.org/pdf/2301.09452.pdf,Fast and robust single particle reconstruction in 3D fluorescence microscopy,Denis Fortun,,0%
https://arxiv.org/pdf/2301.10018.pdf,GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning,Shuaicheng Liu,liushuaicheng@uestc.edu.cn,95%
https://arxiv.org/pdf/2301.10018.pdf,GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning,Haipeng Li,,0%
https://arxiv.org/pdf/2301.10018.pdf,GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning,Kunming Luo,,0%
https://arxiv.org/pdf/2301.10018.pdf,GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning,Bing Zeng,,0%
https://arxiv.org/pdf/2301.09431.pdf,Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images,Tabea-clara Bucher,tabea.bucher@dkfz.de,95%
https://arxiv.org/pdf/2301.09431.pdf,Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images,Martin J. Hetz,martinjoachim.hetz@dkfz.de,95%
https://arxiv.org/pdf/2301.09431.pdf,Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images,Titus J. Brinker,titus.brinker@dkfz.de,95%
https://arxiv.org/pdf/2301.09430.pdf,Rethinking Real-world Image Deraining via An Unpaired Degradation-Conditioned Diffusion Model,Yiyang Shen,,0%
https://arxiv.org/pdf/2301.09430.pdf,Rethinking Real-world Image Deraining via An Unpaired Degradation-Conditioned Diffusion Model,Mingqiang Wei,,0%
https://arxiv.org/pdf/2301.09430.pdf,Rethinking Real-world Image Deraining via An Unpaired Degradation-Conditioned Diffusion Model,Yongzhen Wang,,0%
https://arxiv.org/pdf/2301.09430.pdf,Rethinking Real-world Image Deraining via An Unpaired Degradation-Conditioned Diffusion Model,Xueyang Fu,,0%
https://arxiv.org/pdf/2301.09430.pdf,Rethinking Real-world Image Deraining via An Unpaired Degradation-Conditioned Diffusion Model,Jing Qin,,0%
https://arxiv.org/pdf/2302.10273.pdf,ViGU: Vision GNN U-Net for Fast MRI,Guang Yang,g.yang@imperial.ac.uk,82%
https://arxiv.org/pdf/2302.10273.pdf,ViGU: Vision GNN U-Net for Fast MRI,Jiahao Huang,j.huang21@imperial.ac.uk,82%
https://arxiv.org/pdf/2302.10273.pdf,ViGU: Vision GNN U-Net for Fast MRI,Angelica Aviles-rivero,,0%
https://arxiv.org/pdf/2302.10273.pdf,ViGU: Vision GNN U-Net for Fast MRI,Carola-bibiane Schonlieb,,0%
https://arxiv.org/pdf/2302.10272.pdf,Is Autoencoder Truly Applicable for 3D CT Super-Resolution?,Weixun Luo,,0%
https://arxiv.org/pdf/2302.10272.pdf,Is Autoencoder Truly Applicable for 3D CT Super-Resolution?,Xiaodan Xing,,0%
https://arxiv.org/pdf/2302.10272.pdf,Is Autoencoder Truly Applicable for 3D CT Super-Resolution?,Guang Yang,,0%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Hao Wen,wenhao@tju.edu.cn,95%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Haozhe Lin,linhz@tsinghua.edu.cn,78%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Huili Cui,huilicui 1@tju.edu.cn,95%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Kun Li,lik@tju.edu.cn,78%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Yukun Lai,LaiY4@cardiff.ac.uk,78%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Lu Fang,fanglu@tsinghua.edu.cn,95%
https://arxiv.org/pdf/2301.09376.pdf,Crowd3D: Towards Hundreds of People Reconstruction from a Single Image,Jing Huang,,0%
https://arxiv.org/pdf/2301.09339.pdf,Computer Vision for a Camel-Vehicle Collision Mitigation System,Khalid Alnujaidi,,0%
https://arxiv.org/pdf/2301.09339.pdf,Computer Vision for a Camel-Vehicle Collision Mitigation System,Ghadah Alhabib,,0%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Eva Vandersmissen,eva.vandersmissen@agfa.com,95%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Annemiek Snoeckx,Annemiek.Snoeckx@uza.be,95%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Dimitrios Lenis,lenis@vrvis.at,78%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Jeroen Cant,jeroen.cant@agfa.com,95%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Maria Wimmer,mwimmer@vrvis.at,82%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Astrid Berg,berg@vrvis.at,78%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Theresa Neubauer,tneubauer@vrvis.at,82%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,David Major,major@vrvis.at,78%
https://arxiv.org/pdf/2301.09338.pdf,Employing similarity to highlight differences: On the impact of anatomical assumptions in chest X-ray registration methods,Katja Bühler,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Neus Rodeja Ferrer,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Malini Vendela Sagar,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Kiril Vadimovic Klein,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Christina Kruuse,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Mads Nielsen,,0%
https://arxiv.org/pdf/2301.09322.pdf,Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19,Mostafa Mehdipour Ghazi,,0%
https://arxiv.org/pdf/2301.09318.pdf,Toward Foundation Models for Earth Monitoring: Generalizable Deep Learning Models for Natural Hazard Segmentation,Johannes Jakubik,,0%
https://arxiv.org/pdf/2301.09318.pdf,Toward Foundation Models for Earth Monitoring: Generalizable Deep Learning Models for Natural Hazard Segmentation,Michal Muszynski,,0%
https://arxiv.org/pdf/2301.09318.pdf,Toward Foundation Models for Earth Monitoring: Generalizable Deep Learning Models for Natural Hazard Segmentation,Michael Vössing,,0%
https://arxiv.org/pdf/2301.09318.pdf,Toward Foundation Models for Earth Monitoring: Generalizable Deep Learning Models for Natural Hazard Segmentation,Niklas Kühl,,0%
https://arxiv.org/pdf/2301.09318.pdf,Toward Foundation Models for Earth Monitoring: Generalizable Deep Learning Models for Natural Hazard Segmentation,Thomas Brunschwiler,,0%
https://arxiv.org/pdf/2301.09315.pdf,AI-Based Framework for Understanding Car Following Behaviors of Drivers in A Naturalistic Driving Environment,Yaw Adu-gyamfi,adugyamfiym@missouri.edu,75%
https://arxiv.org/pdf/2301.09315.pdf,AI-Based Framework for Understanding Car Following Behaviors of Drivers in A Naturalistic Driving Environment,Armstrong Aboah,,0%
https://arxiv.org/pdf/2301.09315.pdf,AI-Based Framework for Understanding Car Following Behaviors of Drivers in A Naturalistic Driving Environment,Abdul Rashid Mussah,,0%
https://arxiv.org/pdf/2301.09299.pdf,Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay,Yinheng Li,,0%
https://arxiv.org/pdf/2301.09299.pdf,Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay,Han Ding,,0%
https://arxiv.org/pdf/2301.09299.pdf,Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay,Shaofei Wang,,0%
https://arxiv.org/pdf/2301.09282.pdf,Classification of Luminal Subtypes in Full Mammogram Images Using Transfer Learning,Adarsh Bhandary Panambur,,0%
https://arxiv.org/pdf/2301.09282.pdf,Classification of Luminal Subtypes in Full Mammogram Images Using Transfer Learning,Prathmesh Madhu,,0%
https://arxiv.org/pdf/2301.09282.pdf,Classification of Luminal Subtypes in Full Mammogram Images Using Transfer Learning,Andreas Maier,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Brian Li,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Steven Palayew,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Francis Li,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Saad Abbasi,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Saeejith Nair,,0%
https://arxiv.org/pdf/2301.09268.pdf,PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge,Alexander Wong,,0%
https://arxiv.org/pdf/2301.09266.pdf,FInC Flow: Fast and Invertible $k \times k$ Convolutions for Normalizing Flows,Aditya Kallappa,aditya.kallappa@research.iiit.ac.in,95%
https://arxiv.org/pdf/2301.09266.pdf,FInC Flow: Fast and Invertible $k \times k$ Convolutions for Normalizing Flows,Sandeep Nagar,sandeep.nagar@research.iiit.ac.in,95%
https://arxiv.org/pdf/2301.09266.pdf,FInC Flow: Fast and Invertible $k \times k$ Convolutions for Normalizing Flows,Girish Varma,girish.varma@iiit.ac.in,95%
https://arxiv.org/pdf/2301.09264.pdf,Efficient Training Under Limited Resources,Mahdi Zolnouri,mahdi.zolnouri@huawei.com,95%
https://arxiv.org/pdf/2301.09264.pdf,Efficient Training Under Limited Resources,Sébastien Le Digabel,sebastien.le.digabel@gerad.ca,95%
https://arxiv.org/pdf/2301.09264.pdf,Efficient Training Under Limited Resources,Eyyüb Sari,eyyub.sari@huawei.com,95%
https://arxiv.org/pdf/2301.09264.pdf,Efficient Training Under Limited Resources,Christophe Tribes,christophe.tribes@polymtl.ca,95%
https://arxiv.org/pdf/2301.09264.pdf,Efficient Training Under Limited Resources,Dounia Lakhmiri,dounia.lakhmiri@polymtl.ca,95%
https://arxiv.org/pdf/2301.09257.pdf,Real-Time Simultaneous Localization and Mapping with LiDAR intensity,Giovanni Beltrame,giovanni.beltrame@polymtl.ca,95%
https://arxiv.org/pdf/2301.09257.pdf,Real-Time Simultaneous Localization and Mapping with LiDAR intensity,Wenqiang Du,wenqiang.du@polymtl.ca,95%
https://arxiv.org/pdf/2301.09255.pdf,Combined Use of Federated Learning and Image Encryption for Privacy-Preserving Image Classification with Vision Transformer,Hitoshi Kiya,kiya@tmu.ac.jp,78%
https://arxiv.org/pdf/2301.09255.pdf,Combined Use of Federated Learning and Image Encryption for Privacy-Preserving Image Classification with Vision Transformer,Teru Nagamori,nagamori-teru@ed.tmu.ac.jp,95%
https://arxiv.org/pdf/2301.09254.pdf,Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference,Peter A. Beerel,pabeerel@usc.edu,82%
https://arxiv.org/pdf/2301.09254.pdf,Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference,Jacqueline Liu,jtliu@usc.edu,82%
https://arxiv.org/pdf/2301.09254.pdf,Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference,Souvik Kundu,souvikk.kundu@intel.com,95%
https://arxiv.org/pdf/2301.09254.pdf,Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference,Shunlin Lu,shunlinlu@usc.edu,95%
https://arxiv.org/pdf/2301.09254.pdf,Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference,Yuke Zhang,yukezhan@usc.edu,85%
https://arxiv.org/pdf/2301.09253.pdf,CircNet: Meshing 3D Point Clouds with Circumcenter Detection,Huan Lei,,0%
https://arxiv.org/pdf/2301.09253.pdf,CircNet: Meshing 3D Point Clouds with Circumcenter Detection,Ruitao Leng,,0%
https://arxiv.org/pdf/2301.09253.pdf,CircNet: Meshing 3D Point Clouds with Circumcenter Detection,Liang Zheng,,0%
https://arxiv.org/pdf/2301.09253.pdf,CircNet: Meshing 3D Point Clouds with Circumcenter Detection,Hongdong Li,,0%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Yadan Luo,y.luo@uq.edu.au,82%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Zhuoxiao Chen,,0%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Zijian Wang,,0%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Xin Yu,,0%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Zi Huang,,0%
https://arxiv.org/pdf/2301.09249.pdf,Exploring Active 3D Object Detection from a Generalization Perspective,Mahsa Baktashmotlagh,,0%
https://arxiv.org/pdf/2301.09219.pdf,Applied Deep Learning to Identify and Localize Polyps from Endoscopic Images,Chandana Raju,,0%
https://arxiv.org/pdf/2301.09219.pdf,Applied Deep Learning to Identify and Localize Polyps from Endoscopic Images,Sumedh Vilas Datar,,0%
https://arxiv.org/pdf/2301.09219.pdf,Applied Deep Learning to Identify and Localize Polyps from Endoscopic Images,Kushala Hari,,0%
https://arxiv.org/pdf/2301.09219.pdf,Applied Deep Learning to Identify and Localize Polyps from Endoscopic Images,Kavin Vijay,,0%
https://arxiv.org/pdf/2301.09219.pdf,Applied Deep Learning to Identify and Localize Polyps from Endoscopic Images,Suma Ningappa,,0%
https://arxiv.org/pdf/2301.09213.pdf,FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for Egocentric multi-robot exploration,Nikolaos Stathoulopoulos,niksta@ltu.se,60%
https://arxiv.org/pdf/2301.09213.pdf,FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for Egocentric multi-robot exploration,Anton Koval,,0%
https://arxiv.org/pdf/2301.09213.pdf,FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for Egocentric multi-robot exploration,Ali-akbar Agha-mohammadi,,0%
https://arxiv.org/pdf/2301.09213.pdf,FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for Egocentric multi-robot exploration,George Nikolakopoulos,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Razvan-george Pasca,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Alexey Gavryushin,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Muhammad Hamza,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Yen-ling Kuo,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Kaichun Mo,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Luc Van Gool,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Otmar Hilliges,,0%
https://arxiv.org/pdf/2301.09209.pdf,Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation,Xi Wang,,0%
https://arxiv.org/pdf/2301.09190.pdf,Apples and Oranges? Assessing Image Quality over Content Recognition,Junyong You,,0%
https://arxiv.org/pdf/2301.09190.pdf,Apples and Oranges? Assessing Image Quality over Content Recognition,Zheng Zhang,,0%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Luis F. Gomez,luisf.gomez@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Aythami Morales,aythami.morales@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Julian Fierrez,julian.ﬁerrez@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Ruben Tolosana,ruben.tolosana@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Ruth Cobos,ruth.cobos@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Roberto Daza,roberto.daza@uam.es,95%
https://arxiv.org/pdf/2301.09174.pdf,MATT: Multimodal Attention Level Estimation for e-learning Platforms,Javier Ortega-garcia,javier.ortega@uam.es,85%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Kevin Mcguinness,kevin.mcguinness@dcu.ie,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Eric Arazo,eric.arazo@insight-centre.org,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Alexandru Drimbarean,Alexandru.Drimbarean@xperi.com,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Paul Albert,paul.albert@insight-centre.org,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Tarun Krishna,tarun.krishna2@mail.dcu.ie,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Noel E O'connor,noel.oconnor@dcu.ie,85%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Alan F Smeaton,alan.smeaton@dcu.ie,95%
https://arxiv.org/pdf/2301.09164.pdf,Unifying Synergies between Self-supervised Learning and Dynamic Computation,Ayush K Rai,ayush.rai3@mail.dcu.ie,95%
https://arxiv.org/pdf/2301.09123.pdf,Face Generation from Textual Features using Conditionally Trained Inputs to Generative Adversarial Networks,Mihir Tale,4mihir.tale18@vit.edu,95%
https://arxiv.org/pdf/2301.09123.pdf,Face Generation from Textual Features using Conditionally Trained Inputs to Generative Adversarial Networks,Sandeep Shinde,1sandeep.shinde@vit.edu,95%
https://arxiv.org/pdf/2301.09123.pdf,Face Generation from Textual Features using Conditionally Trained Inputs to Generative Adversarial Networks,Aniket Ghorpade,3aniket.ghorpade18@vit.edu,95%
https://arxiv.org/pdf/2301.09123.pdf,Face Generation from Textual Features using Conditionally Trained Inputs to Generative Adversarial Networks,Tejas Pradhan,2tejas.pradhan18@vit.edu,95%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Jilan Xu,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Junlin Hou,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Yuejie Zhang,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Rui Feng,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Yi Wang,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Yu Qiao,,0%
https://arxiv.org/pdf/2301.09121.pdf,Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision,Weidi Xie,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Minjung Shin,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Yunji Seo,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Jeongmin Bae,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Young Sun Choi,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Hyunsu Kim,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Hyeran Byun,,0%
https://arxiv.org/pdf/2301.09091.pdf,BallGAN: 3D-aware Image Synthesis with a Spherical Background,Youngjung Uh,,0%
https://arxiv.org/pdf/2301.09077.pdf,Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,Yixuan Yuan,yxyuan@ee.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.09077.pdf,Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,Junhui Hou,jh.hou@cityu.edu.hk,82%
https://arxiv.org/pdf/2301.09077.pdf,Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,Qijian Zhang,qijizhang3-c@my.cityu.edu.hk,82%
https://arxiv.org/pdf/2301.09077.pdf,Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,Yifan Zhang,yzhang3362-c@my.cityu.edu.hk,82%
https://arxiv.org/pdf/2301.09077.pdf,Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,Guoliang Xing,glxing@ie.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Wenqiao Zhang,wenqiao@nus.edu.sg,85%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Linchao Zhu,zhulinchao@zju.edu.cn,95%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Fei Wu,wufei@zju.edu.cn,95%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Siliang Tang,siliang@zju.edu.cn,85%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Yi Yang,yangyics@zju.edu.cn,95%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Juncheng Li,junchengli@zju.edu.cn,95%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Tat-seng Chua,,0%
https://arxiv.org/pdf/2301.09071.pdf,Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding,Yueting Zhuang,,0%
https://arxiv.org/pdf/2301.09063.pdf,DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking,Jihong Zhu,jhzhu@tsinghua.edu.cn,82%
https://arxiv.org/pdf/2301.09063.pdf,DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking,Eksan Firkat,eksan@stu.xju.edu.cn.com,85%
https://arxiv.org/pdf/2301.09063.pdf,DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking,Askar Hamdulla,askar@xju.edu.cn,85%
https://arxiv.org/pdf/2301.09063.pdf,DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking,Yucheng Huang,,0%
https://arxiv.org/pdf/2301.09063.pdf,DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking,Ziwang Xiao,,0%
https://arxiv.org/pdf/2301.09060.pdf,3D Reconstruction of Non-cooperative Resident Space Objects using Instant NGP-accelerated NeRF and D-NeRF,Basilio Caruso,,0%
https://arxiv.org/pdf/2301.09060.pdf,3D Reconstruction of Non-cooperative Resident Space Objects using Instant NGP-accelerated NeRF and D-NeRF,Trupti Mahendrakar,,0%
https://arxiv.org/pdf/2301.09060.pdf,3D Reconstruction of Non-cooperative Resident Space Objects using Instant NGP-accelerated NeRF and D-NeRF,Van Minh Nguyen,,0%
https://arxiv.org/pdf/2301.09060.pdf,3D Reconstruction of Non-cooperative Resident Space Objects using Instant NGP-accelerated NeRF and D-NeRF,Ryan T. White,,0%
https://arxiv.org/pdf/2301.09060.pdf,3D Reconstruction of Non-cooperative Resident Space Objects using Instant NGP-accelerated NeRF and D-NeRF,Todd Steffen,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Trupti Mahendrakar,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Steven Holmberg,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Andrew Ekblad,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Emma Conti,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Ryan T. White,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Markus Wilde,,0%
https://arxiv.org/pdf/2301.09059.pdf,Autonomous Rendezvous with Non-cooperative Target Objects with Swarm Chasers and Observers,Isaac Silver,,0%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Nathan Fischer,nfischer2018@my.fit.edu,82%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Isaac Silver,isaac@energymanagementaero.com,85%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Markus Wilde,mwilde@fit.edu,82%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Ryan T. White,rwhite@my.fit.edu,82%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Brian Kish,bkish@fit.edu,82%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Andrew Ekblad,aekblad2019@my.fit.edu,82%
https://arxiv.org/pdf/2301.09056.pdf,Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation around Non-Cooperative Targets,Trupti Mahendrakar,tmahendrakar2020@my.fit.edu,82%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Ryan T. White,rwhite@fit.edu,82%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Brooke Wheeler,bwheeler@fit.edu,82%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Isaac Silver,isaac@energymanagementaero.com,85%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Markus Wilde,mwilde@fit.edu,82%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Andrew Ekblad,aekblad2019@my.fit.edu,82%
https://arxiv.org/pdf/2301.09055.pdf,Resource-constrained FPGA Design for Satellite Component Feature Extraction,Trupti Mahendrakar,Tmahendrakar2020@my.fit.edu,82%
https://arxiv.org/pdf/2301.09045.pdf,Champion Solution for the WSDM2023 Toloka VQA Challenge,Shengyi Gao,,0%
https://arxiv.org/pdf/2301.09045.pdf,Champion Solution for the WSDM2023 Toloka VQA Challenge,Zhe Chen,,0%
https://arxiv.org/pdf/2301.09045.pdf,Champion Solution for the WSDM2023 Toloka VQA Challenge,Guo Chen,,0%
https://arxiv.org/pdf/2301.09045.pdf,Champion Solution for the WSDM2023 Toloka VQA Challenge,Wenhai Wang,,0%
https://arxiv.org/pdf/2301.09045.pdf,Champion Solution for the WSDM2023 Toloka VQA Challenge,Tong Lu,,0%
https://arxiv.org/pdf/2301.09015.pdf,E$^3$Pose: Energy-Efficient Edge-assisted Multi-camera System for Multi-human 3D Pose Estimation,Jie Xu,jiexu@miami.edu,95%
https://arxiv.org/pdf/2301.09015.pdf,E$^3$Pose: Energy-Efficient Edge-assisted Multi-camera System for Multi-human 3D Pose Estimation,Letian Zhang,,0%
https://arxiv.org/pdf/2301.09007.pdf,MultiNet with Transformers: A Model for Cancer Diagnosis Using Images,Yash Patel,yspatel@uwm.edu,82%
https://arxiv.org/pdf/2301.09007.pdf,MultiNet with Transformers: A Model for Cancer Diagnosis Using Images,Zeyun Yu,yuz@uwm.edu,78%
https://arxiv.org/pdf/2301.09007.pdf,MultiNet with Transformers: A Model for Cancer Diagnosis Using Images,Hosein Barzekar,barzekar@uwm.edu,78%
https://arxiv.org/pdf/2301.09007.pdf,MultiNet with Transformers: A Model for Cancer Diagnosis Using Images,Ling Tong,ltong@uwm.edu,82%
https://arxiv.org/pdf/2302.08503.pdf,Unpaired Image-to-Image Translation with Limited Data to Reveal Subtle Phenotypes,Anis Bourou,anis.bourou@ens.fr,95%
https://arxiv.org/pdf/2302.08503.pdf,Unpaired Image-to-Image Translation with Limited Data to Reveal Subtle Phenotypes,Auguste Genovesio,auguste.genovesio@ens.psl.eu,95%
https://arxiv.org/pdf/2301.08965.pdf,Raw or Cooked? Object Detection on RAW Images,William Ljungbergh,william.ljungbergh@liu.se,95%
https://arxiv.org/pdf/2301.08965.pdf,Raw or Cooked? Object Detection on RAW Images,Christoffer Petersson,christoffer.petersson@zenseact.com,95%
https://arxiv.org/pdf/2301.08965.pdf,Raw or Cooked? Object Detection on RAW Images,Joakim Johnander,joakim.johnander@zenseact.com,95%
https://arxiv.org/pdf/2301.08965.pdf,Raw or Cooked? Object Detection on RAW Images,Michael Felsberg,michael.felsberg@liu.se,95%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,Xiaofeng Liu,,0%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,Fangxu Xing,,0%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,Hanna K. Gaggin,,0%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,C. -c. Jay Kuo,,0%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,Georges El Fakhri,,0%
https://arxiv.org/pdf/2301.08959.pdf,Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI,Jonghye Woo,,0%
https://arxiv.org/pdf/2301.08957.pdf,Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,Saeed Anwar,saeed.anwar@kfupm.edu.sa,95%
https://arxiv.org/pdf/2301.08957.pdf,Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,Muhammad Ibrahim,,0%
https://arxiv.org/pdf/2301.08957.pdf,Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,Naveed Akhtar,,0%
https://arxiv.org/pdf/2301.08957.pdf,Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,Michael Wise,,0%
https://arxiv.org/pdf/2301.08957.pdf,Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,Ajmal Mian,,0%
https://arxiv.org/pdf/2301.08951.pdf,Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction,Bin Li,libin@fudan.edu.cn,95%
https://arxiv.org/pdf/2301.08951.pdf,Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction,Chengmin Gao,,0%
https://arxiv.org/pdf/2301.08939.pdf,Counterfactual Explanation and Instance-Generation using Cycle-Consistent Generative Adversarial Networks,Tehseen Zia,tehseen.zia@comsats.edu.pk,95%
https://arxiv.org/pdf/2301.08939.pdf,Counterfactual Explanation and Instance-Generation using Cycle-Consistent Generative Adversarial Networks,Zeeshan Nisar,,0%
https://arxiv.org/pdf/2301.08939.pdf,Counterfactual Explanation and Instance-Generation using Cycle-Consistent Generative Adversarial Networks,Shakeeb Murtaza,,0%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Ping Tan,pingtan@ust.hk,95%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Luwei Yang,luweiy@sfu.ca,85%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Weihao Yuan,qianmu.ywh@alibaba-inc.com,65%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Zilong Dong,dadong.gxd@alibaba-inc.com,78%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Heng Li,lh.heng.li@connect.ust.hk,95%
https://arxiv.org/pdf/2301.08930.pdf,Dense RGB SLAM with Neural Implicit Maps,Xiaodong Gu,,0%
https://arxiv.org/pdf/2301.08915.pdf,Improving Deep Regression with Ordinal Entropy,Shihao Zhang,,0%
https://arxiv.org/pdf/2301.08915.pdf,Improving Deep Regression with Ordinal Entropy,Linlin Yang,,0%
https://arxiv.org/pdf/2301.08915.pdf,Improving Deep Regression with Ordinal Entropy,Michael Bi Mi,,0%
https://arxiv.org/pdf/2301.08915.pdf,Improving Deep Regression with Ordinal Entropy,Xiaoxu Zheng,,0%
https://arxiv.org/pdf/2301.08915.pdf,Improving Deep Regression with Ordinal Entropy,Angela Yao,,0%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Houqiang Li,lihq@ustc.edu.cn,78%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Keyi Zhou,kyzhou2000@mail.ustc.edu.cn,82%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Jiajun Deng,jiajun.deng@adelaide.edu.au,95%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Hao Feng,haof@mail.ustc.edu.cn,85%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Yufei Yin,yinyufei@mail.ustc.edu.cn,95%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Wengang Zhou,,0%
https://arxiv.org/pdf/2301.08898.pdf,Recurrent Generic Contour-based Instance Segmentation with Progressive Learning,Qi Sun,,0%
https://arxiv.org/pdf/2301.08888.pdf,Pre-text Representation Transfer for Deep Learning with Limited Imbalanced Data : Application to CT-based COVID-19 Detection,Fouzia Altaf,,0%
https://arxiv.org/pdf/2301.08888.pdf,Pre-text Representation Transfer for Deep Learning with Limited Imbalanced Data : Application to CT-based COVID-19 Detection,Syed M. S. Islam,,0%
https://arxiv.org/pdf/2301.08888.pdf,Pre-text Representation Transfer for Deep Learning with Limited Imbalanced Data : Application to CT-based COVID-19 Detection,Naeem K. Janjua,,0%
https://arxiv.org/pdf/2301.08888.pdf,Pre-text Representation Transfer for Deep Learning with Limited Imbalanced Data : Application to CT-based COVID-19 Detection,Naveed Akhtar,,0%
https://arxiv.org/pdf/2301.08880.pdf,A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement,Chi-man Pun,cmpun@umac.mo,82%
https://arxiv.org/pdf/2301.08880.pdf,A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement,Zinuo Li,,0%
https://arxiv.org/pdf/2301.08880.pdf,A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement,Xuhang Chen,,0%
https://arxiv.org/pdf/2301.08880.pdf,A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement,Shuqiang Wang,,0%
https://arxiv.org/pdf/2301.08874.pdf,Improving Zero-Shot Action Recognition using Human Instruction with Text Description,Hiroshi Kera,kera@chiba-u.jp,78%
https://arxiv.org/pdf/2301.08874.pdf,Improving Zero-Shot Action Recognition using Human Instruction with Text Description,Kazuhiko Kawamoto,kawa@faculty.chiba-u.jp,90%
https://arxiv.org/pdf/2301.08874.pdf,Improving Zero-Shot Action Recognition using Human Instruction with Text Description,Nan Wu,gonan@chiba-u.jp,85%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Eric Z. Chen,,0%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Chi Zhang,,0%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Xiao Chen,,0%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Yikang Liu,,0%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Terrence Chen,,0%
https://arxiv.org/pdf/2301.08868.pdf,Computationally Efficient 3D MRI Reconstruction with Adaptive MLP,Shanhui Sun,,0%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Weixuan Liang,weixuanliang@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Siwei Wang,wangsiwei13@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Jiyuan Liu,liujiyuan13@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Xinhang Wan,wanxinhang@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Lu Zhou,lu.zhou@nuaa.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Yi Wen,wenyi21@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,En Zhu,enzhu@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Xinwang Liu,xinwangliu@nudt.edu.cn,95%
https://arxiv.org/pdf/2303.01983.pdf,Auto-weighted Multi-view Clustering for Large-scale Data,Zhe Liu,zhe.liu@nuaa.edu.cn,95%
https://arxiv.org/pdf/2301.08849.pdf,CADA-GAN: Context-Aware GAN with Data Augmentation,Sofie Daniels,,0%
https://arxiv.org/pdf/2301.08849.pdf,CADA-GAN: Context-Aware GAN with Data Augmentation,Jiugeng Sun,,0%
https://arxiv.org/pdf/2301.08849.pdf,CADA-GAN: Context-Aware GAN with Data Augmentation,Jiaqing Xie,,0%
https://arxiv.org/pdf/2301.08846.pdf,Regeneration Learning: A Learning Paradigm for Data Generation,Tao Qin,taoqin@microsoft.com,95%
https://arxiv.org/pdf/2301.08846.pdf,Regeneration Learning: A Learning Paradigm for Data Generation,Jiang Bian,jiabia@microsoft.com,65%
https://arxiv.org/pdf/2301.08846.pdf,Regeneration Learning: A Learning Paradigm for Data Generation,Yoshua Bengio,2yoshua.bengio@mila.quebec,95%
https://arxiv.org/pdf/2301.08846.pdf,Regeneration Learning: A Learning Paradigm for Data Generation,Tie-yan Liu,tyliu@microsoft.com,82%
https://arxiv.org/pdf/2301.08846.pdf,Regeneration Learning: A Learning Paradigm for Data Generation,Xu Tan,xuta@microsoft.com,85%
https://arxiv.org/pdf/2301.08815.pdf,DiffusionCT: Latent Diffusion Model for CT Image Standardization,Md Selim,,0%
https://arxiv.org/pdf/2301.08815.pdf,DiffusionCT: Latent Diffusion Model for CT Image Standardization,Jie Zhang,,0%
https://arxiv.org/pdf/2301.08815.pdf,DiffusionCT: Latent Diffusion Model for CT Image Standardization,Michael A. Brooks,,0%
https://arxiv.org/pdf/2301.08815.pdf,DiffusionCT: Latent Diffusion Model for CT Image Standardization,Ge Wang,,0%
https://arxiv.org/pdf/2301.08815.pdf,DiffusionCT: Latent Diffusion Model for CT Image Standardization,Jin Chen,,0%
https://arxiv.org/pdf/2301.08802.pdf,Impact of PCA-based preprocessing and different CNN structures on deformable registration of sonograms,Christian Schmidt,christian.schmidt@w-hs.de,95%
https://arxiv.org/pdf/2301.08802.pdf,Impact of PCA-based preprocessing and different CNN structures on deformable registration of sonograms,Heinrich Martin Overhoff,heinrich-martin.overhoff@w-hs.de,95%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Rui Kou,kourui.mun@gmail.com,95%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Satish Kumar,satishkumar@ucsb.edu,95%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Vikram Jayaram,Vikram.Jayaram@pxd.com,95%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Henry Hill,,0%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Jake Lempges,,0%
https://arxiv.org/pdf/2301.08800.pdf,In-situ Water quality monitoring in Oil and Gas operations,Eric Qian,,0%
https://arxiv.org/pdf/2301.08798.pdf,DeepCOVID-Fuse: A Multi-modality Deep Learning Model Fusing Chest X-Radiographs and Clinical Variables to Predict COVID-19 Risk Levels,Yunan Wu,yunanwu2020@u.northwestern.edu,95%
https://arxiv.org/pdf/2301.08798.pdf,DeepCOVID-Fuse: A Multi-modality Deep Learning Model Fusing Chest X-Radiographs and Clinical Variables to Predict COVID-19 Risk Levels,Amil Dravid,,0%
https://arxiv.org/pdf/2301.08798.pdf,DeepCOVID-Fuse: A Multi-modality Deep Learning Model Fusing Chest X-Radiographs and Clinical Variables to Predict COVID-19 Risk Levels,Ramsey Michael Wehbe,,0%
https://arxiv.org/pdf/2301.08798.pdf,DeepCOVID-Fuse: A Multi-modality Deep Learning Model Fusing Chest X-Radiographs and Clinical Variables to Predict COVID-19 Risk Levels,Aggelos K. Katsaggelos,,0%
https://arxiv.org/pdf/2301.08794.pdf,"Robot Skill Learning Via Classical Robotics-Based Generated Datasets: Advantages, Disadvantages, and Future Improvement",Batu Kaan Oezen,ozenbatukaan@gmail.com,85%
https://arxiv.org/pdf/2301.08784.pdf,Visual Semantic Relatedness Dataset for Image Captioning,Ahmed Sabir,,0%
https://arxiv.org/pdf/2301.08784.pdf,Visual Semantic Relatedness Dataset for Image Captioning,Francesc Moreno-noguer,,0%
https://arxiv.org/pdf/2301.08784.pdf,Visual Semantic Relatedness Dataset for Image Captioning,Lluís Padró,,0%
https://arxiv.org/pdf/2301.08783.pdf,An Asynchronous Intensity Representation for Framed and Event Video Sources,Andrew C. Freeman,acfreeman@cs.unc.edu,82%
https://arxiv.org/pdf/2301.08783.pdf,An Asynchronous Intensity Representation for Framed and Event Video Sources,Montek Singh,montek@cs.unc.edu,85%
https://arxiv.org/pdf/2301.08783.pdf,An Asynchronous Intensity Representation for Framed and Event Video Sources,Ketan Mayer-patel,kmp@cs.unc.edu,98%
https://arxiv.org/pdf/2301.08782.pdf,Estimation of mitral valve hinge point coordinates -- deep neural net for echocardiogram segmentation,Christian Schmidt,christian.schmidt@w-hs.de,95%
https://arxiv.org/pdf/2301.08782.pdf,Estimation of mitral valve hinge point coordinates -- deep neural net for echocardiogram segmentation,Heinrich Martin Overhoff,heinrich-martin.overhoff@w-hs.de,95%
https://arxiv.org/pdf/2301.08739.pdf,FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer,Zhijian Liu,,0%
https://arxiv.org/pdf/2301.08739.pdf,FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer,Xinyu Yang,,0%
https://arxiv.org/pdf/2301.08739.pdf,FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer,Haotian Tang,,0%
https://arxiv.org/pdf/2301.08739.pdf,FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer,Shang Yang,,0%
https://arxiv.org/pdf/2301.08739.pdf,FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer,Song Han,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Changan Chen,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Alexander Richard,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Roman Shapovalov,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Vamsi Krishna Ithapu,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Natalia Neverova,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Kristen Grauman,,0%
https://arxiv.org/pdf/2301.08730.pdf,Novel-View Acoustic Synthesis,Andrea Vedaldi,,0%
https://arxiv.org/pdf/2302.10277.pdf,A Comparative Analysis of CNN-Based Pretrained Models for the Detection and Prediction of Monkeypox,Sourav Saha,souravsaha0152@gmail.com,95%
https://arxiv.org/pdf/2302.10277.pdf,A Comparative Analysis of CNN-Based Pretrained Models for the Detection and Prediction of Monkeypox,Trina Chakraborty,trinasustcse41@gmail.com,85%
https://arxiv.org/pdf/2302.10277.pdf,A Comparative Analysis of CNN-Based Pretrained Models for the Detection and Prediction of Monkeypox,Tithi Paul,tithi.cse3.bu@gmail.com,85%
https://arxiv.org/pdf/2302.10277.pdf,A Comparative Analysis of CNN-Based Pretrained Models for the Detection and Prediction of Monkeypox,Rejwan Bin Sulaiman,rejwan.binsulaiman@gmail.com,95%
https://arxiv.org/pdf/2302.06389.pdf,Deep-Learning Quantitative Structural Characterization in Additive Manufacturing,Amra Peles,pelesa@ornl.gov,78%
https://arxiv.org/pdf/2302.06389.pdf,Deep-Learning Quantitative Structural Characterization in Additive Manufacturing,Vincent C. Paquit,,0%
https://arxiv.org/pdf/2302.06389.pdf,Deep-Learning Quantitative Structural Characterization in Additive Manufacturing,Ryan R. Dehoff,,0%
https://arxiv.org/pdf/2301.08669.pdf,Holistically Explainable Vision Transformers,Moritz Böhle,,0%
https://arxiv.org/pdf/2301.08669.pdf,Holistically Explainable Vision Transformers,Mario Fritz,,0%
https://arxiv.org/pdf/2301.08669.pdf,Holistically Explainable Vision Transformers,Bernt Schiele,,0%
https://arxiv.org/pdf/2301.08664.pdf,AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics,Liang Mi,liangmi@smail.nju.edu.cn,95%
https://arxiv.org/pdf/2301.08664.pdf,AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics,Haipeng Dai,haipengdai@nju.edu.cn,95%
https://arxiv.org/pdf/2301.08664.pdf,AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics,Xiaoming Fu,fu@cs.uni-goettingen.de,78%
https://arxiv.org/pdf/2301.08664.pdf,AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics,Tingting Yuan,tingting.yuan@cs.uni-goettingen.de,95%
https://arxiv.org/pdf/2301.08664.pdf,AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics,Weijun Wang,weijun.wang@cs.uni-goettingen.de,95%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Justyna P. Zwolak,jpzwolak@nist.gov,82%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Joshua Ziegler,,0%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Florian Luthi,,0%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Mick Ramsey,,0%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Felix Borjans,,0%
https://arxiv.org/pdf/2301.08654.pdf,Automated extraction of capacitive coupling for quantum dot systems,Guoji Zheng,,0%
https://arxiv.org/pdf/2301.08647.pdf,Image Memorability Prediction with Vision Transformers,Thomas Hagen,,0%
https://arxiv.org/pdf/2301.08647.pdf,Image Memorability Prediction with Vision Transformers,Thomas Espeseth,,0%
https://arxiv.org/pdf/2302.08508.pdf,Sanity checks and improvements for patch visualisation in prototype-based image classification,Romain Xu-darme,,0%
https://arxiv.org/pdf/2302.08508.pdf,Sanity checks and improvements for patch visualisation in prototype-based image classification,Georges Quénot,,0%
https://arxiv.org/pdf/2302.08508.pdf,Sanity checks and improvements for patch visualisation in prototype-based image classification,Zakaria Chihani,,0%
https://arxiv.org/pdf/2302.08508.pdf,Sanity checks and improvements for patch visualisation in prototype-based image classification,Marie-christine Rousset,,0%
https://arxiv.org/pdf/2301.08605.pdf,A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas,Laurent Ferro-famil,laurent.ferro-famil@isae-supaero.fr,95%
https://arxiv.org/pdf/2301.08605.pdf,A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas,Yue Huang,yhuang228@gmail.com,82%
https://arxiv.org/pdf/2301.08605.pdf,A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas,Loïc Denis,loic.denis@univ-st-etienne.fr,95%
https://arxiv.org/pdf/2301.08605.pdf,A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas,Zoé Berenger,,0%
https://arxiv.org/pdf/2301.08605.pdf,A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas,Florence Tupin,,0%
https://arxiv.org/pdf/2301.08590.pdf,Improving Sketch Colorization using Adversarial Segmentation Consistency,Pinar Duygulu,pinar@cs.hacettepe.edu.tr,85%
https://arxiv.org/pdf/2301.08590.pdf,Improving Sketch Colorization using Adversarial Segmentation Consistency,Emre Akbas,emre@ceng.metu.edu.tr,85%
https://arxiv.org/pdf/2301.08590.pdf,Improving Sketch Colorization using Adversarial Segmentation Consistency,Nermin Samet,nermin.samet@enpc.fr,95%
https://arxiv.org/pdf/2301.08590.pdf,Improving Sketch Colorization using Adversarial Segmentation Consistency,Samet Hicsonmez,samethicsonmez@hacettepe.edu.tr,95%
https://arxiv.org/pdf/2301.08571.pdf,Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,Bernt Schiele,schiele@mpi-inf.mpg.de,78%
https://arxiv.org/pdf/2301.08571.pdf,Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,Vera Demberg,vera@coli.uni-saarland.de,85%
https://arxiv.org/pdf/2301.08571.pdf,Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,Xudong Hong,xhong@coli.uni-saarland.de,82%
https://arxiv.org/pdf/2301.08571.pdf,Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,Asad Sayeed,asad.sayeed@gu.se,95%
https://arxiv.org/pdf/2301.08571.pdf,Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences,Khushboo Mehra,kmehra@coli.uni-saarland.de,82%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Zoltan Galaz,xgalaz00@gmail.com,78%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Jiri Mekyska,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Jan Mucha,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Vojtech Zvoncak,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Zdenek Smekal,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Marcos Faundez-zanuy,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Lubos Brabenec,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Ivona Moravkova,,0%
https://arxiv.org/pdf/2301.08534.pdf,Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of Graphomotor and Handwriting Difficulties,Irena Rektorova,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Irena Rektorova,irena.rektorova@fnusa.cz,95%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Jan Mucha,mucha@vut.cz,78%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Zoltan Galaz,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Jiri Mekyska,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Marcos Faundez-zanuy,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Vojtech Zvoncak,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Zdenek Smekal,,0%
https://arxiv.org/pdf/2301.08529.pdf,Exploration of Various Fractional Order Derivatives in Parkinson's Disease Dysgraphia Analysis,Lubos Brabenec,,0%
https://arxiv.org/pdf/2301.08479.pdf,Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance,Rizwan Ahmed Khan,Rizwan.Khan@shu.edu.pk,95%
https://arxiv.org/pdf/2301.08479.pdf,Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance,Wardah Ali,,0%
https://arxiv.org/pdf/2301.08479.pdf,Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance,Eesha Qureshi,,0%
https://arxiv.org/pdf/2301.08479.pdf,Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance,Omama Ahmed Farooqi,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Jianyuan Wang,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Lalit Bhagat,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Ceyuan Yang,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Yinghao Xu,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Yujun Shen,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Hongdong Li,,0%
https://arxiv.org/pdf/2301.08455.pdf,Spatial Steerability of GANs via Self-Supervision from Discriminator,Bolei Zhou,,0%
https://arxiv.org/pdf/2301.08448.pdf,Source-free Subject Adaptation for EEG-based Visual Recognition,Seogkyu Jeon,jone9312@yonsei.ac.kr,55%
https://arxiv.org/pdf/2301.08448.pdf,Source-free Subject Adaptation for EEG-based Visual Recognition,Hyeran Byun,hrbyun@yonsei.ac.kr,82%
https://arxiv.org/pdf/2301.08448.pdf,Source-free Subject Adaptation for EEG-based Visual Recognition,Sunhee Hwang,sunheehwang@lguplus.co.kr,95%
https://arxiv.org/pdf/2301.08448.pdf,Source-free Subject Adaptation for EEG-based Visual Recognition,Pilhyeon Lee,,0%
https://arxiv.org/pdf/2301.08448.pdf,Source-free Subject Adaptation for EEG-based Visual Recognition,Minjung Shin,,0%
https://arxiv.org/pdf/2301.08443.pdf,DIFAI: Diverse Facial Inpainting using StyleGAN Inversion,Dongsik Yoon,,0%
https://arxiv.org/pdf/2301.08443.pdf,DIFAI: Diverse Facial Inpainting using StyleGAN Inversion,Jeong-gi Kwak,,0%
https://arxiv.org/pdf/2301.08443.pdf,DIFAI: Diverse Facial Inpainting using StyleGAN Inversion,Yuanming Li,,0%
https://arxiv.org/pdf/2301.08443.pdf,DIFAI: Diverse Facial Inpainting using StyleGAN Inversion,David Han,,0%
https://arxiv.org/pdf/2301.08443.pdf,DIFAI: Diverse Facial Inpainting using StyleGAN Inversion,Hanseok Ko,,0%
https://arxiv.org/pdf/2301.08433.pdf,Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction,Nan Meng,nanmeng@hku.hk,95%
https://arxiv.org/pdf/2301.08433.pdf,Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction,Shansi Zhang,sszhang@eee.hku.hk,82%
https://arxiv.org/pdf/2301.08433.pdf,Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction,Edmund Y. Lam,elam@eee.hku.hk,82%
https://arxiv.org/pdf/2301.09416.pdf,Towards Robust Video Instance Segmentation with Temporal-Aware Transformer,Zhenghao Zhang,zhangzhenghao.zzh@alibaba-inc.com,95%
https://arxiv.org/pdf/2301.09416.pdf,Towards Robust Video Instance Segmentation with Temporal-Aware Transformer,Siyu Zhu,siting.zsy@alibaba-inc.com,60%
https://arxiv.org/pdf/2301.09416.pdf,Towards Robust Video Instance Segmentation with Temporal-Aware Transformer,Zuozhuo Dai,zuozhuo.dzz@alibaba-inc.com,85%
https://arxiv.org/pdf/2301.09416.pdf,Towards Robust Video Instance Segmentation with Temporal-Aware Transformer,Fangtao Shao,shaofangtao.sft@alibaba-inc.com,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Yong Liu,yongliu@iipc.zju.edu.cn,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Junyu Zhu,junyuzhu@zju.edu.cn,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Hongbo Zhang,zhanghongbo888@huawei.com,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Wanlong Li,liwanlong@huawei.com,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Lina Liu,linaliu@zju.edu.cn,95%
https://arxiv.org/pdf/2301.08414.pdf,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,Feng Wen,wenfeng3@huawei.com,95%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Yan Li,yanli@shnu.edu.cn,95%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Wenming Cao,wmcao@szu.edu.cn,82%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Hong Wang,wanghong1@cetc.com.cn,95%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Guitao Cao,gtcao@sei.ecnu.edu.cn,82%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Chunwei Wu,,0%
https://arxiv.org/pdf/2301.08413.pdf,Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation,Xidong Xi,,0%
https://arxiv.org/pdf/2301.09420.pdf,On Multi-Agent Deep Deterministic Policy Gradients and their Explainability for SMARTS Environment,Aditya Malte,malte@usc.edu,78%
https://arxiv.org/pdf/2301.09420.pdf,On Multi-Agent Deep Deterministic Policy Gradients and their Explainability for SMARTS Environment,Ansh Mittal,anshm@usc.edu,85%
https://arxiv.org/pdf/2301.08408.pdf,Identity masking effectiveness and gesture recognition: Effects of eye enhancement in seeing through the mask,Madeline Rachow,mrachow@uark.edu,82%
https://arxiv.org/pdf/2301.08408.pdf,Identity masking effectiveness and gesture recognition: Effects of eye enhancement in seeing through the mask,Thomas Karnowski,karnowskitp@ornl.gov,78%
https://arxiv.org/pdf/2301.08408.pdf,Identity masking effectiveness and gesture recognition: Effects of eye enhancement in seeing through the mask,Alice J. O'toole,otoole@utdallas.edu,55%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Miao Yin,miao.yin@rutgers.edu,95%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Yang Sui,yang.sui@rutgers.edu,95%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Dingwen Tao,ditao@iu.edu,82%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Lizhi Xiang,lizhi.xiang@wsu.edu,95%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Jinqi Xiao,jinqi.xiao@rutgers.edu,95%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Bo Yuan,bo.yuan@soe.rutgers.edu,95%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Chengming Zhang,,0%
https://arxiv.org/pdf/2301.09422.pdf,HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks,Yu Gong,,0%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Malik Boudiaf,lik.boudiaf.1@etsmtl.net,78%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Etienne Bennequin,etienneb@sicara.com,85%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Myriam Tami,,0%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Antoine Toubhans,,0%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Pablo Piantanida,,0%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Céline Hudelot,,0%
https://arxiv.org/pdf/2301.08390.pdf,Open-Set Likelihood Maximization for Few-Shot Learning,Ismail Ben Ayed,,0%
https://arxiv.org/pdf/2301.08387.pdf,Occlusion Reasoning for Skeleton Extraction of Self-Occluded Tree Canopies,George Kantor,kantor@andrew.cmu.edu,78%
https://arxiv.org/pdf/2301.08387.pdf,Occlusion Reasoning for Skeleton Extraction of Self-Occluded Tree Canopies,Chung Hee Kim,chunghek@andrew.cmu.edu,85%
https://arxiv.org/pdf/2301.08365.pdf,On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction,George Yiasemis,,0%
https://arxiv.org/pdf/2301.08365.pdf,On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction,Clara I. Sánchez,,0%
https://arxiv.org/pdf/2301.08365.pdf,On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction,Jan-jakob Sonke,,0%
https://arxiv.org/pdf/2301.08365.pdf,On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction,Jonas Teuwen,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Antanas Kascenas,antanas.kascenas@mre.medical.canon,95%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Pedro Sanchez,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Patrick Schrempf,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Chaoyang Wang,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,William Clackett,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Shadia S. Mikhael,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Jeremy P. Voisey,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Keith Goatman,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Alexander Weir,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Nicolas Pugeault,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Sotirios A. Tsaftaris,,0%
https://arxiv.org/pdf/2301.08330.pdf,The role of noise in denoising models for anomaly detection in medical images,Alison Q. O'neil,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Chiara Di Vece,chiara.divece.20@ucl.ac.uk,95%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Maela Le Lous,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Brian Dromey,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Francisco Vasconcelos,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Anna L David,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Donald Peebles,,0%
https://arxiv.org/pdf/2301.08317.pdf,Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain,Danail Stoyanov,,0%
https://arxiv.org/pdf/2301.08247.pdf,Multiview Compressive Coding for 3D Reconstruction,Chao-yuan Wu,,0%
https://arxiv.org/pdf/2301.08247.pdf,Multiview Compressive Coding for 3D Reconstruction,Justin Johnson,,0%
https://arxiv.org/pdf/2301.08247.pdf,Multiview Compressive Coding for 3D Reconstruction,Jitendra Malik,,0%
https://arxiv.org/pdf/2301.08247.pdf,Multiview Compressive Coding for 3D Reconstruction,Christoph Feichtenhofer,,0%
https://arxiv.org/pdf/2301.08247.pdf,Multiview Compressive Coding for 3D Reconstruction,Georgia Gkioxari,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Pierluigi Zama Ramirez,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Alex Costanzino,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Fabio Tosi,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Matteo Poggi,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Samuele Salti,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Stefano Mattoccia,,0%
https://arxiv.org/pdf/2301.08245.pdf,Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces,Luigi Di Stefano,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Mahmoud Assran,massran@meta.com,82%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Quentin Duval,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Ishan Misra,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Piotr Bojanowski,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Pascal Vincent,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Michael Rabbat,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Yann Lecun,,0%
https://arxiv.org/pdf/2301.08243.pdf,Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,Nicolas Ballas,,0%
https://arxiv.org/pdf/2301.08237.pdf,LoCoNet: Long-Short Context Network for Active Speaker Detection,Feng Cheng,fengchan@cs.unc.edu,85%
https://arxiv.org/pdf/2301.08237.pdf,LoCoNet: Long-Short Context Network for Active Speaker Detection,Xizi Wang,xiziwang@iu.edu,95%
https://arxiv.org/pdf/2301.08237.pdf,LoCoNet: Long-Short Context Network for Active Speaker Detection,Gedas Bertasius,gedas@cs.unc.edu,85%
https://arxiv.org/pdf/2301.08237.pdf,LoCoNet: Long-Short Context Network for Active Speaker Detection,David Crandall,,0%
https://arxiv.org/pdf/2301.08229.pdf,Estimating Remaining Lifespan from the Face,Amir Fekrazad,afekrazad@tamusa.edu,82%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Mihir Durve,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Sibilla Orsini,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Adriano Tiribocchi,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Andrea Montessori,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Jean-michel Tucny,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Marco Lauricella,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Andrea Camposeo,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Dario Pisignano,,0%
https://arxiv.org/pdf/2301.08189.pdf,Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking applications,Sauro Succi,,0%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,George Deligiannidis,deligian@stats.ox.ac.uk,90%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Fabian Falck,fabian.falck@stats.ox.ac.uk,95%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Dominic Danks,ddanks@turing.ac.uk,82%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Matthew Willetts,mwilletts@turing.ac.uk,82%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Christopher Williams,williams@stats.ox.ac.uk,78%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Christopher Yau,cyau@turing.ac.uk,82%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Chris Holmes,cholmes@stats.ox.ac.uk,82%
https://arxiv.org/pdf/2301.08187.pdf,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,Arnaud Doucet,doucet@stats.ox.ac.uk,78%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Alistair Weld,a.weld20@imperial.ac.uk,82%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Michael Dyck,michael.dyck@dlr.de,95%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Julian Klodmann,,0%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Giulio Anichini,,0%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Luke Dixon,,0%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Sophie Camp,,0%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Alin Albu-schäffer,,0%
https://arxiv.org/pdf/2301.08174.pdf,Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection Guidance in Neurosurgery,Stamatia Giannarou,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Huafeng Liu,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Pai Peng,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Tao Chen,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Qiong Wang,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Yazhou Yao,,0%
https://arxiv.org/pdf/2301.08160.pdf,FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,Xian-sheng Hua,,0%
https://arxiv.org/pdf/2301.08157.pdf,SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots,Luigi Manfredi,l.manfredi@dundee.ac.uk,82%
https://arxiv.org/pdf/2301.08157.pdf,SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots,Alwyn Mathew,,0%
https://arxiv.org/pdf/2301.08157.pdf,SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots,Ludovic Magerand,,0%
https://arxiv.org/pdf/2301.08157.pdf,SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation for Colonoscopy Endorobots,Emanuele Trucco,,0%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Yunzhao Zeng,zengyunzhao@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Li Chen,chenli.phd@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Ming Wu,wuming@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Hao Yang,yang.hao@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Min Zheng,zhengmin.666@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Shizun Wang,wangshizun@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Xu Wang,wangxu.ailab@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Chuang Zhang,zhangchuang@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Yi Yuan,yuanyi.cv@bytedance.com,95%
https://arxiv.org/pdf/2301.08153.pdf,SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines,Weihong Zeng,zengweihong@bytedance.com,95%
https://arxiv.org/pdf/2301.08147.pdf,"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation",Leonard Bruns,leonardb@kth.se,85%
https://arxiv.org/pdf/2301.08147.pdf,"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation",Patric Jensfelt,patric@kth.se,85%
https://arxiv.org/pdf/2301.08140.pdf,Regularising disparity estimation via multi task learning with structured light reconstruction,Alistair Weld,a.weld20@imperial.ac.uk,82%
https://arxiv.org/pdf/2301.08140.pdf,Regularising disparity estimation via multi task learning with structured light reconstruction,Joao Cartucho,,0%
https://arxiv.org/pdf/2301.08140.pdf,Regularising disparity estimation via multi task learning with structured light reconstruction,Chi Xu,,0%
https://arxiv.org/pdf/2301.08140.pdf,Regularising disparity estimation via multi task learning with structured light reconstruction,Joseph Davids,,0%
https://arxiv.org/pdf/2301.08140.pdf,Regularising disparity estimation via multi task learning with structured light reconstruction,Stamatia Giannarou,,0%
https://arxiv.org/pdf/2301.08125.pdf,Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification,Conghao Xiong,chxiong21@cse.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.08125.pdf,Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification,Irwin King,king@cse.cuhk.edu.hk,78%
https://arxiv.org/pdf/2301.08125.pdf,Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification,Joseph J. Y. Sung,josephsung@ntu.edu.sg,95%
https://arxiv.org/pdf/2301.08125.pdf,Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification,Hao Chen,,0%
https://arxiv.org/pdf/2301.08113.pdf,Soft Thresholding for Visual Image Enhancement,Christoph Dalitz,christoph.dalitz@hsnr.de,95%
https://arxiv.org/pdf/2301.08092.pdf,RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge Distillation,Yingzhen Yang,yyang409@asu.edu,82%
https://arxiv.org/pdf/2301.08092.pdf,RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge Distillation,Utkarsh Nath,unath@asu.edu,82%
https://arxiv.org/pdf/2301.08092.pdf,RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge Distillation,Yancheng Wang,ywan1053@asu.edu,65%
https://arxiv.org/pdf/2301.08072.pdf,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,Leyuan Fang,fangleyuan@gmail.com,95%
https://arxiv.org/pdf/2301.08072.pdf,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,Yue Deng,yuedeng.thu@gmail.com,95%
https://arxiv.org/pdf/2301.08072.pdf,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,Shaobo Xia,shaobo.xia@csust.edu.cn,95%
https://arxiv.org/pdf/2301.08072.pdf,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,Jiayi Ma,jyma2010@gmail.com,82%
https://arxiv.org/pdf/2301.08072.pdf,Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models,Jun Yue,,0%
https://arxiv.org/pdf/2301.08067.pdf,Interpreting CNN Predictions using Conditional Generative Adversarial Networks,R T Akash Guna,sikhakrishnanunni@gmail.com,85%
https://arxiv.org/pdf/2301.08067.pdf,Interpreting CNN Predictions using Conditional Generative Adversarial Networks,Raul Benitez,raul.benitez@upc.edu,95%
https://arxiv.org/pdf/2301.08067.pdf,Interpreting CNN Predictions using Conditional Generative Adversarial Networks,O K Sikha,,0%
https://arxiv.org/pdf/2301.08064.pdf,Position Regression for Unsupervised Anomaly Detection,Julia Wolleb,julia.wolleb@unibas.ch,95%
https://arxiv.org/pdf/2301.08064.pdf,Position Regression for Unsupervised Anomaly Detection,Florentin Bieder,florentin.bieder@unibas.ch,95%
https://arxiv.org/pdf/2301.08064.pdf,Position Regression for Unsupervised Anomaly Detection,Philippe C. Cattin,philippe.cattin@unibas.ch,95%
https://arxiv.org/pdf/2301.08064.pdf,Position Regression for Unsupervised Anomaly Detection,Robin Sandkühler,robin.sandkuehler@unibas.ch,85%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,Dongsik Yoon,kevinds1106@korea.ac.kr,60%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,Youngsaeng Jin,youngsjin@korea.ac.kr,82%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,Hanseok Ko,hsko@korea.ac.kr,82%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,Jeonggi Kwak,,0%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,Yuanming Li,,0%
https://arxiv.org/pdf/2301.08044.pdf,Reference Guided Image Inpainting using Facial Attributes,David Han,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Rosalba Calvini,rosalba.calvini@unimore.it,95%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Veronica Ferrari,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Bas Boom,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Camilla Menozzi,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Aravind Krishnaswamy Rangarajan,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Lara Maistrello,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Peter Offermans,,0%
https://arxiv.org/pdf/2301.08252.pdf,Evaluation of the potential of Near Infrared Hyperspectral Imaging for monitoring the invasive brown marmorated stink bug,Alessandro Ulrici,,0%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Sylwia Majchrowska,sylwia.majchrowska@ai.se,95%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Jakub Nalepa,jnalepa@ieee.org,82%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Maria Ferlin,maria.ferlin@pg.edu.pl,95%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Alicja Kwaśniwska,alicja@sima.ai,85%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Marta Plantykow,m.plantykow@gmail.com,82%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Agnieszka Mikołajczyk-bareła,agnieszka.mikolajczyk@voicelab.ai,85%
https://arxiv.org/pdf/2302.10768.pdf,On the Importance of Sign Labeling: The Hamburg Sign Language Notation System Case Study,Milena Olech,milena.w.olech@gmail.com,95%
https://arxiv.org/pdf/2301.08555.pdf,Hybrid Open-set Segmentation with Synthetic Negative Data,Siniša Šegvić,sinisa.segvic@fer.hr,95%
https://arxiv.org/pdf/2301.08555.pdf,Hybrid Open-set Segmentation with Synthetic Negative Data,Matej Grcić,matej.grcic@fer.hr,95%
https://arxiv.org/pdf/2301.07969.pdf,Fast Inference in Denoising Diffusion Models via MMD Finetuning,Emanuele Aiello,name.surname@polito.it,60%
https://arxiv.org/pdf/2301.07969.pdf,Fast Inference in Denoising Diffusion Models via MMD Finetuning,Diego Valsesia,,0%
https://arxiv.org/pdf/2301.07969.pdf,Fast Inference in Denoising Diffusion Models via MMD Finetuning,Enrico Magli,,0%
https://arxiv.org/pdf/2301.07958.pdf,RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes,Xiaoguang Han,hanxiaoguang@cuhk.edu.cn,95%
https://arxiv.org/pdf/2301.07958.pdf,RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes,Bingchen Gong,gongbingchen@gmail.com,95%
https://arxiv.org/pdf/2301.07958.pdf,RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes,Qi Dou,qidou@cuhk.edu.hk,95%
https://arxiv.org/pdf/2301.07958.pdf,RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes,Yuehao Wang,yhwang@link.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.07947.pdf,Point Cloud Data Simulation and Modelling with Aize Workspace,Boris Mocialov,,0%
https://arxiv.org/pdf/2301.07947.pdf,Point Cloud Data Simulation and Modelling with Aize Workspace,Eirik Eythorsson,,0%
https://arxiv.org/pdf/2301.07947.pdf,Point Cloud Data Simulation and Modelling with Aize Workspace,Reza Parseh,,0%
https://arxiv.org/pdf/2301.07947.pdf,Point Cloud Data Simulation and Modelling with Aize Workspace,Hoang Tran,,0%
https://arxiv.org/pdf/2301.07947.pdf,Point Cloud Data Simulation and Modelling with Aize Workspace,Vegard Flovik,,0%
https://arxiv.org/pdf/2301.07944.pdf,Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition,Mengmeng Wang,mengmengwang@zju.edu.cn,95%
https://arxiv.org/pdf/2301.07944.pdf,Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition,Boyu Mu,muboyu@zju.edu.cn,95%
https://arxiv.org/pdf/2301.07944.pdf,Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition,Jiazheng Xing,jiazhengxing@zju.edu.cn,95%
https://arxiv.org/pdf/2301.07944.pdf,Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition,Yong Liu,yongliu@iipc.zju.edu.cn,95%
https://arxiv.org/pdf/2301.07927.pdf,Exploiting Style Transfer-based Task Augmentation for Cross-Domain Few-Shot Learning,Jun Huang,huangj@sari.ac.cn,78%
https://arxiv.org/pdf/2301.07927.pdf,Exploiting Style Transfer-based Task Augmentation for Cross-Domain Few-Shot Learning,Shuzhen Rao,,0%
https://arxiv.org/pdf/2301.07927.pdf,Exploiting Style Transfer-based Task Augmentation for Cross-Domain Few-Shot Learning,Zengming Tang,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Snehashis Majhi,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Rui Dai,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Quan Kong,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Lorenzo Garattoni,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Gianpiero Francesca,,0%
https://arxiv.org/pdf/2301.07923.pdf,Human-Scene Network: A Novel Baseline with Self-rectifying Loss for Weakly supervised Video Anomaly Detection,Francois Bremond,,0%
https://arxiv.org/pdf/2301.07921.pdf,Spatio-Temporal Context Modeling for Road Obstacle Detection,Xiuen Wu,xiuen_wu@163.com,95%
https://arxiv.org/pdf/2301.07921.pdf,Spatio-Temporal Context Modeling for Road Obstacle Detection,Tao Wang,twang@mju.edu.cn,82%
https://arxiv.org/pdf/2301.07921.pdf,Spatio-Temporal Context Modeling for Road Obstacle Detection,Fum Yew Ching,fyching@student.usm.my,82%
https://arxiv.org/pdf/2301.07921.pdf,Spatio-Temporal Context Modeling for Road Obstacle Detection,Lingyu Liang,eelyliang@scut.edu.cn,78%
https://arxiv.org/pdf/2301.07921.pdf,Spatio-Temporal Context Modeling for Road Obstacle Detection,Zuoyong Li,,0%
https://arxiv.org/pdf/2302.12720.pdf,Surface Recognition for e-Scooter Using Smartphone IMU Sensor,Barak Or,barak@almatechnologies.com,85%
https://arxiv.org/pdf/2302.12720.pdf,Surface Recognition for e-Scooter Using Smartphone IMU Sensor,Areej Eweida,,0%
https://arxiv.org/pdf/2302.12720.pdf,Surface Recognition for e-Scooter Using Smartphone IMU Sensor,Nimord Segol,,0%
https://arxiv.org/pdf/2302.12720.pdf,Surface Recognition for e-Scooter Using Smartphone IMU Sensor,Maxim Freydin,,0%
https://arxiv.org/pdf/2302.12720.pdf,Surface Recognition for e-Scooter Using Smartphone IMU Sensor,Niv Sfaradi,,0%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Dongdong Liu,ddliu@nyu.edu,82%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Hang Zhang,,0%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Rongguang Wang,,0%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Jinwei Zhang,,0%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Chao Li,,0%
https://arxiv.org/pdf/2301.07895.pdf,Spatially Covariant Lesion Segmentation,Jiahao Li,,0%
https://arxiv.org/pdf/2301.07879.pdf,Unposed: Unsupervised Pose Estimation based Product Image Recommendations,Faizan Ahemad,ahemf@amazon.com,73%
https://arxiv.org/pdf/2301.07879.pdf,Unposed: Unsupervised Pose Estimation based Product Image Recommendations,Saurabh Sharma,sharsar@amazon.com,65%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Bin Huang,huangbin1@senseauto.com,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Yangguang Li,liyangguang@sensetime.com,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Fenggang Liu,liufenggang@senseauto.com,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Luya Wang,wangluya@bupt.edu.cn,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Enze Xie,xieenze@connect.hku.hk,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Ping Luo,pluo@cs.hku.hk,82%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Mingzhu Shen,shenmingzhu@sensetime.com,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Jing Shao,shaojing@senseauto.com,95%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Feng Liang,,0%
https://arxiv.org/pdf/2301.07870.pdf,Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception,Tianqi Wang,,0%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Bowen Zhang,zhangbowen.17@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Xiaojie Jin,jinxiaojie@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Kai Xu,xukai.1993@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Peng Wang,peng.wang@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Jiashi Feng,jshfeng@bytedance.com,82%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Weibo Gong,gongweibo@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Xiaohui Shen,shenxiaohui.kevin@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Xueqing Deng,xueqingdeng@bytedance.com,95%
https://arxiv.org/pdf/2301.07868.pdf,MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval,Zhao Zhang,,0%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Junde Wu,jundewu@ieee.org,95%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Yanwu Xu,ywxu@ieee.org,82%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Min Xu,xumin100@gmail.com,95%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Wei Ji,,0%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Huazhu Fu,,0%
https://arxiv.org/pdf/2301.11798.pdf,MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer,Yueming Jin,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Yue Han,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Sri Kalyan Yarlagadda,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Tonmoy Ghosh,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Fengqing Zhu,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Edward Sazonov,,0%
https://arxiv.org/pdf/2301.07861.pdf,Improving Food Detection For Images From a Wearable Egocentric Camera,Edward J. Delp,,0%
https://arxiv.org/pdf/2301.07845.pdf,Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment,Qiuhao Zeng,,0%
https://arxiv.org/pdf/2301.07845.pdf,Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment,Wei Wang,,0%
https://arxiv.org/pdf/2301.07845.pdf,Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment,Fan Zhou,,0%
https://arxiv.org/pdf/2301.07845.pdf,Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment,Charles Ling,,0%
https://arxiv.org/pdf/2301.07845.pdf,Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment,Boyu Wang,,0%
https://arxiv.org/pdf/2301.07836.pdf,Masked Autoencoding Does Not Help Natural Language Supervision at Scale,Yinfei Yang,yinfei yang@apple.com,95%
https://arxiv.org/pdf/2301.07836.pdf,Masked Autoencoding Does Not Help Natural Language Supervision at Scale,Angelos Katharopoulos,a katharopoulos@apple.com,82%
https://arxiv.org/pdf/2301.07836.pdf,Masked Autoencoding Does Not Help Natural Language Supervision at Scale,Vaishaal Shankar,vaishaal shankar@apple.com,95%
https://arxiv.org/pdf/2301.07836.pdf,Masked Autoencoding Does Not Help Natural Language Supervision at Scale,Tom Gunter,tom gunter@apple.com,95%
https://arxiv.org/pdf/2301.07836.pdf,Masked Autoencoding Does Not Help Natural Language Supervision at Scale,Floris Weers,fweers@apple.com,82%
https://arxiv.org/pdf/2301.08556.pdf,NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis,Allan Zhou,,0%
https://arxiv.org/pdf/2301.08556.pdf,NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis,Moo Jin Kim,,0%
https://arxiv.org/pdf/2301.08556.pdf,NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis,Lirui Wang,,0%
https://arxiv.org/pdf/2301.08556.pdf,NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis,Pete Florence,,0%
https://arxiv.org/pdf/2301.08556.pdf,NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis,Chelsea Finn,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Renjie Li,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Chun Yu Lao,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Rebecca St. George,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Katherine Lawler,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Saurabh Garg,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Son N. Tran,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Quan Bai,,0%
https://arxiv.org/pdf/2302.08505.pdf,Rapid-Motion-Track: Markerless Tracking of Fast Human Motion with Deeper Learning,Jane Alty,,0%
https://arxiv.org/pdf/2301.07807.pdf,Measuring uncertainty in human visual segmentation,Ruben Coen-cagli,ruben.coen-cagli@einsteinmed.edu,95%
https://arxiv.org/pdf/2301.07807.pdf,Measuring uncertainty in human visual segmentation,Jonathan Vacher,jonathan.vacher@u-paris.fr,95%
https://arxiv.org/pdf/2301.07807.pdf,Measuring uncertainty in human visual segmentation,Claire Launay,,0%
https://arxiv.org/pdf/2301.07807.pdf,Measuring uncertainty in human visual segmentation,Pascal Mamassian,,0%
https://arxiv.org/pdf/2301.07805.pdf,Multi-target multi-camera vehicle tracking using transformer-based camera link model and spatial-temporal information,Hsiang-wei Huang,hwhuang@uw.edu,82%
https://arxiv.org/pdf/2301.07805.pdf,Multi-target multi-camera vehicle tracking using transformer-based camera link model and spatial-temporal information,Cheng-yen Yang,cycyang@uw.edu,82%
https://arxiv.org/pdf/2301.07805.pdf,Multi-target multi-camera vehicle tracking using transformer-based camera link model and spatial-temporal information,Jenq-neng Hwang,hwang@uw.edu,78%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Megan M. Baker,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Alexander New,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Mario Aguilar-simon,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Ziad Al-halah,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Sébastien M. R. Arnold,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Ese Ben-iwhiwhu,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Andrew P. Brna,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Ethan Brooks,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Ryan C. Brown,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Zachary Daniels,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Anurag Daram,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Fabien Delattre,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Ryan Dellana,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Eric Eaton,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Haotian Fu,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Kristen Grauman,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Jesse Hostetler,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Shariq Iqbal,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Cassandra Kent,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Nicholas Ketz,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Soheil Kolouri,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,George Konidaris,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Dhireesha Kudithipudi,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Erik Learned-miller,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Seungwon Lee,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Michael L. Littman,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Sandeep Madireddy,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Jorge A. Mendez,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Eric Q. Nguyen,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Christine D. Piatko,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Praveen K. Pilly,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Aswin Raghavan,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Abrar Rahman,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Santhosh Kumar Ramakrishnan,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Neale Ratzlaff,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Andrea Soltoggio,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Peter Stone,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Indranil Sur,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Zhipeng Tang,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Saket Tiwari,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Kyle Vedder,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Felix Wang,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Zifan Xu,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Angel Yanguas-gil,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Harel Yedidsion,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Shangqun Yu,,0%
https://arxiv.org/pdf/2301.07799.pdf,A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems,Gautam K. Vallabha,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Zifan Shi,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Yujun Shen,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Yinghao Xu,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Sida Peng,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Yiyi Liao,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Sheng Guo,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Qifeng Chen,,0%
https://arxiv.org/pdf/2301.07702.pdf,Learning 3D-aware Image Synthesis with Unknown Pose Distribution,Dit-yan Yeung,,0%
https://arxiv.org/pdf/2301.07700.pdf,Attention2Minority: A salient instance inference-based multiple instance learning for classifying small lesions in whole slide images,Ziyu Su,zsu@wakehealth.edu,82%
https://arxiv.org/pdf/2301.07700.pdf,Attention2Minority: A salient instance inference-based multiple instance learning for classifying small lesions in whole slide images,Mostafa Rezapour,,0%
https://arxiv.org/pdf/2301.07700.pdf,Attention2Minority: A salient instance inference-based multiple instance learning for classifying small lesions in whole slide images,Usama Sajjad,,0%
https://arxiv.org/pdf/2301.07700.pdf,Attention2Minority: A salient instance inference-based multiple instance learning for classifying small lesions in whole slide images,Metin Nafi Gurcan,,0%
https://arxiv.org/pdf/2301.07700.pdf,Attention2Minority: A salient instance inference-based multiple instance learning for classifying small lesions in whole slide images,Muhammad Khalid Khan Niazi,,0%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Xiao Fu,fuxiao@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Ziwei Liu,ziwei.liu@ntu.edu.sg,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Jiawei Ren,jiawei011@e.ntu.edu.sg,85%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Yuxin Wang,ywangom@connect.ust.hk,82%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Chen Qian,qianchen@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Lei Yang,yanglei@sensetime.com,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Wayne Wu,wuwenyan0503@gmail.com,82%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Jiaqi Wang,wangjiaqi@pjlab.org.cn,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Liang Pan,liang.pan@ntu.edu.sg,95%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Dahua Lin,dhlin@ie.cuhk.edu.hk,82%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Tong Wu,,0%
https://arxiv.org/pdf/2301.07525.pdf,"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation",Jiarui Zhang,,0%
https://arxiv.org/pdf/2301.07681.pdf,Reduced-Reference Quality Assessment of Point Clouds via Content-Oriented Saliency Projection,Guanghui Yue,yueguanghui@szu.edu.cn,95%
https://arxiv.org/pdf/2301.07681.pdf,Reduced-Reference Quality Assessment of Point Clouds via Content-Oriented Saliency Projection,Hantao Liu,liuh35@cardiff.ac.uk,78%
https://arxiv.org/pdf/2301.07681.pdf,Reduced-Reference Quality Assessment of Point Clouds via Content-Oriented Saliency Projection,Wei Zhou,wei.zhou@uwaterloo.ca,95%
https://arxiv.org/pdf/2301.07681.pdf,Reduced-Reference Quality Assessment of Point Clouds via Content-Oriented Saliency Projection,Yipeng Qin,qiny16@cardiff.ac.uk,78%
https://arxiv.org/pdf/2301.07681.pdf,Reduced-Reference Quality Assessment of Point Clouds via Content-Oriented Saliency Projection,Ruizeng Zhang,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Xingyi He,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Jiaming Sun,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Yuang Wang,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Di Huang,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Hujun Bao,,0%
https://arxiv.org/pdf/2301.07673.pdf,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,Xiaowei Zhou,,0%
https://arxiv.org/pdf/2301.07670.pdf,Active learning for medical image segmentation with stochastic batches,Mélanie Gaillochet,,0%
https://arxiv.org/pdf/2301.07670.pdf,Active learning for medical image segmentation with stochastic batches,Christian Desrosiers,,0%
https://arxiv.org/pdf/2301.07670.pdf,Active learning for medical image segmentation with stochastic batches,Hervé Lombaert,,0%
